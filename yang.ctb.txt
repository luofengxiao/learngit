MYSQL
存储引擎（以插件的方式存在） 是基于表的 

技术文档～ 

故障库～
mysql 是单进程 多线程的方式






第一章



第二章9(MYSQL安装）
问题
  报错日志   /data/dbdata/xx.eer
  mkdir /usr/local/mysql/tmp/
  chmod -R 755  /usr/local/mysql/tmp/ 
  chown  -R  mysql:mysql /usr/local/mysql/tmp/
  
  
  MySQL Daemon failed to start.
  
  setenforce 0  关闭SElinux可以解决
 make&&make install 出错   make: *** No targets specified and no makefile found.  Stop.
 原因  没有先安装相关编译的软件   gcc
 mysql所依赖的软件
  yum -y install gcc gcc-c++ ncurses ncurses-devel openssl openssl-devel libtool* 
2.1、安装依赖包
#yum -y install gcc gcc-c++ ncurses ncurses-devel openssl openssl-devel libtool*

2.2、创建用户
# groupadd mysql
# useradd mysql –g mysql –s /sbin/nologin
2.3、安装Mysql 
# tar –xvf mysql-5.1.50.tar.gz
#cd mysql-5.1.50
# ./configure  '--prefix=/usr/local/services/mysql' '--localstatedir=/data/dbdata/' '--with-unix-socket-path=/usr/local/mysql/tmp/mysql.sock' '--with-charset=utf8' '--with-extra-charsets=complex' '--with-pthread' '--enable-thread-safe-client' '--with-ssl' '--with-client-ldflags=-all-static' '--with-mysqld-ldflags=-all-static' '--with-plugins=partition,federated,ndbcluster,innobase,csv,blackhole,myisam,innodb_plugin,heap,archive' '--enable-shared' '--enable-assembler'
# make && make install
解释
--prefix 指定 Mysql 安装目录 (必须)
--localstatedir 指定Mysql数据存储目录(必须)
--with-unix-socket-path 执行socke存放位置(必须) 
--with-charset 指定默认字符集
--with-extra-charsets 可以扩展复杂字符集
--with-pthread 强制使用pthread类库
--enable-thread-safe-client 使用编译客户端；(让客户端支持线程的意思)
--with-ssl  启用SSL的支持
--with-client-ldflags=-all-static 静态编译MySQL客户端；（静态链接提高13%性能）
--with-mysqld-ldflags=-all-static 静态编译MySQL服务器端；（静态链接提高13%性能）
--with-plugins MySQL服务器端支持的存储引擎
--enable-shared 共享变异模块
--enable-assembler 使用汇编模式提高效率
更多的详细信息可以参考：http://2999835.blog.51cto.com/2989835/1376960
2.4、初始化
# mkdir /data/dbdata/
# chown -R mysql:mysql /usr/local/services/mysql
# chown -R mysql:mysql /data/dbdata/
 mkdir /usr/local/mysql/tmp/
  chmod -R 755  /usr/local/mysql/tmp/ 
  chown  -R  mysql:mysql /usr/local/mysql/tmp/
/usr/local/services/mysql/bin/mysql_install_db --user=mysql --basedir=/usr/local/services/mysql --datadir=/data/dbdata/
# cp /usr/local/services/mysql/share/mysql/mysql.server /etc/init.d/mysqld
# chmod 755 /etc/init.d/mysqld
# vim /etc/init.d/mysqld
basedir=/usr/local/services/mysql
datadir=/data/dbdata/

2.5、配置文件
#cp support-files/my-medium.cnf /etc/my.cnf
# vim /etc/my.cnf
[client]       
port            = 3306   #客户端连接端口3306（可以更改）
socket          = /usr/local/mysql/tmp/mysql.sock  #(连接sock所在位置)
[mysqld]
datadir=/data/dbdata/   #数据库存放目录 
skip-name-resolve      #garnt时，必须使用ip，不能使用主机名
lower_case_table_names=1 #不区分大小写
innodb_file_per_table=1  #可以修改InnoDB为独立表空间模式,每个数据库的每个表都会生成一个数据空间ci
expire_logs_days = 10    #binlog日志保留10天
federated              #本地MySQL数据库要访问远程MySQL数据库的表中的数据, 必须通过FEDERATED存储引擎来实现
port            = 3306  # Mysql 端口默认3306 ，可以修改
socket          = /usr/local/mysql/tmp/mysql.sock  #Mysql 定义sock的存放位置
back_log = 50   #在MySQL的连接请求等待队列中允许存放的最大连接请求数。系统默认值为50
max_connections = 330   #最大并发连接数 ，增大该值需要相应增加允许打开的文件描述符数 
max_connect_errors = 1000  #如果某个用户发起的连接error超过该数值，则该用户的下次连接将被阻塞， 
table_open_cache = 2048    # Table_open_cache：表描述符缓存大小，可减少文件打开/关闭次数
max_allowed_packet = 16M  #将发出“信息包过大”错误，并关闭连接，默认值16M
binlog_cache_size = 2M     #限制其最大大小（当单个事务过大的时候 MySQL 会申请更多的内存）
max_heap_table_size = 64M  #内存表的大小
sort_buffer_size = 8M       #MyISAM表发生变化时重新排序所需的缓冲。一般64M足矣
join_buffer_size = 4M       # InnoDB用来缓存数据和
thread_cache_size = 64     # 缓存可重用的线程数，可以适当的调整
thread_concurrency = 8     #这个是innodb内核的并发线程处理参数，前端有100个连接，发来1000个sql，如果这个参数被设置成2。那么这1000个sql中，最多只有2 个sql在innodb内核运行。其它都得等。(事实上，处理过程很复杂，可以先这么理解，不是所有sql都需要放在Innodb内核处理的)
query_cache_size = 128M   #指定MySQL查询结果缓冲区的大小。调优可以适当调整
query_cache_limit = 2M    #缓存单条SQL的结果集上限。默认4KB。调优可以适当调整
ft_min_word_len = 4      #指定被索引的关键词的最小长度。注意：在更改该参数值后，索引必须重建！注意此值设定好后。不要随意修改
default-storage-engine = innodb  #默认引擎使用innodb
thread_stack = 192K           #应小于可用内存保持默认
transaction_isolation = REPEATABLE-READ  #设定默认的事务隔离级别
tmp_table_size = 128M  # 内部(内存中)临时表的最大大小  如果一个表增长到比此值更大,将会自动转换为基于磁盘的表. 此限制是针对单个表
log-bin=mysql-bin    # 打开二进制日志功能.注意此功能必须打开
binlog_format=mixed  #Mysql主从复制参数，必须开启
slow_query_log      #开启慢日志
long_query_time = 2  #命令耗时大于2秒的记录
server-id = 1   #主从复制唯一的服务辨识号,数值位于 1 到 2^32-1之间. 忽略此选项,MySQL不会作为master生效，越小优先级越高成为master
key_buffer_size = 8M  #关键词缓冲的大小, 一般用来缓冲MyISAM表的索引块
read_buffer_size = 2M # 用来做MyISAM表全表扫描的缓冲大小. 
read_rnd_buffer_size = 2M  #当在排序之后,从一个已经排序好的序列中读取行时,行数据将从这个缓冲中读取来防止磁盘寻道
bulk_insert_buffer_size = 64M  # 当突发插入被检测到时此缓冲将被分配用于myisam
myisam_sort_buffer_size = 128M  # 这在每个线程中被分配.所以在设置大值时需要小心
myisam_max_sort_file_size = 10G  # MySQL重建索引时所允许的最大临时文件的大小如果文件大小比此值更大,索引会通过键值缓冲创建(更慢)
myisam_repair_threads = 1  #如果一个表拥有超过一个索引, MyISAM 可以通过并行排序使用超过一个线程去修复他们
myisam_recover           #  自动检查和修复没有适当关闭的 MyISAM 表
innodb_additional_mem_pool_size = 32M  #附加的内存池被InnoDB用来保存 metadata 信息，正常保持默认
innodb_buffer_pool_size = 2G# InnoDB使用一个缓冲池来保存索引和原始数据，越大所需要的磁盘I/O 就越少，服务器物理内存大小的70%
innodb_data_file_path = ibdata1:10M:autoextend #如果你只有单个逻辑驱动保存你的数据,一个单个的自增文件就足够好了
innodb_file_io_threads = 8  # 用来同步IO操作的IO线程的数量 
innodb_thread_concurrency = 16  # 在InnoDb核心内的允许线程数量 过高的值可能导致线程的互斥颠簸

innodb_flush_log_at_trx_commit = 2 # 0代表日志只大约每秒写入日志文件并且日志文件刷新到磁盘  # 2代表日志写入日志文件在每次提交后,但是日志文件只有大约每秒才会刷新到磁盘上
innodb_log_buffer_size = 16M  ?  # 用来缓冲日志数据的缓冲区的大小.  当此值快满时, InnoDB将必须刷新数据到磁盘上
innodb_log_file_size = 512M   #在日志组中每个日志文件的大小,
innodb_log_files_in_group = 3  # 在日志组中的文件总数.  通常来说2~3是比较好的
innodb_max_dirty_pages_pct = 60  #在InnoDB缓冲池中最大允许的脏页面的比例.  60-90都可以
innodb_lock_wait_timeout = 120  #在被回滚前,一个InnoDB的事务应该等待一个锁被批准多久
[mysqldump]
quick  # 不要在将内存中的整个结果写入磁盘之前缓存. 在导出非常巨大的表时需要此项 
max_allowed_packet = 256M  # 每个连接独立的大小.大小动态增加 
[mysql]
auto-rehash         #可以在命令可以使用tab键补齐
prompt=\\u@\\d \\R:\\m>  #在Mysql命令显示主机名字
[myisamchk]
key_buffer_size = 512M # MyISAM 使用特殊的类似树的cache来使得突发插入
sort_buffer_size = 512M  # 这在每个线程中被分配.所以在设置大值时需要小心
read_buffer = 8M   # 用来做MyISAM表全表扫描的缓冲R大小.  当全表扫描需要时,在对应线程中分配
write_buffer = 8M  # 用来做MyISAM表全表扫描的缓冲W大小.  当全表扫描需要时,在对应线程中分配
[mysqlhotcopy]
interactive-timeout  #服务器关闭交互式连接前等待活动的秒数参数默认值：28800秒（8小时）
[mysqld_safe]
open-files-limit = 8192  #设置打开文件的句柄数量，在系统里面可以用ulimit –a 查看

2.6、启动服务和设置环境变量
#:vim /etc/profile
MYSQL=/usr/local/services/mysql/bin
PATH=$PATH:$MYSQL

#:source /etc/profile
启动服务
# /etc/init.d/mysqld start
注意:
log_slave_updates
主从复制的时候。在主(master)服务器上关闭此选项，在从(slave)上面开启此选项

2.7、本章练习题目
  (1)、要求安装Mysql数据库版本号及包名为：mysql-5.1.50.tar.gz
  (2)、安装目录为/usr/local/services
  (3)、数据存储目录为/data/dbdata
  (4)、配置文件存放为/etc/my.cnf
  (5)、用户名为mysql 
:wq  (6)、要求设置环境变量，服务加入开机自动启动，



MY.CNF 配置文件
#BEGIN CONFIG INFO
#DESCR: 4GB RAM, InnoDB only, ACID, few connections, heavy queries
#TYPE: SYSTEM
#END CONFIG INFO

#
# This is a MySQL example config file for systems with 4GB of memory
# running mostly MySQL using InnoDB only tables and performing complex
# queries with few connections.
# 
# You can copy this file to /etc/my.cnf to set global options,
# mysql-data-dir/my.cnf to set server-specific options 
# (/data for this installation) or to
# ~/.my.cnf to set user-specific options.
#
# In this file, you can use all long options that a program supports.
# If you want to know which options a program supports, run the program
# with the "--help" option.
#
# More detailed information about the individual options can also be
# found in the manual.
#

#
# The following options will be read by MySQL client applications.
# Note that only client applications shipped by MySQL are guaranteed
# to read this section. If you want your own MySQL client program to
# honor these values, you need to specify it as an option during the
# MySQL client library initialization.
#
[client]
#password	= [your_password]
port		= 3306
socket		= /usr/local/mysql/tmp/mysql.sock

# *** Application-specific options follow here ***

#
# The MySQL server
#
[mysqld]
datadir=/data/dbdata/
basedir = /usr/local/services/mysql/
skip-name-resolve
lower_case_table_names=1
innodb_file_per_table=1
expire_logs_days = 10
federated
# generic configuration options
port		= 3306
socket		= /usr/local/mysql/tmp/mysql.sock

# back_log is the number of connections the operating system can keep in
# the listen queue, before the MySQL connection manager thread has
# processed them. If you have a very high connection rate and experience
# "connection refused" errors, you might need to increase this value.
# Check your OS documentation for the maximum value of this parameter.
# Attempting to set back_log higher than your operating system limit
# will have no effect.
back_log = 50

# Don't listen on a TCP/IP port at all. This can be a security
# enhancement, if all processes that need to connect to mysqld run
# on the same host.  All interaction with mysqld must be made via Unix
# sockets or named pipes.
# Note that using this option without enabling named pipes on Windows
# (via the "enable-named-pipe" option) will render mysqld useless!
#skip-networking

# The maximum amount of concurrent sessions the MySQL server will
# allow. One of these connections will be reserved for a user with
# SUPER privileges to allow the administrator to login even if the
# connection limit has been reached.
max_connections = 330

# Maximum amount of errors allowed per host. If this limit is reached,
# the host will be blocked from connecting to the MySQL server until
# "FLUSH HOSTS" has been run or the server was restarted. Invalid
# passwords and other errors during the connect phase result in
# increasing this value. See the "Aborted_connects" status variable for
# global counter.
max_connect_errors = 1000

# The number of open tables for all threads. Increasing this value
# increases the number of file descriptors that mysqld requires.
# Therefore you have to make sure to set the amount of open files
# allowed to at least 4096 in the variable "open-files-limit" in
# section [mysqld_safe]
table_open_cache = 2048

# Enable external file level locking. Enabled file locking will have a
# negative impact on performance, so only use it in case you have
# multiple database instances running on the same files (note some
# restrictions still apply!) or if you use other software relying on
# locking MyISAM tables on file level.
#external-locking

# The maximum size of a query packet the server can handle as well as
# maximum query size server can process (Important when working with
# large BLOBs).  enlarged dynamically, for each connection.
max_allowed_packet = 16M

# The size of the cache to hold the SQL statements for the binary log
# during a transaction. If you often use big, multi-statement
# transactions you can increase this value to get more performance. All
# statements from transactions are buffered in the binary log cache and
# are being written to the binary log at once after the COMMIT.  If the
# transaction is larger than this value, temporary file on disk is used
# instead.  This buffer is allocated per connection on first update
# statement in transaction
binlog_cache_size = 2M

# Maximum allowed size for a single HEAP (in memory) table. This option
# is a protection against the accidential creation of a very large HEAP
# table which could otherwise use up all memory resources.
max_heap_table_size = 64M

# Sort buffer is used to perform sorts for some ORDER BY and GROUP BY
# queries. If sorted data does not fit into the sort buffer, a disk
# based merge sort is used instead - See the "Sort_merge_passes"
# status variable. Allocated per thread if sort is needed.
sort_buffer_size = 8M

# This buffer is used for the optimization of full JOINs (JOINs without
# indexes). Such JOINs are very bad for performance in most cases
# anyway, but setting this variable to a large value reduces the
# performance impact. See the "Select_full_join" status variable for a
# count of full JOINs. Allocated per thread if full join is found
join_buffer_size = 4M

# How many threads we should keep in a cache for reuse. When a client
# disconnects, the client's threads are put in the cache if there aren't
# more than thread_cache_size threads from before.  This greatly reduces
# the amount of thread creations needed if you have a lot of new
# connections. (Normally this doesn't give a notable performance
# improvement if you have a good thread implementation.)
thread_cache_size = 64

# This permits the application to give the threads system a hint for the
# desired number of threads that should be run at the same time.  This
# value only makes sense on systems that support the thread_concurrency()
# function call (Sun Solaris, for example).
# You should try [number of CPUs]*(2..4) for thread_concurrency
thread_concurrency = 8

# Query cache is used to cache SELECT results and later return them
# without actual executing the same query once again. Having the query
# cache enabled may result in significant speed improvements, if your
# have a lot of identical queries and rarely changing tables. See the
# "Qcache_lowmem_prunes" status variable to check if the current value
# is high enough for your load.
# Note: In case your tables change very often or if your queries are
# textually different every time, the query cache may result in a
# slowdown instead of a performance improvement.
query_cache_size = 128M

# Only cache result sets that are smaller than this limit. This is to
# protect the query cache of a very large result set overwriting all
# other query results.
query_cache_limit = 2M

# Minimum word length to be indexed by the full text search index.
# You might wish to decrease it if you need to search for shorter words.
# Note that you need to rebuild your FULLTEXT index, after you have
# modified this value.
ft_min_word_len = 4

# If your system supports the memlock() function call, you might want to
# enable this option while running MySQL to keep it locked in memory and
# to avoid potential swapping out in case of high memory pressure. Good
# for performance.
#memlock

# Table type which is used by default when creating new tables, if not
# specified differently during the CREATE TABLE statement.
default-storage-engine = innodb

# Thread stack size to use. This amount of memory is always reserved at
# connection time. MySQL itself usually needs no more than 64K of
# memory, while if you use your own stack hungry UDF functions or your
# OS requires more stack for some operations, you might need to set this
# to a higher value.
thread_stack = 192K

# Set the default transaction isolation level. Levels available are:
# READ-UNCOMMITTED, READ-COMMITTED, REPEATABLE-READ, SERIALIZABLE
transaction_isolation = REPEATABLE-READ

# Maximum size for internal (in-memory) temporary tables. If a table
# grows larger than this value, it is automatically converted to disk
# based table This limitation is for a single table. There can be many
# of them.
tmp_table_size = 128M

# Enable binary logging. This is required for acting as a MASTER in a
# replication configuration. You also need the binary log if you need
# the ability to do point in time recovery from your latest backup.
log-bin=mysql-bin

# binary logging format - mixed recommended
binlog_format=mixed

# If you're using replication with chained slaves (A->B->C), you need to
# enable this option on server B. It enables logging of updates done by
# the slave thread into the slave's binary log.

# Enable the full query log. Every query (even ones with incorrect
# syntax) that the server receives will be logged. This is useful for
# debugging, it is usually disabled in production use.
#log

# Print warnings to the error log file.  If you have any problem with
# MySQL you should enable logging of warnings and examine the error log
# for possible explanations. 
#log_warnings

# Log slow queries. Slow queries are queries which take more than the
# amount of time defined in "long_query_time" or which do not use
# indexes well, if log_short_format is not enabled. It is normally good idea
# to have this turned on if you frequently add new queries to the
# system.
slow_query_log

# All queries taking more than this amount of time (in seconds) will be
# trated as slow. Do not use "1" as a value here, as this will result in
# even very fast queries being logged from time to time (as MySQL
# currently measures time with second accuracy only).
long_query_time = 0.5

# The directory used by MySQL for storing temporary files. For example,
# it is used to perform disk based large sorts, as well as for internal
# and explicit temporary tables. It might be good to put it on a
# swapfs/tmpfs filesystem, if you do not create very large temporary
# files. Alternatively you can put it on dedicated disk. You can
# specify multiple paths here by separating them by ";" - they will then
# be used in a round-robin fashion.
#tmpdir = /tmp


# ***  Replication related settings 


# Unique server identification number between 1 and 2^32-1. This value
# is required for both master and slave hosts. It defaults to 1 if
# "master-host" is not set, but will MySQL will not function as a master
# if it is omitted.
server-id = 1
#replicate-do-db=tuge
#replicate-ignore-table=tuge.datasource
#replicate-ignore-table=tuge.gps_currentinfo
#replicate-ignore-table=tuge.dm_datasource
#log-slave-updates
#sync_binlog=1
#auto_increment_increment=2
#auto_increment_offset=2

# Replication Slave (comment out master section to use this)
#
# To configure this host as a replication slave, you can choose between
# two methods :
#
# 1) Use the CHANGE MASTER TO command (fully described in our manual) -
#    the syntax is:
#
#    CHANGE MASTER TO MASTER_HOST=<host>, MASTER_PORT=<port>,
#    MASTER_USER=<user>, MASTER_PASSWORD=<password> ;
#
#    where you replace <host>, <user>, <password> by quoted strings and
#    <port> by the master's port number (3306 by default).
#
#    Example:
#
#    CHANGE MASTER TO MASTER_HOST='125.564.12.1', MASTER_PORT=3306,
#    MASTER_USER='joe', MASTER_PASSWORD='secret';
#
# OR
#
# 2) Set the variables below. However, in case you choose this method, then
#    start replication for the first time (even unsuccessfully, for example
#    if you mistyped the password in master-password and the slave fails to
#    connect), the slave will create a master.info file, and any later
#    changes in this file to the variable values below will be ignored and
#    overridden by the content of the master.info file, unless you shutdown
#    the slave server, delete master.info and restart the slaver server.
#    For that reason, you may want to leave the lines below untouched
#    (commented) and instead use CHANGE MASTER TO (see above)
#
# required unique id between 2 and 2^32 - 1
# (and different from the master)
# defaults to 2 if master-host is set
# but will not function as a slave if omitted
#server-id = 2
#
# The replication master for this slave - required
#master-host = <hostname>
#
# The username the slave will use for authentication when connecting
# to the master - required
#master-user = <username>
#
# The password the slave will authenticate with when connecting to
# the master - required
#master-password = <password>
#
# The port the master is listening on.
# optional - defaults to 3306
#master-port = <port>


# Make the slave read-only. Only users with the SUPER privilege and the
# replication slave thread will be able to modify data on it. You can
# use this to ensure that no applications will accidently modify data on
# the slave instead of the master
#read_only


#*** MyISAM Specific options


# Size of the Key Buffer, used to cache index blocks for MyISAM tables.
# Do not set it larger than 30% of your available memory, as some memory
# is also required by the OS to cache rows. Even if you're not using
# MyISAM tables, you should still set it to 8-64M as it will also be
# used for internal temporary disk tables.
key_buffer_size = 8M

# Size of the buffer used for doing full table scans of MyISAM tables.
# Allocated per thread, if a full scan is needed.
read_buffer_size = 2M

# When reading rows in sorted order after a sort, the rows are read
# through this buffer to avoid disk seeks. You can improve ORDER BY
# performance a lot, if set this to a high value.
# Allocated per thread, when needed.
read_rnd_buffer_size = 2M

# MyISAM uses special tree-like cache to make bulk inserts (that is,
# INSERT ... SELECT, INSERT ... VALUES (...), (...), ..., and LOAD DATA
# INFILE) faster. This variable limits the size of the cache tree in
# bytes per thread. Setting it to 0 will disable this optimisation.  Do
# not set it larger than "key_buffer_size" for optimal performance.
# This buffer is allocated when a bulk insert is detected.
bulk_insert_buffer_size = 64M

# This buffer is allocated when MySQL needs to rebuild the index in
# REPAIR, OPTIMIZE, ALTER table statements as well as in LOAD DATA INFILE
# into an empty table. It is allocated per thread so be careful with
# large settings.
myisam_sort_buffer_size = 128M

# The maximum size of the temporary file MySQL is allowed to use while
# recreating the index (during REPAIR, ALTER TABLE or LOAD DATA INFILE.
# If the file-size would be bigger than this, the index will be created
# through the key cache (which is slower).
myisam_max_sort_file_size = 10G

# If a table has more than one index, MyISAM can use more than one
# thread to repair them by sorting in parallel. This makes sense if you
# have multiple CPUs and plenty of memory.
myisam_repair_threads = 1

# Automatically check and repair not properly closed MyISAM tables.
myisam_recover

# *** INNODB Specific options ***

# Use this option if you have a MySQL server with InnoDB support enabled
# but you do not plan to use it. This will save memory and disk space
# and speed up some things.
#skip-innodb

# Additional memory pool that is used by InnoDB to store metadata
# information.  If InnoDB requires more memory for this purpose it will
# start to allocate it from the OS.  As this is fast enough on most
# recent operating systems, you normally do not need to change this
# value. SHOW INNODB STATUS will display the current amount used.
innodb_additional_mem_pool_size = 32M

# InnoDB, unlike MyISAM, uses a buffer pool to cache both indexes and
# row data. The bigger you set this the less disk I/O is needed to
# access data in tables. On a dedicated database server you may set this
# parameter up to 80% of the machine physical memory size. Do not set it
# too large, though, because competition of the physical memory may
# cause paging in the operating system.  Note that on 32bit systems you
# might be limited to 2-3.5G of user level memory per process, so do not
# set it too high.
innodb_buffer_pool_size = 2G

# InnoDB stores data in one or more data files forming the tablespace.
# If you have a single logical drive for your data, a single
# autoextending file would be good enough. In other cases, a single file
# per device is often a good choice. You can configure InnoDB to use raw
# disk partitions as well - please refer to the manual for more info
# about this.
innodb_data_file_path = ibdata1:10M:autoextend

# Set this option if you would like the InnoDB tablespace files to be
# stored in another location. By default this is the MySQL datadir.
#innodb_data_home_dir = <directory>

# Number of IO threads to use for async IO operations. This value is
# hardcoded to 4 on Unix, but on Windows disk I/O may benefit from a
# larger number.
innodb_file_io_threads = 8


# If you run into InnoDB tablespace corruption, setting this to a nonzero
# value will likely help you to dump your tables. Start from value 1 and
# increase it until you're able to dump the table successfully.
#innodb_force_recovery=1

# Number of threads allowed inside the InnoDB kernel. The optimal value
# depends highly on the application, hardware as well as the OS
# scheduler properties. A too high value may lead to thread thrashing.
innodb_thread_concurrency = 16

# If set to 1, InnoDB will flush (fsync) the transaction logs to the
# disk at each commit, which offers full ACID behavior. If you are
# willing to compromise this safety, and you are running small
# transactions, you may set this to 0 or 2 to reduce disk I/O to the
# logs. Value 0 means that the log is only written to the log file and
# the log file flushed to disk approximately once per second. Value 2
# means the log is written to the log file at each commit, but the log
# file is only flushed to disk approximately once per second.
innodb_flush_log_at_trx_commit = 2

# Speed up InnoDB shutdown. This will disable InnoDB to do a full purge
# and insert buffer merge on shutdown. It may increase shutdown time a
# lot, but InnoDB will have to do it on the next startup instead.
#innodb_fast_shutdown

# The size of the buffer InnoDB uses for buffering log data. As soon as
# it is full, InnoDB will have to flush it to disk. As it is flushed
# once per second anyway, it does not make sense to have it very large
# (even with long transactions). 
innodb_log_buffer_size = 16M

# Size of each log file in a log group. You should set the combined size
# of log files to about 25%-100% of your buffer pool size to avoid
# unneeded buffer pool flush activity on log file overwrite. However,
# note that a larger logfile size will increase the time needed for the
# recovery process.
innodb_log_file_size = 128M

# Total number of files in the log group. A value of 2-3 is usually good
# enough.
innodb_log_files_in_group = 3

# Location of the InnoDB log files. Default is the MySQL datadir. You
# may wish to point it to a dedicated hard drive or a RAID1 volume for
# improved performance
#innodb_log_group_home_dir

# Maximum allowed percentage of dirty pages in the InnoDB buffer pool.
# If it is reached, InnoDB will start flushing them out agressively to
# not run out of clean pages at all. This is a soft limit, not
# guaranteed to be held.
innodb_max_dirty_pages_pct = 60

# The flush method InnoDB will use for Log. The tablespace always uses
# doublewrite flush logic. The default value is "fdatasync", another
# option is "O_DSYNC".
#innodb_flush_method=O_DSYNC

# How long an InnoDB transaction should wait for a lock to be granted
# before being rolled back. InnoDB automatically detects transaction
# deadlocks in its own lock table and rolls back the transaction. If you
# use the LOCK TABLES command, or other transaction-safe storage engines
# than InnoDB in the same transaction, then a deadlock may arise which
# InnoDB cannot notice. In cases like this the timeout is useful to
# resolve the situation.
innodb_lock_wait_timeout = 120


[mysqldump]
# Do not buffer the whole result set in memory before writing it to
# file. Required for dumping very large tables
quick

max_allowed_packet = 256M

[mysql]
no-auto-rehash
prompt=\\u@\\d \\R:\\m>
# Only allow UPDATEs and DELETEs that use keys.
#safe-updates

[myisamchk]
key_buffer_size = 512M
sort_buffer_size = 512M
read_buffer = 8M
write_buffer = 8M

[mysqlhotcopy]
interactive-timeout

[mysqld_safe]
# Increase the amount of open files allowed per process. Warning: Make
# sure you have set the global system limit high enough! The high value
# is required for a large number of opened tables
open-files-limit = 8192


第3章  数据类型
                                                        
第三章 Mysql数据类型
      
3.1、整数类型
      
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 || 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             整数类型
           ||             字节
           ||             取值范围
           ||             取值范围
           ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             tinyint
           ||             1
           ||             有符号 -128
            无符号 0
           ||             有符号 127
            无符号 255
           ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             smallint
           ||             2
           ||             有符号 -32768
            无符号 0
           ||             有符号 32767
            无符号65535
           ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             mediumint
           ||             3
           ||             有符号 -8388608
            无符号 0
           ||             有符号 8388607
            无符号1677215
           ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             int,integer
           ||             4
           ||             有符号 -2147483648
            无符号 0
           ||             有符号 2147483647
            无符号 4294967295
           ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             bigint
           ||             8
           ||             有符号 -263
            无符号 0
           ||             有符号 263-1
            无符号264-1
           ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

      以上表 我们可以看到int类型和interger类型的取值范围是一样的，tinyint类型占用的字节最小，只需要1个字节，因此它的取值范围也是最小的，bigint占用的字节最大，那么它的取值范围也是最大的。
      其格式默认如下：
      create table zy(
      a tinyint，
      b smallint，
      c mediumint，
      d int，
      e bigint); 整型类可以自增auto_increment，其中(-)负号占一位，
   
                                                             
  Mysql 中创建表时，需要考虑字段选择，哪一种数据类型是最合适的，只有选择了合适的数据类型，才能提高数据库的效率。
      (1)、如何选择整数类型
      整数类型和浮点数类型最大的区别在于能否表达小数。那么我们的整数是不能表达小数的，而浮点却可以，不同的整数类型取值范围不一样，tinyint类型取值范围0~255，如果字段不超过255。那么选择tinyint就足够了，bigint取值范围最大，常用的都是int类型。
       
       
       
       
      
5.2、浮点类型与定点数类型
      
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 || 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             浮点数类型
           ||             字节
           ||             负数的取值范围
           ||             非负数得取值范围
           ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             float 单精度
           ||             4
           ||             -3.402823466E+38~
            -1.175494351E-38
             
           ||             0和1.175494351E-38~
            3.402823466E+38
           ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             double 双精度
           ||             8
           ||             -1.7976931348623157E+308~
            -2.2250738585072014E-308 
           ||             0和2.2250738585072014E-308~1.7976931348623157E
           ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             定点类型
           ||             字节
           ||             描述
           ||  ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             decimal(m,d)
           ||             M+2
           ||             最大取值范围与double相同，给定decimal的有效取值范围由M和D决定
           ||  ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

       
      举例:
      decimal(M,D) M为精度，D为标度
      decimal (6,2) 数据长度为6，小数点保留2位
      create table tt(
      aa float,     
      bb double,
      cc decimal (6,2));
      float和double 类型也可以通过M，D设置一个显示宽度指示器和一个小数点指示器。
      (2)、如何选择浮点数类型和定点数类型
      Double类型要比float精确要高，那么如果需要精确到小数点10位以上，那么我们就用double类型，普通用float类型就够了。
      在Mysql中，定点数的精度比浮点要高，而且，浮点数会出现误差，如果要对数据的精度要求比较高的话，那么应该选择定点数。
       
      
6.3、日期与时间类型
      
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 || 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             日期和时间类型
           ||             字节
           ||             最小值
           ||             最大值
           ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             Date 年月日
           ||             4
           ||             1000-01-01
           ||             9999-12-31
           ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             Datetime 年月日 时分秒
           ||             8
           ||             1000-01-01 00:00:00
           ||             9999-12-31 23:59:59
           ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             Timestamp 时区对应时间
           ||             4
           ||             19700101080001
           ||             20380119111407
           ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             Time  单独表示时间
           ||             3
           ||             -838:59:59
           ||             838:59:59
           ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             Year 单独表示年
           ||             1
           ||             1901
           ||             2155
           ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

      举例：                                                        举例：
      create table yy(aa date,bb datetime,cc timestamp,dd time,ff year);
          
   4. 
          
      
   4.                                                         (4)如何选择时间和日期类型
      year类型只表示年份，如果单单只记录年份那么选择year就OK，还可以节约空间，
      time类型只表示时间，如果只需要记录时间那么只选择time类型,
      date类型只表示年月日，如果只需要记录年月日，那么只选择date类型
      如果既需要记录年月日和时间，可以选择datetime类型和timestamp类型，
      datetime类型表示的时间范围比timestamp的类型要大，因此，需要时间范围比较大的选择datetime类型比较合适，
      timestamp类型的时间是根据时区来选择的，如果需要显示的时间与时区对应，那么选择timestamp类型。
       
      
7.4、字符串类型
      
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             字符串类型
           ||             字节
           ||             描述
           ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             char(m)
           ||             M
           ||             M为0-255之间的整数
           ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             varchar(m)
           ||              
           ||             M为0-65535之间的整数，值的长度为+1个字节
           ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             tinytext
           ||              
           ||             允许长度0-255字节，值为长度+2个字节
           ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             text
           ||              
           ||             允许长度0-65535字节，值为长度+2个字节
           ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             mediumtext
           ||              
           ||             允许长度0~167772150字节     值为长度+3个字节
           ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             longtext
           ||              
           ||             允许长度0~4294967295字节    值为长度+4个字节
           ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

      char(5) 比如这行实际只用了3个字节，但是还占用5个字节的空间，
      varchar(5) 比如这行实际只用了3个字节，它就只是占用了3个字节的长度
      
      Text类型石一种特殊的文字串类型，text只有保存字符数据，比如：新闻内容等。
      Text包含了(tinytext mediumtext,langtext)
      
8.5、二进制类型
          

   
   
      binary(10)
      varbinary(20)
      存储普通二进制字符类串型.两者区别和char varchar一样，一个占用实际字节，一个占用分配固定字节。
      
      
      
     
    6)、text类型和blob类型
        text类型与blob类型很类似，text只能存储字符数据，纯文本之类的。选择text类型
        blob 类型可以存储二进制数据，可以存储图片pdf等的二进制数据，选择blob类型
       
      
3.6、枚举类型
      enum 取值范围0~65535
      set   取值范围0~64
       
      举例:
      create table cc(
      aa enum(‘man’, ‘woman’),                         
      bb set (‘youyong’, ‘pashan’, ‘lanqiu’));
      insert into cc values(‘woman’, ‘youyong,pashan,lanqiu’);
       
      (5)、enum 类型和set类型
      Enum类型可以有65535个成员，而set类型最多只能包含64个成员，两者取值范围只能在成员列表中选取，enum类型只能从成员当中选择一个，而set 类型可以选择多个，
        enum用法：那么对于多个值当中选取一个的话，可以选择enum类型，比如，性别（男女）二选一
       set  类型用法：比如个人爱好，可以选择多个，那么这个使用我们用set类型
          
       
          
   

第四章 数据库操作
                                                    
                                                 第四章 Mysql数据库操作
        数据库之指长期存储在计算机内，有组织的和可共享的数据集合，那么简单的说。数据库就是存储数据的一个地方，只是，存储方式有特定的规律，这样可以方便处理数据    
          
          
         语法：create database 数据库名;
         语法：show databases 查看已经存在数据库
                                                                 
 存储引擎简介
      1)、innoDB 引擎
      innoDB是mysql的一种存储引擎，inodb给mysql的表提供了事务日志，回滚、奔溃、修复能力和多版本并发控制的事务安全。Mysql从3.23.34a开始包含innoDB存储引擎.
      innoDB是第一个提供外键约束的表引擎，而且对innoDB对事务处理的能力。也是其它引擎无法与之抗衡的。，
         innodb支持自动增长列使用auto_increment，自动增长列不值不能为空
         innodb 存储引擎中支持外键Z(foreign key)，外键所在的表为子表，外键所依赖的表为父母，父表中的被子表外检关联的字段必须是主键，当删除、更新父表的某条信息时，字表也必须有相应的改变，
         innodb存储引擎中，创建表的表结构存储在.frm文件中，数据和索引存储在innodb_data_home_dir 和innodb_data_file_path定义的表空间.
      数据文件：*.myd
索引文件：*.myi
表定义文件：*.frm
         Inoodb存储引擎的
      优势：在于提供了良好的事务管理、崩溃、修复能力和并发控制，
      缺点：是其读写效率稍差，占用的数据空间相对比较大.
       
       
      (2)、MyISAM引擎                                                       
      MyISAM存储表分为3个文件，文件与表名相同，扩展包括frm,MYD和MYI，
      Frm 为扩展名的文件存储表的结构
      MYD 为扩展名的文件存储数据
      MYI  为扩展名的文件存储索引
        优点：占用空间小，。处理速度快，
        缺点： 不支持事务日志的完整性和并发性
          
      (3)、MEMORY 引擎
       Mysql中的特殊引擎，所有的数据全部存放于内存当中，在企业生产环境当中。几乎
      是用不到。因为数据存储在内存，如果内存出现异常。将影响数据的完整性。
       优点：存储速度快
       缺点：缺乏稳定性和完整性
          
     
     存储引擎是Mysql的特点，Mysql可以选择多种存储引擎及不同的存储方式，是否进行事物处理等。
             
       查询Mysql支持引擎的信息
      Mysql->show variables like ‘have%’
          
          
          
        更改表的存储引擎 
        alter table XXX engine=存储引擎
        
        (3)、查询Mysql默认存储引擎 
      Mysql-> show variables like 'storage_engine';
       如果想修改存储引擎，可以在 my.ini中进行修改
      Default-storage-engine=引擎类型
          
          
          

第五章  表的操作
                                                     
                                        第五章 创建、修改、删除表
                                                               
5.1、创建表的方法
      语法：create table 表名(
      属性名  数据类型 完整约束条件，
      属性名  数据类型 完整约束条件，
      。。。。。。。。。
      属性名  数据类型
      )
          
                                                             
5.2、表的完整性约束
      
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             约束条件
           ||             说明
           ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             (1)primary key
           ||             标识该字段为表的主键，具备唯一性
           ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             (2)foreign key
           ||             标识该字段为表的外键，与某表的主键联系
           ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             (3)not null
           ||             标识该属于的值不能为空
           ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             (4)unique
           ||             标识这个属性值是唯一
           ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             (5)auto_increment
           ||             标识该属性值的自动增加
           ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
             (6)default
           ||             为该属性值设置默认值
           ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

          
          设置表的主键
         主键是一个表的特殊字段，这个字段是唯一标识表中的每条信息，主键和记录的关系，跟人的身份证一样。名字可以一样，但是身份证号码觉得不会一样，主键用来标识每个记录，每个记录的主键值都不同，
         主键可以帮助Mysql以最快的速度查找到表中的某一条信息，主键必须满足的条件那就是它的唯一性，表中的任意两条记录的主键值，不能相同，否则就会出现主键值冲突，
      主键值不能为空，可以是单一的字段，也
      举例：
      create table sxkj(
      user_id int primary key
      user_name varchar(20),
      user_sex char(7));
       
    6. 设置多个字段做主键
      举例：
        create table sxkj2(
      user_id int ,
      primary key(user_id,user_name));
          
   
6.(3)、设置表的外键，
      外键是表的一个特殊字段，如果aa是B表的一个属性且依赖于A表的主键，那么A表被称为父表。B表为被称为子表，
        
      举例说明:
      user_id 是A 表的主键，
      aa  是B表的外键，
      那么user_id的值为zhangsan，如果这个zhangsan离职了，需要从A表中删除，那么B表关于zhangsan的信息也该得到相应的删除，这样可以保证信息的完整性。
      -> constraint c_fk foreign key (user_id,grade_id)
      -> references A(user_id,grade_id) on delete cascade);
          
       在创建的表后面加上ENGINE=INNODB； 表模式下才可生效。
      
   7.语法：
      constraint  外键别名 foreign key(外键字段1，外键字段2) 
      references 表名(关联的主键字段1，主键字段2) 
          
          
      插入数据
   7. 向A表和B表中插入数据，以及建标时两者的数据类型必须以致。
      注意因为受到外键的约束，B所有关联的外键字段的值要和主的以致
      root@zytest 15:24>insert into A values('11','12.5','13.5');
      root@zytest 15:25>insert into B values('11','13.5','13.5');
      所以在每次删除两者相关联的数据时。只要删除掉A里面数据那么B将自动也删除
  (4)设置表的非空值
      语法： 属性名  数据类型  NOT NULL
      举例：
      create table C(
      user_id int NOT NULL);
   
    5。设置表的唯一性约束
      唯一性指的就是所有记录中该字段。不能重复出现。
      语法：属性名 数据类型  unique
      举例：
      root@zytest 15:43>create table D(
          -> user_id int unique);
      root@zytest 15:44>show create table D;
          
      (5)、设置表的属性值自动增加
      Auto_increment 是Mysql数据库中特殊的约束条件，它的作用是向表中插入数据时
      自动生成唯一的ID，一个表只能有一个字段使用auto_increment 约束，必须是唯一的
      语法：属性名 数据类型 auto_increment,默认该字段的值从1开始自增。
      举例：
      create table F( user_id int primary key auto_increment); 
      root@zytest 15:56>insert into F values('');           插入一条空的信息
      Query OK, 1 row affected, 1 warning (0.00 sec)
      root@zytest 15:56>select * from F;                值自动从1开始自增
      +---------+
      | user_id |
      +---------+
      |       1 | 
      +---------+
      1 row in set (0.01 sec)
      
      
    (6)、设置表的默认值 
         在创建表时，可以指定表中的字段的默认值，如果插入一条新的纪录时，没有给这个字段赋值，那么数据库会自动的给这个字段插入一个默认值，字段的默认值用default来设置。
        语法: 属性名 数据类型 default 默认值
      举例： 
      root@zytest 16:05>create table G(
      user_id int primary key auto_increment, 
      user_name varchar(20) default 'zero');
       
      root@zytest 16:05>insert into G values('','');  插入数据，应为ID为自增，值为空，user_name设置了默认值，所以也为空。
          
      
                                                            
5.4、修改表的方法
          
    (1)、修改表名
 
     语法：alter table 旧表名 rename 新表名；
       举例; 
      root@zytest 16:11>alter table A rename zyA;
      Query OK, 0 rows affected (0.02 sec)
   (2)、修改表的数据类型
      语法：alter table 表名 modify 属性名 数据类型;
      举例;
      root@zytest 16:15>alter table A modify user_name double;
      Query OK, 0 rows affected (0.18 sec)
   (3)、修改表的字段名称
        语法: alter table 表名 change 旧属性名  新属性名 新数据类型；
      root@zytest 16:15>alter table A change user_name user_zyname float;
      Query OK, 0 rows affected (0.10 sec)
   (4)、修改增加字段
      root@zytest 16:42>alter table A add age int(4) not null; 
      Query OK, 0 rows affected (0.13 sec)
      在表的第一个位置增加字段alter table 表名 ADD 属性名1  数据类型 [完整性约束条件] [FIRST |AFTER 属性名2]
      
 （5）增加没有约束条件的字段
      root@zytest 16:18>alter table A add phone varchar(20);
      Query OK, 0 rows affected (0.13 sec)
      
 （6）执行在那个位置插入新的字段，在phone后面增加
     
      root@zytest 16:46>alter table A add address varchar(30) not null after phone;
      Query OK, 0 rows affected (0.10 sec)
      Records: 0  Duplicates: 0  Warnings: 0
 （7 删除一个字段
      alter table 表名DROP 属性名；
          
 （8）更改表的存储引擎
        alter table表名 engine=存储引擎
      alter table A engine=MySIAM;
       
  (9)、删除表的外键约束
      alter table 表名drop foreign key 外键别名
          
          
   

第六章  索引 
                                                        
第六章 索引设计
                                                         
6.1、索引的含义和特点
     索引时什么，所以相当于字典里面的目录序表，比如查询一个“星”字，如果不按照拼音来找的话，那么我们需要把整个字典全部遍历查询一边。才能查到这个字，如果按照拼音来
   找的，那么只需要在几页音序表中查询。就可以通过音序就快速查到，这个字在字典的哪一页。
   在数据库中，索引是建立在表上面的，索引可以很大程度上提高数据库的查询，
   同时也提高了数据库的性能，
   不同的存储引擎定义了索引的最大长度和所索引的数量，所存储殷勤对每个表最少支持16个索引，索引的长度最少支持256字节。
   索引优点： 
         其优点可以提高数据的检索速度，针对于有依赖关系的子表和父表，在联合查询的时候可以提高查询速度。
   索引的缺点：
    创建和维护索引需要消耗时间，索引需要占用物理空间，每一个索引都需要占用一定的
    物理空间，大量的索引会影响插入数据，数据库系统会按照索引进行
    序，这样降低了插入数据的速度
                                                        
    解决办法
  ：在插入数据时，先临时删除表的索引，然后插入数据，数据插入完成后，再创建索引。
          
          
    6.2、索引的分类
      Mysql的索引类型有：普通索引，唯一性索引，全文索引，单列索引、多列索引
      和空间等，
      1.普通索引 ----all
      创建普通索引时，不附加任何限制条件，这类索引可以创建在任何数据类型上
      2.唯一索引----all
      使用unique参数可以设置唯一索引，在创建唯一索引时，限制该索引的值必须是唯一的。
      比如在student表中，user_name 字段设置为唯一索引的话，那么此值必须是唯一的。
      3.全文索引----MyISAM
      使用fulltext参数可以设置为全文索引，全文索引只能创建char  varchar或者--
      Text类型的字段上。只有MyISAM的存储引擎才支持此索
      4.单列索引----all
       在表中的单个字段上创建索引，单列索引只根据该字段进行索引。
      单列索引可以是、普通索引、也可以是唯一索引，还可以是全文索引。只要保证该索引
      只对应一个字段即可。
      5.多列索引----all
      多列索引是在表的多个字段上创建一个索引，该索引指向创建时对应的多个字段。可以通过这几个字段进行查询。但是使用了多列索引，只有查询这些字段中的第一个字段时才会被使用索引。比如： 在表中id、name和sex字段上建立一个多列索引，那么，只有查询条件使用了id 字段时多列索引才会被使用
      6.空间索引----MyISAM
      使用spatial参数可以设置为空间索引, 空间索引只能建立在空间数据类型上，
      目前只有使用MyISAM存储引擎才支持空间索引。而且此索引的字段值不能为空
     
                                                             
                                                                  
6.3、如何设计索引
          
      1.唯一索引的设置 
      唯一索引的值是唯一的，可以更快速的通过该索引可以确定某条记录，
      比如：身份证号码是唯一的，可以建立唯一索引，如果是名字的话，那么有 可能出现同名的状况。从而减低查询速度。
      2,为经常需要排序，分组和联合操作的字段建立索引
      例如 order by group by  distinct和union 
      3.为经常作为查询条件的字段建立索引 
      4.限制索引的数目
      5.尽量使用数据量少的索引
      6.删除不再使用和很少使用的索引
    的一些索引可能不在需要，DBA应该定期的找出这些索引，将它们删除，
      从而减少索引对更新操作的影响。
   7.                                                         
6.4、如何创建索引
          
        语法：
       [unique|fulltext|spatial] index |key
      [别名] (属性名1  [(长度)]  [ASC|DESC] )
      unique可选参数，代表唯一索引
      fulltext 可选参数，代表全文索引
      spatial 可选参数， 代表空间索引
      index 和key 用来指定字段为索引两者选择其一。
      别名  可选参数，给创建的索引取新的名称
       长度  可选参数，给索引执定长度，必须是字符类型的
      才可以指定长度。
      ASC升序，DESC降序
   7. 
7.   创建普通索引
      Mysql-> create table aatest(
      id int,
      name varchar(20),
      sex boolean,
      index(id));
      使用 index设置id为普通索引。
      Mysqlà show create table aatest\G;  查看一下表详细结构
      Mysqlàexplain  ASCselect * from aatest where id=1 \G; 查看索引是否被使用。
       
      建立唯一索
         唯一索引使用unique进行约束
      create table aatest2(
        id int unique,
        name varchar(20),
        unique index aatest_id(id ASC));
     
         创建全文索
       create table aatest3(
      id int,
      info varchar(20),
      fulltext index aatest3_info(info)
      )ENGINE=MyISAM;  全文索引只有MyISAM引擎支持。
          
          创建单列索引
        create table aatest4(
      id int,
      subject varchar(30),
      index aatest4_st(subject(10)));  subject(10)指定索引的长度
       
         创建多列索引
         多列索引，是在表上多个字段创建一个索引。
      create table aatest5(
      id int,
      name varchar(20),
      sex char(4),
      index aatest5_ns(name,sex));
   8. 
9.                                                         
.5、在以存在的表上创建索引

          
         语法：
      create [unique | fulltext | spatial ] index 索引名
      on  表名 (属性名 [(长度)] [ ASC | DESC]);
       
      alter table 表名 ADD [unique | fulltext | spatial ] index 索引名
       (属性名 [(长度)] [ ASC | DESC]);
       
          1创建普通索引
      create index zytest_id  on zytest(id);
      alter table zytest add index zytest_id(id);
          
        2.创建唯一索引
      create unique index zytest1_id on zytest1(id);
      alter table zytest1 add unique index zytest1_id(id);
       3.创建全文索引
      reate fulltext index zytest2_id on zytest2(info);
      alter table zytest2 add fulltext zytest_2(info);
       4.创建单列索引
       create index zytest3_addr on zytest3(address(4));
      alter table zytest3 add index zytest3_addr(address(4));
       5.创建多列索引
       create index zytest4_na on zytest4(name,address);
      alter table zytest4 add index zytest4_na(name,address);
                                                                  
6.6、如何删除索引                                             
             
       语法：drop index 索引名 ON 表名
        drop  index  id  on  zytest 
       
      Drop index索引别名 on 表名
          
          
          

第七章 触发器
                                                        
                                                                        
                                                                    
第七章 触发器
                                                                   
7.1、触发器的含义与作用
      触发器(trigger)是由事件来触发某个操作，主要是由insert update delete等事件来触发某种特定的条件，满足触发器的触发条件时，数据库就会执行触发器定义的程序语句，
     个触发器，每次增加一个学生的记录。就执行一次计算学生的总数量的操作   比如：当学生表当中增加了一个学生记录，学生的总数就必须同时改变。可以在这里创建一。
        这一可以保证每次增加学生后的记录统计一直保持最新。。
     
  8.  触发器触发的执行语句可以只有一个。也可能有多个。 
      语法： 
         create trigger 触发器名称  before|after 触发事件
      on 表名 for each row 执行语句
           berfore指触发事件之前执行的触发语句。
           Alter   表示在触发事件之后执行语句
           触发事件包括(insert update delete)等
           on 表名  在XXX表之上
           执行语句 指的是XXSQL语句和触发事件类型要对应
        
        
                                                                  
7.2、创建触发器
       1) 创建一个表alvin
      create table alvin(
           userid int(10),
          username varchar(20),
          old int(4),
      address varchar(30));
       
      (2) 创建一个表为trigger_time 用来存放触发后条件的结果
      create table trigger_time(
      zhixing_time time);
      Query OK, 0 rows affected (0.15 sec)
       
      (3)、创建只有单个执行语句的触发器
      create trigger alvin1 before insert 
      on alvin for each row
      insert into trigger_time values(now());
      Query OK, 0 rows affected (0.07 sec)
   8. 
      （4创建有多个执行语句的触发器
          
    create trigger  触发器 before|after  触发时间 
               on 表名  for  each row 
            begin   
                 执行语句列表
             end
                            
    
 8.   举例一、
      root@zytest 10:49>delimiter &&    #告诉MYSQL该命令段下面的内容在提示结束后再执行分析。默认是以分号(;)执行
      root@zytest 10:53>create trigger alvin3 after delete
          -> on alvin for each row
          -> begin
          -> insert into trigger_time values('21:01:01');
          -> insert into trigger_time values('22:01:01');
          -> end
          -> &&
      Query OK, 0 rows affected (0.05 sec)
      root@zytest 10:54>delimiter ;    #结束退出，注意分号要有空格
    
       root@zytest 10:57>select * from alvin;   
      +--------+-------------+------+----------+
      | userid | username    | old  | address  |
      +--------+-------------+------+----------+
      |    110 | zengxiaohua |   28 | tianxing |
      +--------+-------------+------+----------+
      1 row in set (0.00 sec)
       
      root@zytest 11:07>delete from alvin where userid='110';  #执行删除动作看看触发器是否成功
      Query OK, 1 row affected (0.05 sec)
       
      root@zytest 11:07>select * from trigger_time;    #:查看触发器的执行结果
      +--------------+
      | zhixing_time |
      +--------------+
      | 19:09:41     |
      | 21:01:01     |
      | 22:01:01     |
      +--------------+
      3 rows in set (0.00 sec)
       
        举例二、
       alvin1表存放了学生的信息。每次增加(insert)一个学生的信息。就触发一次统计。统计结果存入aac表里面；
       首先创建一个alvin1表结构
      create table alvin1(
      user_id int(10),
      username varchar(20),
      old tinyint(4),
      address varchar(30));
       
      create table aac(
      my_count int);
       然后开始创建一个触发器
      delimiter &&
      create trigger alvin123 before insert on
      alvin1 for each row begin
      declare ycount int(10);                 #:申明变量类型 
      set ycount=(select count(*) from alvin1);   #:给变量赋值
      insert into aac(my_count) values(ycount);  #:调用变量
      end &&
      delimiter ;
       
      root@zytest 16:24>insert into alvin1 values('1001','zhangsan','18','China'); 开始测试
      root@zytest 16:24>select * from aac;
          
      7.4 查看触发器 
       
      1) 查看所有触发器，提前要进入某库
      #: show triggers \G;
      
        在triggers 表中查看触发信息 
        
        
        use information_schema;
        select * from information_schema,trihhers\g;
        
     小技巧：所有触发器的信息都存在information_schema库中的triggers表里面，
      在使用select 查询单个触发器的时候。可以根据triggers表里面的字段名称
      Trigger_name字段进行查询。
      root@information_schema 11:24>select * from triggers where trigger_name='alvin1'\G;
          
        
        2) 删除触发器 
        
        drop trigger 触发器名  
        
                                                                删除alvin1触发器
      root@(none) 12:18>use zytest;
      Database changed
      root@zytest 12:18>drop trigger alvin1;
          
          
       
       
          

第八章 数据查询 语句
查询语句笔记
 语法：
 select 属性列表
 where 条件表达式
 group by 属性名1 HAVING条件表达式2
 order by 属性名2 asc|desc
 属性列表和属性名:要查询的字段名称
 where  表示指定查询条件
 group by 对指定的字段分组
 order by  对指定的字段进行排序
 


truncate table gongda; 直接清空表中的所有数据
 
secureCRT
1、在单表上查询所有数据
> select * from orders; *号代表查询所有



2、查询某个指定字段
> select cust_id,order_date from orders;

3、where 查询指定字段
>select cust_id,order_date from orders where cust_id=10001;

小于或者等于
select cust_id,order_date from orders where cust_id<=10003;



大于或者等于
> select cust_id,order_date from orders where cust_id>=10003;

大于
> select cust_id,order_date from orders where cust_id>10003;

小于
> select cust_id,order_date from orders where cust_id<10003;

不等于
> select cust_id,order_date from orders where cust_id != 10003;


排除掉
> select cust_id,order_date from orders where cust_id <> 10005;

指定范围
> select cust_id,order_date from orders where cust_id between 10001 and 10004;




指定集合
> select cust_id,order_date from orders where cust_id in(10001,10004); 



> select cust_id,order_date from orders where cust_id not in(10001,10004); 




匹配字符
> select cust_id,order_date from orders where cust_id like '10004';

> select cust_id,order_date from orders where cust_id not like '10004';


判断字符值空或者非空
> select * from vendors where vend_state is null;

> select * from vendors where vend_state is not null;





多条件查询
l> select * from orders where cust_id=10003 or cust_id=10004; 或

> select * from orders where cust_id>10003 and cust_id<10005; 与



去掉重复distinct
> select distinct cust_id  from orders;




对单个字段进行分组
> select * from student group by address;


使用group_concat将字段分组显出来
>select group_concat(name),address from student group by address;

练习题目:
(1)、对性别进行分组。分别显出名字
(2)、对学院进行分组。分别显出名字


having作用，指定查询条件,必须和group by一起使用
l> select sex,count(sex),group_concat(name) from student group by sex having sex='男';


group by 之后。想得到总和 with rollup
> select sex,count(sex),group_concat(name) from student group by sex with rollup;



#==============================================
集合函数
count() 统计记录的条数
select count(*) from vendors;
sum()   计算字段值的总和
select sum(vend_id)_ from vendors;

avg()   计算字段的平均值
select avg(vend_id)_ from vendors;

max()   查询字段的最大值
select max(vend_id)_ from vendors;

min()   查询字段的最小值
select min(vend_id)_ from vendors;

#==============================================
多表查询
(1)内链接
l> select cust_name,cust_address,order_date,order_num from customers a ,orders b where a.cust_id=b.cust_id;

练习题目：
要求利用内链接，得到customers,orders 

(1)
要求cust_name用户产生的订单号和日期。
cust_name,cust_address,cust_contact,order_date,order_num

(2)要求根据orders里面的订单号，查出在customers有那些用户.
order_num,order_date,cust_name
然后呢。根据用户进行分组。使用count计算。一个用户产生了几张订单？
select order_num,order_date,cust_name ,count(order_num) from orders a ,customers b where a.cust_id=b.cust_id group by cust_name;


(2)外链接
select 属性列表名
from 表名1 left | right join 表名2
on 表名1.属性名=表名2.属性名

左链接
可以查询表名1里面所有的数据，而表名2只能匹配记录
> select customers.cust_id,order_date,order_num from customers left join orders on customers.cust_id = orders.cust_id;

custmoers为主表，orders为匹配表，
通俗例子：orders为IT员工--->去customers财务部领取工资，进行匹配。


右链接
可以查询表名2里面所有的数,而表名1只能匹配记录
 select orders.cust_id,cust_name,cust_address from customers right join orders on orders.cust_id = customers.cust_id where orders.cust_id=10001;
orders为主表，customers为匹配表，
通俗例子：customers为IT员工--->去orders财务部领取工资，进行匹配。



练习题：
(1)使用左链接查询：vendors为主表  products匹配表.
prod_name prod_id vend_name vend_address 



(2)使用右链接查询：products为主表  vendors匹配表.
prod_name prod_id vend_name vend_address 


子查询
select * from customers where cust_id in(select cust_id from orders where cust_id=10003);



合并查询使用union 和union all
union 系统会将重复的去掉
> select vend_id from vendors union select vend_id from products;

union all恰恰相反。不去重复
> select vend_id from vendors union select vend_id from products;

为表和字段名称别名
select vend_id as userid from vendors 字段名称取别名
select vend_id from vendors a where a.vend_id='1001'; 为表取别名


正则表达式regexp
select * from vendors where vend_name regexp '^An';  以An开头的
select * from vendors where vend_city regexp 's$';  以s结尾的
select * from vendors where vend_city regexp '.d'; 任何字符后面包含d 
select * from vendors where vend_city regexp 'd.'; d后面包含的任意字符
select * from vendors where vend_city regexp '[London]'; 只要包含中括号里面任意一个字符的都会被显示出来
select * from vendors where vend_city regexp '[^Paris]'; 匹配除了Paris以外的所有字符，也就是说Paris将被过滤掉了。
select * from vendors where vend_state regexp 'MI|OH'; 匹配MI或者OH任意一个满足都会被显示出来。
select * from vendors where vend_state regexp 'M*'; 匹配以包含M后面的任何字符。
select * from vendors where vend_name regexp 'll+'; 代表多个字符前面或者后面的任何字符
select * from vendors where vend_city regexp 'd{1}'; 查询d出现过1次 或者N次





脚本需求：
1、主机之间需要建立信任关系
2、编写Mysql批量部署脚本，实现单机安装。实现多台服务器批量部署
3、使用nc命令测试端口号3306的端口号是否可以通信。
4、环境需求，至少需要3台机器，其中一台作为跳板机。












AUTO_MYSQL


第九章 UPDATE INSERT DELETE
主题： 数据插入(insert)、更新(update)、删除(delete)




(1)、数据插入insert
语法：insert into 表名 (字段名称1, 字段名称2,n,)values('值1'，'值2'，'值3')
举例说明:
create table gonda(
user_id int,
user_name varchar(15),
old int,
address varchar(50));
标准数据插入：
 insert into gonda(user_id,user_name,old,address)
values('111','alvin','2000','gongdahanshuiliyuan');
 非标准数据插入
 insert into gonda values('110','zhangsan','200','asdfdfsdf');
 
 同时插入多条数据
insert into gonda values('110','zhangsan','200','asdfdfsdf'),
('113','lisi','300','aaaaa'),
('114','lisi','300','aaaaa'),
('116','lisi','300','aaaaa'),
('118','lisi','300','aaaaa');


#==============================================================
(2)、更新数据update
语法：update 表名
set 字段名称1=值1,字段名称2=取值2.....
where 条件表达式(必须的)
举例说明：
更改单个值
update gonda set old=500 where user_id=110;
更改多个值
update gonda set user_name='glvin',old='1000' where user_id=111;

#==============================================================
(3)、删除数据delete
语法:delete from 表名 where 条件表达式
举例说明:
delete from gonda where user_id=110;

truncate table gongda; 清楚所有表。




脚本需求：
1、主机之间需要建立信任关系
2、编写Mysql批量部署脚本，实现单机安装。实现多台服务器批量部署
3、使用nc命令测试端口号3306的端口号是否可以通信。
4、环境需求，至少需要3台机器，其中一台作为跳板机。







 
 



第十章 函数 长度 合并  替换 大小写 IF CASE 
第10章 Mysql函数
								
一、字符串函数
(1)、计算字符串个数
语法:char_length(string)
例子：select char_length(user_name) from gonda;



(2)、计算字节长度
语法：length(string)
例子:select length(name) from student;



(3)、合并字符串函数
语法：concat(s1,s2) 默认不定义分割符号
举例：select concat(user_id,user_name) from gonda;

语法：concat_ws('-',s1,s2)定义分割符-之后，自动分割
举例：select concat_ws('-',user_id,user_name,old) from gonda;




(4)、替换字符串函数
语法：insert(s,2,4'fang') 将s字段中2后的4个字符，其中含了第二字符本身，用fang替换
举例：select order_num,insert(order_num,2,4,'aa') from orders;




(5)、将字符大小写转换

将小写转换成大写
语法：upper(s)
> select user_name,upper(user_name) from gonda;
语法：ucase(s)
> select user_name,ucase(user_name),lower(user_name) from gonda;

将大写转换称小写
语法：lower(s)
> select vend_state,lower(vend_state) from vendors;
语法：lcase(s)
> select vend_state,lcase(vend_state) from vendors;


#===========================================================
二、时间日期函数
(1）、返回当前日期
语法：curdate()
> select vend_name,curdate() from vendors;
(2)、返回当前日期和时间
语法:now()
> select vend_name,now() from vendors;

(3)、以Unix时间戳形式返回当前时间
语法：unix_timestam(s)
> select unix_timestamp(order_date) from orders;

(4)、将Unix时间戳转换称普通的时间格式
语法:from_unixtime(s)
> select from_unixtime(old) from gonda where user_id='2222';
#===========================================================
三、条件判断函数
(1)、if(expr,v1,v2)函数,
如果表达式expr成立，则返回v1,否则返回v2
> select order_num,order_date,if(order_num < 20005,'yes','no') from orders;

(2)、ifnull(s1,v2)函数
如果s1字段值不为空，就返回s1本身的值，否则返回v2的值
> select vend_id,ifnull(vend_state,'kong') from vendors;

(3)、case函数
语法：case when 表达式1 then '返回值1' when 表达式2 then '返回值2' else '返回值3' end 承载返回值模拟字段名称
> select cust_id,order_num,case when order_num >=20008 then 'yes' when cust_id >=10004 then 'yes2' else 'fail..' end myname from orders;
order_nu>=20008 或者cust_id >=10004 只要满足其中一个
满足前者则返回yes 满足后者显示yes2，否则就显示Fail..
如果两条都满足，则谁在最前面。优先级越高。




#===========================================================
四、系统信息函数
(1)、返回数据库版本号
version()
> select version();


(2)、返回服务器的连接数
connection_id()
> select connection_id();

(3)、返回当前数据库名
database()
> select database();

(4)、返回当前用户名
user()
> select user();
#==========================================================

五、加密函数
(1)、password()普通加密函数，此函数经常用来给mysql用户加密，在mysql里面用户是不能存储明文密码的.
> select password('gongda');

(2)、md5(string) 加密
> select md5('gongda');

(3)、encode(str,passd_str) 函数可可以使用字串pass_str 来加密str ，加密的结果是一个二进制数，
必须使用blob类型字段来保存它

mysql> insert into aa values(encode('myname','aa'));
Query OK, 1 row affected (0.00 sec)

(4)、decode(str,passd_str)函数来解密encode加密的内容
> select decode(encode('myname','aa'),'aa');





启动过程  
raid 
vim 



第十一章  存储过程 
                             第11章存储过程
一、基本语法
create procedure sp_name([proc_parameter[,...]])
[characteristic...]routine_body 
begin
end
sp_name 表示存储过程的名字
proc_parameter 存储过程参数例表[IN OUT INOUT]三个部分组成
其中IN 表示传进来的参数
其中OUT 表示传出去的参数
其中INOUT 表示传进来但最终传回的参数
routine_body 参数是SQL代码的内容(类似于触发器的for each row)
begin..end标志SQL代码的开始和结束



show variables like 'log_bin_trust_function_creators'

set global log_bin_trust_function_creators=1 &&

二、关于IN OUT INPOUT的举例说明
IN 参数例子
delimiter &&
create procedure alvin1(
in p_in int) #设置传入的参数类型和变量
begin
select p_in;  #查询第一次传入的参数值
set p_in=2;   #内部重新赋值给p_in变量
select p_in;  #赋值后在此查询
end &&
delimiter ;
set @test=1;  #开始传入参数1
call alvin1(@test); #调用存储过程，查看和对比输出的值




OUT 参数例子
delimiter &&
create procedure alvin2(
out p_out int)
begin
select p_out;
set p_out=2;
select p_out;
end &&
delimiter ;
set @p_out=1; 传入的参数1之后
call alvin2(@p_out)调用了之后。是否和IN一样都显示出来了？还是无效？

INOUT 参数例子
delimiter &&
create procedure alvin3(
inout p_inout int)
begin
select p_inout;
set p_inout=2;
select p_inout;
end &&
delimiter ;








三、举例说明
需求：创建一个存储过程，要求(返回mysql的版本，用户 所在的数据库、用户名称)
delimiter &&
create procedure zy1(
out getversion varchar(30),
out userversion varchar(30),
out userdatabase varchar(30),
out userconnection int)
reads sql data
begin
select version() into getversion;
select user() into userversion;
select database() into userdatabase;
select connection_id() into userconnection;
end &&
delimiter ;
>call zy1(@a,@b,@c,@d);
>select @a,@b,@c,@d;






需求二、统计vendors vend_id的数量总共有多少条?
out zycount int
select count(*) into zycount from vendors

#====================================================

                              存储函数
create function sp_name([func_parameter[,.....]]) 
return type
[characteristic...]routine_body
begin...end
其中sp_name 存储函数的名称
func_parameter 函数参数列表
return type 指定返回的参数类型
routine_body SQL代码内容
begin..end标志SQL代码的开始和结束
注意：与存储过程不同，
1、参数只有输入类型
2、向调用方返回结果值

举例:
delimiter &&
create function alvin11(
bb_id int)
returns varchar(20)
begin
return(select vend_name from vendors where vend_id=bb_id);
end &&
delimiter ;




练习需求:编写一个存储函数，要求出入cust_id的的时候返回order_date这个字段的值
表名为:orders


#====================================================
                     流程控制
(1）存储过程if语句的使用方法
delimiter &&
create procedure zyif(
in aa int,out bb int)
begin
if aa>20 then
set bb=30;
elseif aa=20
then
set bb=20;
else
set bb=15;
end if;
end &&
delimiter ;




(2)存储过程case用法
delimiter &&
create procedure zy_case(in aa int,inout bb int)
begin
case
when aa=20 then set bb=20;
when aa>20 and aa<=50 then set bb=30;
when aa>51 then set bb=60;
else set bb=15;
end case;
end &&
delimiter ;








(3)while 循环使用，插入1万数据
创建一个表
create table zybb
(user_id int,
name varchar(10));
Query OK, 0 rows affected (0.10 sec)

delimiter &&
create procedure zy_while()
begin
declare count int default 0;
while count < 100000 do
insert into zybb(user_id,name)values(count,'aaa1');
set count=count + 1;
end while;
end &&
delimiter ;
call zy_while() 调用存储过程

#===========================================================
(1)调用存储过程
call+存储过程名称+参数
如：call alvin_name(@p_inout)

(2)查询结果
select @p_inout

(3)查询存储过程
show procedure status\G;

(4)查询某个存储过程详细
show create procedure alvin1\G;

(5)查询存储函数
show function status\G;

(6)查询某个详细的存储函数
show create function alvin10\G;

(7)删除存储过程
drop procedure alvin1;

(8)删除存储函数
drop function alvin1;


当出现报错  this function has none 
需要设置 set global log_bin_trust_function_creators=1 ;

                 
          
          
          



第十二章 用户管理
                               
                               12章Mysql用户管理
                               
select  User,Host from    mysql.user;


prompt=\\u@\\d \\R:\\m>  #在Mysql命令显示主机名字

1、权表介绍 mysql库
(1)、user表 包括了3个字段:Host,User,Password 分别表示：主机名、用户名、密码
(2)、db表   包括了3个字段:Host,Db User，分别表示：主机名 数据库名 和用户名
(3)、host表 包括了2个字段:Host,Db，


2、创建和删除普用户
(1)、新建一个普通用户
语法：create user '用户名成'@'授权的IP地址' indentified by '用户的密码'
create user 'gongda'@'localhost' identified by 'test12356';





(2)、对用户进行授权
语法：grant 用户权限(查询,插入,更新) on 在那个数据库 to '用名名称'@'IP地址' identified by '用户密码'；
>grant select on zytest.zybb to 'gongda'@'localhost' identified by 'test123456'; 
>grant all on zytest to 'gongda'@'localhost' identified by 'test123456'; 
>flush privileges;




(3)、删除普通用户
语法：drop User username@'IP地址'
drop user 'gongda'@'localhost';





3、普通用户和root用户的密码管理

(1)、修改root用户密码
语法：mysqladmin -uusername -p password 'newpassword'
mysqladmin -uroot -p123456 password 'zytest123'

mysqladmin -uroot -p  password 123456   空密码 改密码


(2)、修改普通用户
# mysql -ugongda -paa123456
>set password=password('123456')  修改gongda普通用户的密码为123456



(3)、如果root用户密码丢失怎么办？
编辑my.cnf配置文件,加入skip-grant-tables 选项，然后重新启动MYSQL服务
>update mysql.user set password=password('123456') where User='root' and HOst='localhost'
>flush privileges; 权限刷新



(4)、创建一个远程超级用户
grant all privileges on *.* to admin@'%' identified by '123456' with grant option;


工具名称:SQLyog












习题
12.6、本章练习题目
(1)、创建一个普通用户名为“gonda1” 授权访问地址为”localhost”，
(2)、给这个gonda1用户授权能对test库有绝对访问权。其它的库无访问全，
(3)、修改gongda1这个用户的密码为 ‘gongda123456’
gongda1@(none) 14:46>set password=password('123');
(4)、修改root用户密码为’mynamehost

(5)、如果root超级数据库管理用户密码忘记了应该怎么办？请简述修复步骤。
(6)、常用的作为一名DBA你工作当中常用的SQL管理工具有哪些？
(7)、请使用SQLyog实现1-4题的需求.



(1)、创建一个名称为“gongda”的库，
(2)、在gongda库下面创建一个名字为student的表，
表结果如下：
user_id 整型、为主键、唯一、不为空
user_name 字符串类型 不为空
sex        枚举类型男和女
(3)、编写一个存储过程向student插入1万条数据，除掉
user_name 和sex 字段值可以保持一样，区分user_id的唯一值就OK，

create procedure xuesheng() begin  declare count int default 0; while count <10000 do  insert into student(user_id,user_name,sex)values(count,'aaa','man'); set count=count + 1; end while; end##

(4)、普通备份gongda下面的student表，

mysqldump -uroot -p123 gongda student >mystudent.sql

(5)、使用备份参数备份整个gongda库
mysqldump -uroot -p123 --databases gongda >mmystudent.sql

(6)、删除gongda下面的student表，把备份的sql重新恢复数据.
 mysql -uroot -p123  gongda  <mystudent.sql

(7)、删除gongda库。把5题备份的gongda库。重新导入，恢复数据.

 mysql -uroot -p123 <mmystudent.sql





1.查看配置文件: 

skip-networking #注释掉 因为它是屏蔽掉一切TCP/IP连接 

bind-address = 127.0.0.1 #它和上一个选项是异曲同工，要想远程连接，也得注释掉 

2.如果以上工作都做过还是出现： 


ERROR 2003 (HY000): Can't connect to MySQL server on '*.*.*.*' (113)，那就得考虑防火墙的问题了，关掉防火墙/etc/rc.d/init.d/iptables stop 






数据库 备份
                        数据库备份工具mysqldump



(1)、正式环境数据备份：                            
mysqldump -uroot -p123456 -h 10.0.0.254 -P 3306 zytest --single-transaction 
--flush-logs --routines --events --master-data=2 > zytest.sql

--single-transaction 选项在到出数据之前提交一个Begin SQL语句，Begin不会阻塞如何的程序和保证数据的一致性
--flush-logs 
开始到处之前刷新日志，

--routines
导出存储过程和自定义函数

--evets
导出事件

--master-data
将binlog的位置和文件名追加的输出到文件中.这选择将自动关闭--lock-tables(锁表)



(2)、本地使用root用户备份，备份某个库的某一个表
语法：mysqldump -uusername -ppassword dbname table1 table2 >bakcup.sql
举例：
mysqldump -uroot -pzy123 zytest vendors >vendors.sql

(3)、备份多个库，需要加上--databases
mysqldump -uroot -pzy123 --databases zytest feng >backup.sql


(4)、备份所有库
mysqldump -uroot -pzy123 --all-databases >all.sql


#================================================================
                              mysql命令可以进行数据恢复 
(1)、恢复数据库(如:zytest)
mysql -uroot -pzy123 <zytest.sql

(2)、恢复数据库的某个表 vendors
mysql -uroot -pzy123 zytest <vendors.sql

#================================================================
                              数据迁移
 所谓的是数据迁移。就是指原有的数据库系统迁移到另外一个业务系统上。
 数据迁移的原因是多种多样的，有可能是业务个业务变更，硬件升级或者平台切换，或者升级mysql数据库
 
 迁移的注意事项：
 (1)、相同的版本可以迁移
 (2)、注意版本所以使用的引擎
 (3)、低版本可以向高版本进行数据迁移，高版本一般兼容低版本的特性.
 (4)、高版本的数据不能向低版本进行迁移，会找成数据不兼容的情况
 (5)、迁移时请注意导出数据和备份数据，出现迁移失败时，立即启用预备方案，保证公司业务的正常运行
 (6)、在数据迁移正常来说，选择用户量最小的时候，大部分都在凌晨1-4点之间做数据迁移
 (7)、在数据迁移时，请先写好你的技术文档，在本地做完整的测试之后。方可尝试数据迁移
 (8)、DBA在迁移数据、需要相关人员联合支持(主程序员、测试人员、运维人员)等保证数据迁移后的安全和稳定行。


第十四章  日志
								第14章Mysql日志
								
	
	show variables like "log_%";				查看那些日志已经开启
	show master logs ; or  show binary logs ;查看当前存在的日志 
	
	要想确定第一个的二进制日志文件的文件名，输入下面的MySQL语句：
  show binlog events ; or \G    也可以 in 加文件名 显示
  
  show master status; 查看当前


				
一、mysql日志记录主要用于日常操作和信息的文件，在Mysql当中有4种日志
(1)、二进制日志：以二进制文件的形式记录所有对数据库执行更改的操作，但是不记录查询语句 
记录mysql变化，主从也通过二进制进行同步的。
输出文件名字：mysql-bin.000001 

如果每天都会生成大量的二进制日志，这些日志长时间不清理的话，将会对磁盘空间带来很大的浪费，所以定期清理日志是DBA维护mysql的一个重要工作

使用mysqlbinlog工具进行日志查看
mysqlbinlog mysql-bin.000002 -d test

(2)、错误日志：记录用户登录，记录查询的信息以及异常信息
它记录了MySQL数据库启动关闭信息，以及服务器运行过程中所发生的任何异常的错误信息
slave.err



(3)、慢查询日志:记录执行时间超过指定操作时间。那么就记录
 cat slave-slow.log
 
 慢查询日志里记录了执行时间超过long_query_time参数值的sql语句。慢查询日志可以有效的帮助我们发现实际应用中sql的性能问题，找出执行效率低下的sql语句。
 
 可以查询那些执行语句比较占用资源shou
 
(4)、通用查询日志:用户查询日志以及其它的操作，包括MYSQL启动、关闭，更新、查询等等。
alvin-bin
一般不开启 

二、日志分析
(1)二进制日志    :%!xxd
启动二进制日志 编辑my.cnf配置文件
log-bin=mysql-bin

(2)删除掉所有的二进制
reset master;     

(3)、删除某一个范围的二进制日志
purge master logs to 'mylog_0000021' 代表从000001删除到0000021

报错
root@(none) 09:37>purge master logs to 'mysql-bin.000006';
ERROR 1373 (HY000): Target log not found in binlog index
原因
mysql> show master logs;


(4)、根据创建时间来删除日志
purge master logs to '2013-5-14 16:00:00' 删除2013-5-14 16:00:00 以前的二进制日志

(5)、mysqlbinlog命令来进行数据恢复，利用日志恢复数据从小到大
mysqlbinlog mylog.000001 | mysql -uroot -pzy123
mysqlbinlog mylog.000002 | mysql -uroot -pzy123
mysqlbinlog mylog.000003 | mysql -uroot -pzy123
mysqlbinlog mylog.000004 | mysql -uroot -pzy123

(6)、暂停二进制功能
mysql->set sql_log_bin=0; 暂停
mysql->set sql_log_bin=1; 启动


三、错误日志分析
(1)错误日志默认是开启来的，一般错误日志成为:hostname.err
hostname代表主机名字
开启错误日志，编辑my.cnf
log-error=master.err

(2)删除错误日志
mysqladmin -u root -p flush-logs 系统会自动创建一个新的错误日志
通常情况下DBA不需要查看错误日志，但是在Mysql出现异常的时，DBA可以查询此日志来定位故障


四、通用查询日志
(1)默认情况下，功能日志是关闭的，通过my.cnf开启日志
log=acces.log   一般情况不开启   占用磁盘空间大。
用户所有的操作都记录到通用查询日志当中

(2)删除通用查询日志
删除源文件，然后重新生成新的
rm acces.log && mysqladmin -uroot -p flush-logs 

对源文件直接清空
echo > acces.log


五、慢查询日志
慢查询日志用来记录执行时间超过指定的时间时的查询语句
log-slow-queries=slow.log
long_query_time=n n默认代表10秒，可以自行设置

删除清空慢查询日志
两种方法：
删除源文件，然后重新生成新的
rm slow.log && mysqladmin -uroot -p flush-logs 

对源文件直接清空
echo > slow.log



show processlist; 


kill  "id";






本章练习题目:
(1)、简述Mysql有几种日志
四种日志   二进制日志  错误日志  慢查询日志    通用日志   
(2)、简述每种日志的功能

(3)、怎么开启二进制日志？有那几种方法？
/etc/my.cnf
 log-bin=mysql-bin

(4)、如何开启慢查询日志以及如何开启通用查询日志？
log-error=master.err   错误日志
log=acces.log  通用查询日志
log-slow-queries=slow.log  慢日志
long_query_time=n n默认代表10秒，可以自行设置


(5)、创建一个gongda库
然后在gongda库里面创建一个表sxkj的表，编写一个存储过程，向比表里面填充1万条数据，

(6)、暂停二禁止日志，将数据删除掉，在开启二进制日志，
mysql->set sql_log_bin=0; 暂停
mysql->set sql_log_bin=1; 启动

(7)、使用mysqlbinlog工具将数据回复回来。

show master logs;

mysqlbinlog mylog.000001 | mysql -uroot -pzy123
mysqlbinlog mylog.000002 | mysql -uroot -pzy123
mysqlbinlog mylog.000003 | mysql -uroot -pzy123
mysqlbinlog mylog.000004 | mysql -uroot -pzy123









二进制日志的应用
http://www.blogjava.net/dongbule/archive/2010/09/04/331050.html



mysql> show variables like "log_%";
 +---------------------------------+----------------+
 | Variable_name                   | Value          |
 +---------------------------------+----------------+
 | log_bin                         | ON             |
 | log_bin_trust_function_creators | OFF            |
 | log_error                       | .\ts17-113.err |
 | log_slave_updates               | OFF            |
 | log_slow_queries                | OFF            |
 | log_warnings                    | 1              |
 +---------------------------------+----------------+
  
 可以看到log_bin已经启用

http://www.cszhi.com/20120612/mysql-binlog.html

http://www.linuxidc.com/Linux/2011-10/45068.htm


http://blog.csdn.net/bopzhou/article/details/8330610

对mysqlbinlog 日志进行操作的总结包括启动，过期自动删除等；

 操作命令：
 show binlog events in 'binlog.000016' limit 10;
 reset master 删除所有的二进制日志
 flush logs  产生一个新的binlog日志文件
 
 show master logs; / show binary logs; 查看二进制文件列表和文件大小
 ./mysqlbinlog  --start-datetime="2012-05-21 15:30:00" --stop-datetime="2012-05-21  16:40:00" /var/mysql/binlog/binlog.000005 > a.log
 
 
 
 近段时间一直在研究mysql的日志系统,在网上看了N多mysql日志操作的文章，但都过于零乱，为了让自己以后不再搞忘，特作出以下总结：
 1.  以前我错误的认为mysql的日志可以恢复到任何时间的状态，其实并不是这样，这个恢复是有前提的，就是你至少得有一个从日志记录开始后的数据库备份，通 过日志恢复数据库实际上只是一个对以前操作的回放过程而已，不用想得太复杂，既然是回放你就得注意了，如果你执行了两次恢复那么就相当于是回放了两次，后 果如何你自己应该清楚了吧。[1:恢复前务必先备份数据.2:由于二进制文件多,并且需要恢复的数据跨度大,可以考虑将 日志文件合并在恢复.]
 2. 要想通过日志恢复数据库，在你的my.cnf文件里应该有如下的定义，log-bin=mysql-bin，这个是必须的.binlog-do-db=db_test,这个是指定哪些数据库需要日志，如果有多个数据库就每行一个，如果不指定的话默认就是所有数据库.
 [mysqld]
 log-bin=mysql-bin
 binlog-do-db=db_test
 binlog-do-db=db_test2
 3.删除二进制日志:
 a.mysql> system ls -ltr /var/lib/mysql/bintest*;
 mysql>reset master(清空所有的二进制日志文件)
 b.purge master logs to ‘bintest.000006′;(删除bintest.000006之前的二进制日志文件)
 c.purge master logs before ’2007-08-10 04:07:00′(删除该日期之前的日志)
 d.在my.cnf 配置文件中[mysqld]中添加:
 expire_logs_day=3设置日志的过期天数,过了指定的天数,会自动删除
 4.下面就是恢复操作了
 特别提示，mysql每次启动都会重新生成一个类似mysql-bin.000003的文件，如果你的mysql每天都要重新启动一次的话，这时候你就要特别注意不要选错日志文件了。
 (注意：下面有一些技巧，这些东西才是最宝贵的哟，普通的东东手册上都有，这可是我摸索出来的哟，别人我都不告诉他。
 技巧1 :
 在下面你将看到 mysqlbinlog –stop-date=”2005-04-20 9:59:59″  /var/log/mysql/mysql-bin.000001  | mysql -u root -pmypwd  类似的语句，但是它一次只能操作一个日志文件，如果你变通一下变成这样 mysqlbinlog –stop-date=”2005-04-20  9:59:59″/var/log/mysql/mysql-bin.0* |  mysql -u root -pmypwd 那么它基本上就会表示出的所有的日志文件了，这样可解决你忘记在哪一个日志文件中的问题，当然你也可以用这种写法更完美,mysqlbinlog –stop-date=”2005-04-20 9:59:59″/var/log/mysql/mysql-bin.[0-9]* | mysql -u root -pmypwd  ，看到[0-9]*这个东东了吧，它表示以数字开头的任何字符，方便吧！
 技巧2:
 你可以通过–one-database 参数选择性的恢复单个数据库，example在下面，爽吧。
 mysqlbinlog –stop-date=”2005-04-20 9:59:59″ /var/log/mysql/mysql-bin.000001  | mysql -u root -pmypwd–one-database db_test
 技巧3:
 如果你老人家已经使用过 /usr/local/mysql5/bin/mysqlbinlog –start-date=”2005-04-20 9:55:00″ /var/data/mysql5/mysql-bin.0* > /home/db/tt.sql 类似的语句将日志导成了ASCII文本文件，那么你就可以直接在phpmyadmin或者其它什么乱七糟八的的客户端里执行这个文件文件就行了[source  *.sql]，因为它本身就是一个标准的sql文件，比如想让文件里面的某些语句不执行，OK，it’s easy,找到它们删除即可，然后再放进去执行就OK滴啦！这个可是灰常灰常的爽哟。。。。。。
 技巧4:
 我来给大家讲一下，下面这条语句都做了什么
 mysqlbinlog –stop-date=”2005-04-20 9:59:59″ /var/log/mysql/mysql-bin.000001  | mysql -u root -pmypwd –one-database db_test
 这是把mysql-bin.000001这个二进制文件里的内容转换成ASCII文件(也就是sql语句)，直接通过管道操作符”|”传输给 mysql这个程序，然后过滤掉其它数据库的语句，只在db_test里执行。
 技巧5:
 着了，多打了一个技巧，现在暂时没内容，等以后再加吧！！！
 )
 下面部份摘录自网上。
 如果MySQL服务器启用了二进制日志，你可以使用mysqlbinlog工具来恢复从指定 的时间点开始 (例如，从你最后一次备份)直到现在或另一个指定的时间点的数据。关于启用二进制日志的信息，参见5.11.3节，“二进制日志”。对于  mysqlbinlog的详细信息，参见mysql手册8.6节，“mysqlbinlog：用于处理二进制日志文件的实用工具”。
 要想从二进制日志恢复数据，你需要知道当前二进制日志文件的路径和文件名。一般可以从选项文 件(即my.cnf or  my.ini，取决于你的系统)中找到路径。如果未包含在选项文件中，当服务器启动时，可以在命令行中以选项的形式给出。启用二进制日志的选项为–  log-bin。要想确定当前的二进制日志文件的文件名，输入下面的MySQL语句：
 SHOW BINLOG EVENTS G
 你还可以从命令行输入下面的内容：
 mysql –user=root -pmy_pwd -e ‘SHOW BINLOG EVENTS G’
 将密码my_pwd替换为服务器的root密码。
 1. 指定恢复时间
 对于MySQL  4.1.4，可以在mysqlbinlog语句中通过–start-date和–stop-date选项指定DATETIME格式的起止时间。举例说明， 假设在今天上午10:00(今天是2005年4月20日)，执行SQL语句来删除一个大表。要想恢复表和数据，你可以恢复前晚上的备份，并输入：
 mysqlbinlog –stop-date=”2005-04-20 9:59:59″ /var/log/mysql/mysql-bin.000001  | mysql -u root -pmypwd
 该命令将恢复截止到在–stop-date选项中以DATETIME格式给出的日期和时间的所有数据。如果你没有检测到几个小时后输入的错误的SQL语句，可能你想要恢复后面发生的活动。根据这些，你可以用起使日期和时间再次运行mysqlbinlog：
 mysqlbinlog –start-date=”2005-04-20 10:01:00″ /var/log/mysql/mysql-bin.000001  | mysql -u root -pmypwd
 在该行中，从上午10:01登录的SQL语句将运行。组合执行前夜的转储文件和mysqlbinlog的两行可以将所有数据恢复到上午10:00前一秒钟。你应检查日志以确保时间确切。下一节介绍如何实现。
 2. 指定恢复位置
 也可以不指定日期和时间，而使用mysqlbinlog的选项–start- position和–stop-position来指定日志位置。它们的作用与起止日选项相同，不同的是给出了从日志起的位置号。使用日志位置是更准确的 恢复方法，特别是当由于破坏性SQL语句同时发生许多事务的时候。要想确定位置号，可以运行mysqlbinlog寻找执行了不期望的事务的时间范围，但 应将结果重新指向文本文件以便进行检查。操作方法为：
 mysqlbinlog –start-date=”2005-04-20 9:55:00″ –stop-date=”2005-04-20 10:05:00″
 /var/log/mysql/mysql-bin.000001 > /tmp/mysql_restore.sql
 该命令将在/tmp目录创建小的文本文件，将显示执行了错误的SQL语句时的SQL语句。你 可以用文本编辑器打开该文件，寻找你不要想重复的语句。如果二进制日志中的位置号用于停止和继续恢复操作，应进行注释。用log_pos加一个数字来标记 位置。使用位置号恢复了以前的备份文件后，你应从命令行输入下面内容：
 mysqlbinlog –stop-position=”368312″ /var/log/mysql/mysql-bin.000001 | mysql -u root -pmypwd
 mysqlbinlog –start-position=”368315″ /var/log/mysql/mysql-bin.000001 | mysql -u root -pmypwd
 上面的第1行将恢复到停止位置为止的所有事务。下一行将恢复从给定的起始位置直到二进制日志结束的所有事务。因为mysqlbinlog的输出包括每个SQL语句记录之前的SET TIMESTAMP语句，恢复的数据和相关MySQL日志将反应事务执行的原时间


实例与数据库




数据建模 与MBR


集群 主从复制原理







LVS负载均衡器,  LB负载均衡
 
 Mysql 双机热备
 
 主从结构 



一、主从复制的工作原理
Mysql在Master与slave之间实现整个复制的过程由3个线程来完成的，其中两个线程(SQL线程和IO线程)在
Slave端，另外一个线程（IO）在Master端
  要实现Mysql的复制必须首先打开Master端的binary log(也就是二进制日志)否则无法实现.
 Mysql复制基本过程如下：
   (1)Slave上面的IO 线程链接上Master（向master端发起链接），并且请求指定日志文件的位置（或者从开始的日志之后的日志内容）
   (2)Master接收到来自Slave的IO线程请求后，（根据这个IO的请求信息，返回指定的位置和内容给slave端）通过负责复制的IO线程根据这个请求信息指定日志的位置后，把这个信息返回给Slave的IO线程(返回的信心当中除了日志所包含的信息外,还包括了Master端的二进制文件名称和 二进文件的位置)
   
   (3)Slave的IO线程接收到Master端的返回信息之后，将日志内容一次写入slave端的Relay log（中继日志）文件中，(mysql-relay-bin.xxx)中继日志当中，并且读取到Master端的bin-log文件和位置记录，
   记录到master-info文件当中，（以便下次同步的时候，告诉master,需要从那个为之开始获取日志后的内容）以便下一次能够清楚的告诉Master我需要从某个bin-log的哪个位置开始往后的内容，请发给我。
   
   (4)、Slave的SQL线程检测Relay log中心增加了内容后，马上解析Master二进制文件中的内容，并且执行里面的Query语句.（sql语句）
   
   
   
二、主从的环境
Master IP:10.0.0.201
Slave  IP:10.0.0.202


(1)在Master上操作
首先将bin-log日志打开
其次将server-id设置为1
将log-slave-updates给关闭掉

建立一个内部复制通信用户
grant replication slave on *.* to 'admin'@'10.0.0.202' identified by '123456';
flush privileges;


(2)在Slave上操作
首先将bin-log日志打开
其次将server-id设置为2

show master status\G;

将log-slave-updates打开
>stop slave;
>change master to  master_host='10.0.0.201', master_user='admin', master_password='123456', master_log_file='mysql-bin.000005', master_log_pos=578;
>start slave;


MYSQL 读写分离 
 Mysql高级集群-读写分离Amoeba

读写      数据同步               
Master-->Slave
                                                                    
一、环境介绍
Master-IP:10.0.0.201
Slave- IP:10.0.0.202
Amobea-IP:10.0.0.203

二、安装JDK
# mkdir /Amoeba
# tar -xvf jdk-7u40-linux-x64.tar.gz -C /Amoeba/
# vim /etc/profile
JAVA_HOME=/Amoeba/jdk1.7.0_40
export JAVA_HOME

PATH=$JAVA_HOME/bin:$PATH
export PATH

CLASSPATH=.:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar:$CLASSPATH
export CLASSPATH

# java -version
java version "1.7.0_40"
Java(TM) SE Runtime Environment (build 1.7.0_40-b43)
Java HotSpot(TM) 64-Bit Server VM (build 24.0-b56, mixed mode)

三、安装Amoeba
# unzip amoeba-mysql-1.3.1-BETA.zip -d /usr/local/amoeba/
# chmod -R +x /usr/local/amoeba/bin/


四、主从授权
>grant all privileges on *.* to 'amoeba'@'%' identified by 'amoeba123';
>flush privileges;


五、配置Amoeba文件
# cd /usr/local/amoeba/conf
# vim amoeba.xml
更改的第一个区域
#========================================================
 <!-- proxy server绑定的端口 -->
                <property name="port">9006</property>

                <!-- proxy server绑定的IP -->

                <property name="ipAddress">10.0.0.203</property>

                <!-- proxy server net IO Read thread size -->
                <property name="readThreadPoolSize">20</property>

                <!-- proxy server client process thread size -->
                <property name="clientSideThreadPoolSize">30</property>

                <!-- mysql server data packet process thread size -->
                <property name="serverSideThreadPoolSize">30</property>

                <!-- socket Send and receive BufferSize(unit:K)  -->
                <property name="netBufferSize">128</property>

                <!-- Enable/disable TCP_NODELAY (disable/enable Nagle's algorithm). -->
                <property name="tcpNoDelay">true</property>

                <!-- 对外验证的用户名 -->
                <property name="user">root</property>

                <!-- 对外验证的密码 -->

                <property name="password">123456</property>
                
更改的第二个区域《配置master端登录的信息》
#========================================================             
                <dbServer name="server1">

                        <!-- PoolableObjectFactory实现类 -->
                        <factoryConfig class="com.meidusa.amoeba.mysql.net.MysqlServerConnectionFactory">
                                <property name="manager">defaultManager</property>

                                <!-- 真实mysql数据库端口 -->
                                <property name="port">3306</property>

                                <!-- 真实mysql数据库IP -->
                                <property name="ipAddress">10.0.0.201</property>
                                <property name="schema">test</property>

                                <!-- 用于登陆mysql的用户名 -->
                                <property name="user">amobea</property>

                                <!-- 用于登陆mysql的密码 -->


                                <property name="password">amoeba123</property>


                        </factoryConfig>

                        <!-- ObjectPool实现类 -->
                        <poolConfig class="com.meidusa.amoeba.net.poolable.PoolableObjectPool">
                                <property name="maxActive">200</property>
                                <property name="maxIdle">200</property>
                                <property name="minIdle">10</property>
                                <property name="minEvictableIdleTimeMillis">600000</property>
                                <property name="timeBetweenEvictionRunsMillis">600000</property>
                                <property name="testOnBorrow">true</property>
                                <property name="testWhileIdle">true</property>
                        </poolConfig>
                </dbServer>
                
更改的第三个区域《配置slave端登录的信息》
#========================================================                  
                
<dbServer name="server2">

                        <!-- PoolableObjectFactory实现类 -->
                        <factoryConfig class="com.meidusa.amoeba.mysql.net.MysqlServerConnectionFactory">
                                <property name="manager">defaultManager</property>

                                <!-- 真实mysql数据库端口 -->
                                <property name="port">3306</property>

                                <!-- 真实mysql数据库IP -->
                                <property name="ipAddress">10.0.0.202</property>
                                <property name="schema">test</property>

                                <!-- 用于登陆mysql的用户名 -->
                                <property name="user">amobea</property>

                                <!-- 用于登陆mysql的密码 -->


                                <property name="password">amoeba123</property>


                        </factoryConfig>

                        <!-- ObjectPool实现类 -->
                        <poolConfig class="com.meidusa.amoeba.net.poolable.PoolableObjectPool">
                                <property name="maxActive">200</property>
                                <property name="maxIdle">200</property>
                                <property name="minIdle">10</property>
                                <property name="minEvictableIdleTimeMillis">600000</property>
                                <property name="timeBetweenEvictionRunsMillis">600000</property>
                                <property name="testOnBorrow">true</property>
                                <property name="testWhileIdle">true</property>
                        </poolConfig>
                </dbServer>                
               
更改的第四个区域《配置master和slave负载均衡池(pool)》
#=======================================================      
                <dbServer name="master" virtual="true">
                        <poolConfig class="com.meidusa.amoeba.server.MultipleServerPool">
                                <!-- 负载均衡参数 1=ROUNDROBIN , 2=WEIGHTBASED , 3=HA-->
                                <property name="loadbalance">1</property>

                                <!-- 参与该pool负载均衡的poolName列表以逗号分割 -->
                                <property name="poolNames">server1</property>
                        </poolConfig>
                </dbServer>


                <dbServer name="slave" virtual="true">
                        <poolConfig class="com.meidusa.amoeba.server.MultipleServerPool">
                                <!-- 负载均衡参数 1=ROUNDROBIN , 2=WEIGHTBASED , 3=HA-->
                                <property name="loadbalance">1</property>

                                <!-- 参与该pool负载均衡的poolName列表以逗号分割 -->
                                <property name="poolNames">server1,server2</property>
                        </poolConfig>
                </dbServer>
             
更改的第五个区域《配置master和slave读写分离》
#=======================================================                 
<queryRouter class="com.meidusa.amoeba.mysql.parser.MysqlQueryRouter">
                <property name="ruleConfig">${amoeba.home}/conf/rule.xml</property>
                <property name="functionConfig">${amoeba.home}/conf/functionMap.xml</property>
                <property name="ruleFunctionConfig">${amoeba.home}/conf/ruleFunctionMap.xml</property>
                <property name="LRUMapSize">1500</property>
                <!-- 配置master和slave读写分离 Begin-->
                <property name="defaultPool">master</property>
                <property name="writePool">master</property>
                <property name="readPool">slave</property>
               <!-- 配置master和slave读写分离  End-->
                <property name="needParse">true</property>
        </queryRouter>


六、修改Amoeba启动脚本
# vim /usr/local/amoeba/bin/amoeba
#DEFAULT_OPTS="-server -Xms256m -Xmx256m -Xss128k" 将此行注释掉，增加一下行
DEFAULT_OPTS="-server -Xms256m -Xmx256m -Xss256k"  增加这一行

七、启动Amoeba脚本
# nohup bash -x amoeba &
# cat nohup.out 日志是否成功？
# ps -ef | grep amoeba   查看进程是否启动成功
root      1896  1637  1 03:28 pts/3    00:00:06 /Amoeba/jdk1.7.0_40/bin/java -server -Xms256m -Xmx256m -Xss256k -Damoeba.home=/usr/local/amoeba -Dclassworlds.conf=/usr/local/amoeba/bin/amoeba.classworlds -classpath /usr/local/amoeba/lib/classworlds-1.0.jar org.codehaus.classworlds.Launcher


# mysql -uroot -p123456 -h 10.0.0.203 -P 9006






八、作业需求
XXX互联公司，因原有数据库架构随着公司业务的壮大，出现了数据业务层架构的瓶颈，现
要求公司DBA给出一个合理的解决方案。

(1)、请根据以上要求设计一个合理的DB架构出来。满足目前的业务发展和瓶颈，
(2)、数据架构要具备一定扩展，请把后期扩炸设计也一起设计出来，
(3)、以上2点，请给出标准的架构方案，以便领导审核.
(4)、在给出架构方案的同时，请写出标准的技术文档，一共运维做参考.








              
              


NET ～ 

moeba for mysql读写分离设置(三)  
                                             2013-02-26 18:18:06|  分类：             服务器架构             |  标签：freebsd  amoeba                        |举报           |字号 订阅         
                                                             1.8 访问权限和日志配置
1) 配置access_list.conf(设置哪些IP可以访问Amoeba服务)
# vi + $AMOEBA_HOME/conf/access_list.conf
--------------------------------------------------------------------------------- 
192.168.41.*:yes
--------------------------------------------------------------------------------- 
2) 配置log4j.xml(建议设置日志级别为warn或error)
# vi $AMOEBA_HOME/conf/log4j.xml
:%s/info/warn/cg
在可用性测试已经完成的情况下, 建议将log4j.xml 中关于日志输出level为info的全部设置成warn或者error级别. 日志是非常消耗系统性能的, 在没有必要的情况下可以不使用debug. 
 
1.9 启动Amoeba
# amoeba stop  (如果先前启动过, 则先停止)
amoeba server shutting down with port=64670
# amoeba start &
[1] 14028
log4j:WARN log4j config load completed from file:/usr/local/amoeba-mysql/conf/log4j.xml
2011-07-06 16:37:54,049 INFO  context.MysqlRuntimeContext - Amoeba for Mysql current versoin=5.1.45-mysql-amoeba-proxy-2.1.0-RC5
log4j:WARN ip access config load completed from file:/usr/local/amoeba-mysql/conf/access_list.conf
2011-07-06 16:37:54,319 INFO  net.ServerableConnectionManager - Amoeba for Mysql listening on 0.0.0.0/0.0.0.0:3306.
2011-07-06 16:37:54,322 INFO  net.ServerableConnectionManager - Amoeba Monitor Server listening on /127.0.0.1:58252.
# ps -ef | grep amoeba | grep -v grep
root     14028 11956  1 16:53 pts/4    00:00:00 /usr/java/jdk1.6.0_25/bin/java -server -Xms256m -Xmx256m -Xss128k -Damoeba.home=/usr/local/amoeba-mysql -Dclassworlds.conf=/usr/local/amoeba-mysql/bin/amoeba.classworlds -classpath /usr/local/amoeba-mysql/lib/classworlds-1.0.jar org.codehaus.classworlds.Launcher start
# netstat -ntulp |grep :8066
tcp        0      0 ::ffff:192.168.41.203:8066  :::*                        LISTEN      14028/java          
# tail -100f $AMOEBA_HOME/logs/root.log
# tail -100f $AMOEBA_HOME/logs/project.log
# tail -100f $AMOEBA_HOME/logs/net.log
 
1.10 客户端连接测试
1) 先停止Slave的复制进程
mysql> stop slave;
2) 连接Amoeba端口, 插入数据
# mysql -uu_test -piamwangnc -h192.168.41.203 -P8066 -Ddb_test
如 果提 示"ERROR 1000 (42S02): Access denied for user 'u_test'@'192.168.41.77:33770'(using password: YES)" 错误, 那么确信在access_list.conf配置文件里设置了IP可访问, 确信是使用在amoeba.xml里配置的user和 password登录的, 修改之并重启Amoeba.
mysql> insert into db_test.t_test values ('testB');
mysql> select * from db_test.t_test;
+-------+
| col   |
+-------+
| testA |
+-------+
如果查询不到上步新插入的数据, 说明连接到了Slave, 读写分离成功. 
3) 测试完毕后, 启动Slave的复制进程
mysql> start slave;
 
1.11 正式环境说明
提升Amoeba性能的几点: 
1, 在可用性测试已经完成的情况下, 建议将log4j.xml 中关于日志输出level为debug的全部设置成warn或者error级别. 日志是非常消耗系统性能的, 在没有必要的情况下可以不使用debug. 
2, 性能测试环境: Amoeba对cpu的要求比较高, 建议将Amoeba配置在多核/多cpu的机器上面. 
3, Amoeba多线程配置, 默认只有20～30个线程, 在多核/多cpu的情况下建议开大. 
4, Amoeba与数据库连接数配置: 在性能测试并且客户端并发量不大的情况下, 建议将Amoeba与数据库的连接数跟客户端与MySQL的并发连接数尽量相等, 这样保证一个客户端连接可以获得一个数据库连接. 
--End--


MYSQL 主从复制与读写分离

http://www.cnblogs.com/luckcs/articles/2543607.html



MySQL主从复制(Master-Slave)与读写分离(MySQL-Proxy)实践
Mysql作为目前世界上使用最广泛的免费数据库，相信所有从事系统运维的工程师都一定接触过。但在实际的生产环境中，由单台Mysql作为独立的数据库是完全不能满足实际需求的，无论是在安全性，高可用性以及高并发等各个方面。
因此，一般来说都是通过 主从复制（Master-Slave）的方式来同步数据，再通过读写分离（MySQL-Proxy）来提升数据库的并发负载能力 这样的方案来进行部署与实施的。
如下图所示：





下面是我在实际工作过程中所整理的笔记，在此分享出来，以供大家参考。
一、MySQL的安装与配置
具体的安装过程，建议参考我的这一篇文章：http://heylinux.com/archives/993.html
值得一提的是，我的安装过程都是源码包编译安装的，并且所有的配置与数据等都统一规划到了/opt/mysql目录中，因此在一台服务器上安装完成以后，可以将整个mysql目录打包，然后传到其它服务器上解包，便可立即使用。
二、MySQL主从复制
场景描述：
主数据库服务器：192.168.10.130，MySQL已经安装，并且无应用数据。
从数据库服务器：192.168.10.131，MySQL已经安装，并且无应用数据。
2.1 主服务器上进行的操作
启动mysql服务
/opt/mysql/init.d/mysql start
通过命令行登录管理MySQL服务器
/opt/mysql/bin/mysql -uroot -p'new-password'
授权给从数据库服务器192.168.10.131
mysql> GRANT REPLICATION SLAVE ON *.* to 'rep1'@'192.168.10.131' identified by ‘password’;
查询主数据库状态
Mysql> show master status;
+------------------+----------+--------------+------------------+
| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |
+------------------+----------+--------------+------------------+
| mysql-bin.000005 | 261 | | |
+------------------+----------+--------------+------------------+
记录下 FILE 及 Position 的值，在后面进行从服务器操作的时候需要用到。
2.2 配置从服务器
修改从服务器的配置文件/opt/mysql/etc/my.cnf
将 server-id = 1修改为 server-id = 10，并确保这个ID没有被别的MySQL服务所使用。
启动mysql服务
/opt/mysql/init.d/mysql start
通过命令行登录管理MySQL服务器
/opt/mysql/bin/mysql -uroot -p'new-password'
执行同步SQL语句
mysql> change master to
master_host=’192.168.10.130’,
master_user=’rep1’,
master_password=’password’,
master_log_file=’mysql-bin.000005’,
master_log_pos=261;
正确执行后启动Slave同步进程
mysql> start slave;
主从同步检查
mysql> show slave status\G
==============================================
**************** 1. row *******************
Slave_IO_State:
Master_Host: 192.168.10.130
Master_User: rep1
Master_Port: 3306
Connect_Retry: 60
Master_Log_File: mysql-bin.000005
Read_Master_Log_Pos: 415
Relay_Log_File: localhost-relay-bin.000008
Relay_Log_Pos: 561
Relay_Master_Log_File: mysql-bin.000005
Slave_IO_Running: YES
Slave_SQL_Running: YES
Replicate_Do_DB:
……………省略若干……………
Master_Server_Id: 1
1 row in set (0.01 sec)
==============================================
其中Slave_IO_Running 与 Slave_SQL_Running 的值都必须为YES，才表明状态正常。
如果主服务器已经存在应用数据，则在进行主从复制时，需要做以下处理：
(1)主数据库进行锁表操作，不让数据再进行写入动作
mysql> FLUSH TABLES WITH READ LOCK;
(2)查看主数据库状态
mysql> show master status;
(3)记录下 FILE 及 Position 的值。
将主服务器的数据文件（整个/opt/mysql/data目录）复制到从服务器，建议通过tar归档压缩后再传到从服务器解压。
(4)取消主数据库锁定
mysql> UNLOCK TABLES;
2.3 验证主从复制效果
主服务器上的操作
在主服务器上创建数据库first_db
mysql> create database first_db;
Query Ok, 1 row affected (0.01 sec)
在主服务器上创建表first_tb
mysql> create table first_tb(id int(3),name char(10));
Query Ok, 1 row affected (0.00 sec)
在主服务器上的表first_tb中插入记录
mysql> insert into first_tb values (001,’myself’);
Query Ok, 1 row affected (0.00 sec)
在从服务器上查看
mysql> show databases;
=============================
+--------------------+
| Database |
+--------------------+
| information_schema |
| first_db |
| mysql |
| performance_schema |
| test |
+--------------------+
5 rows in set (0.01 sec)
=============================
数据库first_db已经自动生成
mysql> use first_db
Database chaged
mysql> show tables;
=============================
+--------------------+
| Tables_in_first_db |
+--------------------+
| first_tb |
+--------------------+
1 row in set (0.02 sec)
=============================
数据库表first_tb也已经自动创建
mysql> select * from first_tb;
=============================
+------+------+
| id | name |
+------+------+
| 1 | myself |
+------+------+
1 rows in set (0.00 sec)
=============================
记录也已经存在
由此，整个MySQL主从复制的过程就完成了，接下来，我们进行MySQL读写分离的安装与配置。
三、MySQL读写分离
场景描述：
数据库Master主服务器：192.168.10.130
数据库Slave从服务器：192.168.10.131
MySQL-Proxy调度服务器：192.168.10.132
以下操作，均是在192.168.10.132即MySQL-Proxy调度服务器 上进行的。
3.1 MySQL的安装与配置
具体的安装过程与上文相同。
3.2 检查系统所需软件包
通过 rpm -qa | grep name 的方式验证以下软件包是否已全部安装。
gcc* gcc-c++* autoconf* automake* zlib* libxml* ncurses-devel* libmcrypt* libtool* flex* pkgconfig*
libevent* glib*
若缺少相关的软件包，可通过yum -y install方式在线安装，或直接从系统安装光盘中找到并通过rpm -ivh方式安装。
3.3 编译安装lua
MySQL-Proxy的读写分离主要是通过rw-splitting.lua脚本实现的，因此需要安装lua。
lua可通过以下方式获得
从http://www.lua.org/download.html下载源码包
从rpm.pbone.net搜索相关的rpm包
download.fedora.redhat.com/pub/fedora/epel/5/i386/lua-5.1.4-4.el5.i386.rpm
download.fedora.redhat.com/pub/fedora/epel/5/x86_64/lua-5.1.4-4.el5.x86_64.rpm
这里我们建议采用源码包进行安装
cd /opt/install
wget http://www.lua.org/ftp/lua-5.1.4.tar.gz
tar zvfx lua-5.1.4.tar.gz
cd lua-5.1.4
vi src/Makefile
在 CFLAGS= -O2 -Wall $(MYCFLAGS) 这一行记录里加上-fPIC，更改为 CFLAGS= -O2 -Wall -fPIC $(MYCFLAGS) 来避免编译过程中出现错误。
make linux
make install
cp etc/lua.pc /usr/lib/pkgconfig/
export PKG_CONFIG_PATH=$PKG_CONFIG_PATH:/usr/lib/pkgconfig
3.4 安装配置MySQL-Proxy
MySQL-Proxy可通过以下网址获得：
http://mysql.cdpa.nsysu.edu.tw/Downloads/MySQL-Proxy/
推荐采用已经编译好的二进制版本，因为采用源码包进行编译时，最新版的MySQL-Proxy对automake，glib以及libevent的版本都有很高的要求，而这些软件包都是系统的基础套件，不建议强行进行更新。
并且这些已经编译好的二进制版本在解压后都在统一的目录内，因此建议选择以下版本：
32位RHEL5平台：
http://mysql.cdpa.nsysu.edu.tw/Downloads/MySQL-Proxy/mysql-proxy-0.8.1-linux-rhel5-x86-32bit.tar.gz
64位RHEL5平台：
http://mysql.cdpa.nsysu.edu.tw/Downloads/MySQL-Proxy/mysql-proxy-0.8.1-linux-rhel5-x86-64bit.tar.gz
测试平台为RHEL5 32位，因此选择32位的软件包
wget http://mysql.cdpa.nsysu.edu.tw/Downloads/MySQL-Proxy/mysql-proxy-0.8.1-linux-rhel5-x86-32bit.tar.gz
tar xzvf mysql-proxy-0.8.1-linux-rhel5-x86-32bit.tar.gz
mv mysql-proxy-0.8.1-linux-rhel5-x86-32bit /opt/mysql-proxy
创建mysql-proxy服务管理脚本
mkdir /opt/mysql-proxy/init.d/
vim mysql-proxy





~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 01 || #!/bin/sh ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 02 || # ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 03 || # mysql-proxy This script starts and stops the mysql-proxy daemon ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 04 || # ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 05 || # chkconfig: - 78 30 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 06 || # processname: mysql-proxy ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 07 || # description: mysql-proxy is a proxy daemon to mysql ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 08 ||    ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 09 || # Source function library. ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 10 || . /etc/rc.d/init.d/functions ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 11 ||    ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 12 || #PROXY_PATH=/usr/local/bin ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 13 || PROXY_PATH=/opt/mysql-proxy/bin ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 14 ||    ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 15 || prog="mysql-proxy" ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 16 ||    ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 17 || # Source networking configuration. ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 18 || . /etc/sysconfig/network ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 19 ||    ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 20 || # Check that networking is up. ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 21 || [ ${NETWORKING} = "no" ] && exit 0 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 22 ||    ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 23 || # Set default mysql-proxy configuration. ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 24 || #PROXY_OPTIONS="--daemon" ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 25 || PROXY_OPTIONS="--admin-username=root  --admin-password=password  --proxy-read-only-backend-addresses=192.168.10.131:3306  --proxy-backend-addresses=192.168.10.130:3306   --admin-lua-script=/opt/mysql-proxy/lib/mysql-proxy/lua/admin.lua  --proxy-lua-script=/opt/mysql-proxy/scripts/rw-splitting.lua" ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 26 || PROXY_PID=/opt/mysql-proxy/run/mysql-proxy.pid ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 27 ||    ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 28 || # Source mysql-proxy configuration. ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 29 || if [ -f /etc/sysconfig/mysql-proxy ]; then ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 30 ||         . /etc/sysconfig/mysql-proxy ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 31 || fi ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 32 ||    ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 33 || PATH=$PATH:/usr/bin:/usr/local/bin:$PROXY_PATH ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 34 ||    ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 35 || # By default it's all good ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 36 || RETVAL=0 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 37 ||    ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 38 || # See how we were called. ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 39 || case "$1" in ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 40 ||   start) ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 41 ||         # Start daemon. ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 42 ||         echo -n $"Starting $prog: " ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 43 ||         $NICELEVEL $PROXY_PATH/mysql-proxy $PROXY_OPTIONS --daemon --pid-file=$PROXY_PID --user=mysql --log-level=warning --log-file=/opt/mysql-proxy/log/mysql-proxy.log ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 44 ||         RETVAL=$? ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 45 ||         echo ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 46 ||         if [ $RETVAL = 0 ]; then ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 47 ||                 touch /var/lock/subsys/mysql-proxy ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 48 ||         fi ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 49 ||        ;; ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 50 ||   stop) ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 51 ||         # Stop daemons. ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 52 ||         echo -n $"Stopping $prog: " ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 53 ||         killproc $prog ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 54 ||         RETVAL=$? ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 55 ||         echo ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 56 ||         if [ $RETVAL = 0 ]; then ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 57 ||                 rm -f /var/lock/subsys/mysql-proxy ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 58 ||                 rm -f $PROXY_PID ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 59 ||         fi ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 60 ||        ;; ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 61 ||   restart) ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 62 ||         $0 stop ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 63 ||         sleep 3 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 64 ||         $0 start ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 65 ||        ;; ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 66 ||   condrestart) ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 67 ||        [ -e /var/lock/subsys/mysql-proxy ] && $0 restart ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 68 ||       ;; ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 69 ||   status) ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 70 ||         status mysql-proxy ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 71 ||         RETVAL=$? ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 72 ||        ;; ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 73 ||   *) ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 74 ||         echo "Usage: $0 {start|stop|restart|status|condrestart}" ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 75 ||         RETVAL=1 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 76 ||        ;; ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 77 || esac ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 78 ||    ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
|| 点击这里 || 点击这里 ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 79 || exit $RETVAL ||
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~




脚本参数详解：
==============================================
PROXY_PATH=/opt/mysql-proxy/bin //定义mysql-proxy服务二进制文件路径
PROXY_OPTIONS="--admin-username=root \ //定义内部管理服务器账号
--admin-password=password \ //定义内部管理服务器密码
--proxy-read-only-backend-addresses=192.168.10.131:3306 \ //定义后端只读从服务器地址
--proxy-backend-addresses=192.168.10.130:3306 \ //定义后端主服务器地址
--admin-lua-script=/opt/mysql-proxy/lib/mysql-proxy/lua/admin.lua \ //定义lua管理脚本路径
--proxy-lua-script=/opt/mysql-proxy/scripts/rw-splitting.lua" \ //定义lua读写分离脚本路径
PROXY_PID=/opt/mysql-proxy/run/mysql-proxy.pid //定义mysql-proxy PID文件路径
$NICELEVEL $PROXY_PATH/mysql-proxy $PROXY_OPTIONS \
--daemon \ //定义以守护进程模式启动
--keepalive \ //使进程在异常关闭后能够自动恢复
--pid-file=$PROXY_PID \ //定义mysql-proxy PID文件路径
--user=mysql \ //以mysql用户身份启动服务
--log-level=warning \ //定义log日志级别，由高到低分别有(error|warning|info|message|debug)
--log-file=/opt/mysql-proxy/log/mysql-proxy.log //定义log日志文件路径
==============================================
cp mysql-proxy /opt/mysql-proxy/init.d/
chmod +x /opt/mysql-proxy/init.d/mysql-proxy
mkdir /opt/mysql-proxy/run
mkdir /opt/mysql-proxy/log
mkdir /opt/mysql-proxy/scripts
配置并使用rw-splitting.lua读写分离脚本
最新的脚本我们可以从最新的mysql-proxy源码包中获取
cd /opt/install
wget http://mysql.cdpa.nsysu.edu.tw/Downloads/MySQL-Proxy/mysql-proxy-0.8.1.tar.gz
tar xzvf mysql-proxy-0.8.1.tar.gz
cd mysql-proxy-0.8.1
cp lib/rw-splitting.lua /opt/mysql-proxy/scripts
修改读写分离脚本rw-splitting.lua
修改默认连接，进行快速测试，不修改的话要达到连接数为4时才启用读写分离
vim /opt/mysql-proxy/scripts/rw-splitting.lua
=============================
-- connection pool
if not proxy.global.config.rwsplit then
proxy.global.config.rwsplit = {
min_idle_connections = 1, //默认为4
max_idle_connections = 1, //默认为8
is_debug = false
}
end
=============================
修改完成后，启动mysql-proxy
/opt/mysql-proxy/init.d/mysql-proxy start
3.5 测试读写分离效果
创建用于读写分离的数据库连接用户
登陆主数据库服务器192.168.10.130，通过命令行登录管理MySQL服务器
/opt/mysql/bin/mysql -uroot -p'new-password'
mysql> GRANT ALL ON *.* TO 'proxy1'@'192.168.10.132' IDENTIFIED BY 'password';
由于我们配置了主从复制功能，因此从数据库服务器192.168.10.131上已经同步了此操作。
为了清晰的看到读写分离的效果，需要暂时关闭MySQL主从复制功能
登陆从数据库服务器192.168.10.131，通过命令行登录管理MySQL服务器
/opt/mysql/bin/mysql -uroot -p'new-password'
关闭Slave同步进程
mysql> stop slave;
Query OK, 0 rows affected (0.00 sec)
连接MySQL-Proxy
/opt/mysql/bin/mysql -uproxy1 -p'password' -P4040 -h192.168.10.132
登陆成功后，在first_db数据的first_tb表中插入两条记录
mysql> use first_db;
Database changed
mysql> insert into first_tb values (007,’first’);
Query Ok, 1 row affected (0.00 sec)
mysql> insert into first_tb values (110,’second’);
Query Ok, 1 row affected (0.00 sec)
查询记录
mysql> select * from first_tb;
=============================
+------+------+
| id | name |
+------+------+
| 1 | myself |
+------+------+
1 rows in set (0.00 sec)
=============================
通过读操作并没有看到新记录
mysql> quit
退出MySQL-Proxy
下面，分别登陆到主从数据库服务器，对比记录信息
首先，检查主数据库服务器
mysql> select * from first_tb;
=============================
+------+------+
| id | name |
+------+------+
| 1 | myself |
+------+------+
| 007 | first |
+------+------+
| 110 | second |
+------+------+
3 rows in set (0.00 sec)
=============================
两条新记录都已经存在
然后，检查从数据库服务器
mysql> select * from first_tb;
=============================
+------+------+
| id | name |
+------+------+
| 1 | myself |
+------+------+
1 rows in set (0.00 sec)
=============================
没有新记录存在
由此验证，我们已经实现了MySQL读写分离，目前所有的写操作都全部在Master主服务器上，用来避免数据的不同步；
另外，所有的读操作都分摊给了其它各个Slave从服务器上，用来分担数据库压力。
经验分享：
1.当MySQL主从复制在 show slave status\G  时出现Slave_IO_Running或Slave_SQL_Running 的值不为YES时，需要首先通过 stop slave  来停止从服务器，然后再执行一次本文 2.1与2.2  章节中的步骤即可恢复，但如果想尽可能的同步更多的数据，可以在Slave上将master_log_pos节点的值在之前同步失效的值的基础上增大一 些，然后反复测试，直到同步OK。因为MySQL主从复制的原理其实就是从服务器读取主服务器的binlog，然后根据binlog的记录来更新数据库。
2.MySQL-Proxy的rw-splitting.lua脚本在网上有很多版本，但是最准确无误的版本仍然是源码包中所附带的lib/rw-splitting.lua脚本，如果有lua脚本编程基础的话，可以在这个脚本的基础上再进行优化；
3.MySQL-Proxy实际上非常不稳定，在高并发或有错误连接的情况下，进程很容易自动关闭，因此打开--keepalive参数让进程自动 恢复是个比较好的办法，但还是不能从根本上解决问题，因此通常最稳妥的做法是在每个从服务器上安装一个MySQL-Proxy供自身使用，虽然比较低效但 却能保证稳定性；
4.一主多从的架构并不是最好的架构，通常比较优的做法是通过程序代码和中间件等方面，来规划，比如设置对表数据的自增id值差异增长等方式来实现两个或多个主服务器，但一定要注意保证好这些主服务器数据的完整性，否则效果会比多个一主多从的架构还要差；
5.MySQL-Cluster 的稳定性也不是太好；
6.Amoeba for MySQL 是一款优秀的中间件软件，同样可以实现读写分离，负载均衡等功能，并且稳定性要大大超过MySQL-Proxy，建议大家用来替代MySQL-Proxy，甚至MySQL-Cluster



MYSQL的分库分区分表
mysql知识扩展之分库分表 
http://www.2cto.com/database/201209/153266.ht

MySQL互联网Oracle企业应用数据结构 .数据库的复制能解决访问问题，并不能解决大规模的并发写入问题，要解决这个问题就要考虑mysql数据切分了  www.2cto.com 


数据切分，顾名思义，就是数据分散，将一台主机上的数据分摊到多台，减轻单台主机的负载压力，有两种切分方式，一种是分库，即按照业务模块分多个库，每个库中的表不一样，还有一种就是分表，按照一定的业务规则或者逻辑将数据拆分到不同的主机上，每个主机上的表是一样的，这个有点类似于Oracle的表分区。

分库又叫垂直分区，这种方式实现起来比较简单，重要的是对业务要细化，分库时候要想清楚各个模块业务之间的交互情况，避免将来写程序时出现过多的跨库操作。


分表又叫水平分区，这种方式实现起来就比垂直分区复杂些，但是它能解决垂直分区所不能解决的问题，即单张表的访问及写入很频繁，这时候就可以根据一定的业务规则（PS:如互联网BBS论坛的会员等级概念：根据会员等级来分表）来分表，这样就能减轻单表压力，并且还能解决各个模块的之间的频繁交互问题。

分库的优点是：实现简单，库与库之间界限分明，便于维护，缺点是不利于频繁跨库操作，单表数据量大的问题解决不了。


分表的优点是：能解决分库的不足点，但是缺点却恰恰是分库的优点，分表实现起来比较复杂，特别是分表规则的划分，程序的编写，以及后期的数据库拆分移植维护。

实际应用中，一般互联网企业的路线都是先分库再分表，两者结合使用，取长补短，这样发挥了mysql扩展的最大优势，但是缺点是架构很大，很复杂，应用程序的编写也比较复杂。


以上是mysql的数据切分的一些概念，数据切完了，现在要做的是怎么样在整合起来以便于外界访问，因为程序访问的入口永远只有一个，现在比较常用的解决方案是通过中间代理层来统一管控所有数据源。

常用的代理层方案：
1.mysql proxy类似于连接池，所有连接通过它进行转发。
2.Amoeba是一个开发代理层的框架，有对应版本Amoeba for mysql,对于数据切分规则，连接数控制，以及读写分离路由支持较好。
3. HiveDB仅支持水平切分，底层由hibernate shards实现。
4. 其他  www.2cto.com  HSCALE,Spock Proxy(ROR),Pyshards(Python)


最后值得注意的是mysql分库分表的缺点： 
 缺少好的分布式事务解决方案，目前仅有Innodb提供解决方案，性能值得商榷。 
 缺少类似于DBLink的跨节点SQL解决方案，Federated提供支持了，但是还是简单的支持，对于表结构的变化就不能为力。
 这些缺点只能通过应用程序层来解决，不过话说回来，如果所有缺点都解决了，Oracle也不会卖那么贵了。


WWW
热点数据存储在缓存中

光纤模块  
mysql 数据容灾

MYSQL NDB
4.2、环境描述
一台 10.0.0.201 SQL节点、管理节点
一台 10.0.0.202 做一个数据节点
一台 10.0.0.203做一个数据节点

4.3、安装Mysql_custter (A(管理端可安装可不安装)B（1）C（1）)
在MGM管理节点、SQL节点、NDB节点执行同一操作
#:groupadd mysql
#: useradd mysql -g mysql -s /sbin/nologin
#: tar –xvf mysql-cluster-gpl-7.1.15-linux-x86_64-glibc23.tar.gz 
#:mv mysql-cluster-gpl-7.1.15-linux-x86_64-glibc23 /usr/local/mysql_cluster
#:vim /etc/profile
MYSQL_CLUSTER=/usr/local/mysql_cluster/bin
PATH=$PATH:$HOME/bin:$MYSQL_CLUSTER
export PATH
#: source /etc/profile


4.4、安装MGM管理节点 （A  管理端）
#:mkdir -p /opt/mgm/logs
#:mkdir /opt/conf
#:vim /opt/conf/config.ini
# Options affecting ndbd processes on all home/data nodes:
[ndbd default]
NoOfReplicas=2   #每个数据节点的镜像数量
DataMemory=200M  #每个数据节点中给数据分配的内存
IndexMemory=18M  #每个数据节点中给索引分配的内存
MaxNoOfAttributes=999999
MaxNoOfConcurrentTransactions=10240
LogLevelStatistic=15
LogLevelCheckpoint=15
LogLevelConnection=15
LogLevelError=15
LogLevelInfo=15
[ndb_mgmd]
NodeId=1
Hostname=10.0.0.201
Datadir=/opt/mgm/logs
LogDestination=FILE:filename=ndb_1_cluster.log,maxsize=10000000,maxfiles=6
ArbitrationRank=0
[ndbd]
NodeId=10
Hostname=10.0.0.202
Datadir=/opt/db2/data #管理节点数据(日志)目录
backupdatadir=/opt/db2/databak #管理节点数据(日志)目录的备份
[ndbd]
NodeId=11
Hostname=10.0.0.203
Datadir=/opt/db3/data  #管理节点数据(日志)目录
backupdatadir=/opt/db3/databak #管理节点数据(日志)目录的备份
[mysqld]
NodeId=20
[api]
[api]
[api]
[api]
[api]
启动管理节点：ndb_mgmd -f /opt/conf/config.ini --configdir=/opt/conf/



4.5、安装NDB管理节点 --B
在202上    
#:mkdir -p /opt/db2/data && mkdir /opt/db2/databak
#:mkdir /opt/conf
#:vim /opt/conf/my.cnf
[mysqld]
ndbcluster
ndb-connectstring=10.0.0.201
[mysql_cluster]
ndb-connectstring=10.0.0.201

在203上              --C
#:mkdir -p /opt/db3/data && mkdir /opt/db3/databak
#:mkdir /opt/conf
#:vim /opt/conf/my.cnf
[mysqld]
ndbcluster
ndb-connectstring=10.0.0.201
[mysql_cluster]
ndb-connectstring=10.0.0.201
启动NDB节点
安装后第一次启动数据节点时要加上--initial参数，其它时候不要加，除非是在备份、恢复
配置变化后重启时

#: ndbd --defaults-file=/opt/conf/my.cnf --initial
4.6、安装SQL节点 （B，C 端）
#:groupadd mysql
#: useradd mysql –g mysql –s /sbin/nologin
#: mkdir -p /dbdata/data && chown mysql:mysql /dbdata/data
#:cp /usr/local/mysql_cluster/support-files/mysql.server /etc/init.d/mysql

#:vim /etc/init.d/mysql
basedir=/usr/local/mysql_cluster
datadir=/dbdata/data
#:vim /usr/local/mysql_cluster/my.cnf
# Options for mysqld process:
[mysqld]
max_connections=200000
datadir=/dbdata/data/
log-error=/var/log/mysqld.log
port=3307
socket=/tmp/mysql.sock
character-set-server=utf8
default-storage-engine=ndbcluster
server-id=20
ndbcluster
# run NDB storage engine
ndb-connectstring=10.0.0.201
ndb-force-send=1
ndb-use-exact-count=0
ndb-extra-logging=1
ndb-autoincrement-prefetch-sz=512
#engine-condition-pushdown=1
ndb-cluster-connection-pool=1

key_buffer_size=16M
max_allowed_packet=10M
sort_buffer_size=256K
read_buffer_size=128K
read_rnd_buffer_size=256K
#table_lock_wait_timeout=16
memlock
sysdate_is_now
thread-cache-size=512
table-open_cache=512
max_prepared_stmt_count=24576
lower-case-table-names=0

# Timeout
interactive_timeout=43200
wait_timeout=43200
connect_timeout=60
skip-name-resolve
[ndbd]
connect-string=10.0.0.202
[ndbd_mgm]
connect-string=10.0.0.201
[mysql_cluster]
ndb-connectstring=10.0.0.201
# location of management server 
#：初始化
#cd /usr/local/mysql_cluster/scripts/
#./mysql_install_db --user=mysql --basedir=/usr/local/mysql_cluster/ --datadir=/dbdata/data/
常见报错：
Installing MySQL system tables.../usr/local/mysql_cluster//bin/mysqld: error while  
loading shared libraries: libaio.so.1: cannot open shared object file: No such file  
or directory
解决办法：#: yum -y install libaio
启动SQL节点
#:/etc/init.d/mysqld start
如果SQL启动失败。请保持虚拟机或者真实机的内存至少500M以上


4.7、测试与常见问题
启动顺序
MGM-->NDB-->SQL
关闭顺序
关闭
SQL-->MGM (NDB)
当关闭掉MGM后。NDB也会停掉

关闭MGM
ndb_mgm -e shutdown
测试：
ndb_mgm -e show





NDB









MYSQL 主从复制验证工具
5.2、Mysql 主从同步验证工具
(1)、pt-table-checksum 工具名称

(2)、安装pt-table-checksum
#:wget www.percona.com/downloads/percona-toolkit/2.2.2/percona-toolkit-2.2.2.tar.gz
#:tar -xvf percona-toolkit-2.2.2.tar.gz
#:perl Makefile.PL 
Can't locate ExtUtils/MakeMaker.pm in @INC (@INC contains: /usr/local/lib/perl5 /usr/local/share/perl5 /usr/lib/perl5/vendor_perl /usr/share/perl5/vendor_perl /usr/lib/perl5 /usr/share/perl5 .) at Makefile.PL line 1.
BEGIN failed--compilation aborted at Makefile.PL line 1.

解决方法        yum -y install perl-devel perl-ExtUtils-Embed       


# make && make install

(3)、授权
GRANT update,insert,delete,SELECT, PROCESS, SUPER, REPLICATION SLAVE ON *.* to 'tugeadmin'@'192.168.100.206' identified by 'peshome0716';
创建一个表
CREATE TABLE checksums (
   db             char(64)     NOT NULL,
   tbl            char(64)     NOT NULL,
   chunk          int          NOT NULL,
   chunk_time     float            NULL,
   chunk_index    varchar(200)     NULL,
   lower_boundary text             NULL,
   upper_boundary text             NULL,
   this_crc       char(40)     NOT NULL,
   this_cnt       int          NOT NULL,
   master_crc     char(40)         NULL,
   master_cnt     int              NULL,
   ts             timestamp    NOT NULL,
   PRIMARY KEY (db, tbl, chunk),
   INDEX ts_db_tbl (ts, db, tbl)
) ENGINE=InnoDB;

(4)、开始验证
pt-table-checksum  --nocheck-replication-filters --databases=tuge --replicate=tuge.checksums --create-replicate-table -h192.168.100.206  --port 3306  -utugeadmin -ppeshome0716 --set-vars innodb_lock_wait_timeout=120 --no-check-binlog-format

(5)、验证说明
--nocheck-replication-filters ：不检查复制过滤器，建议启用。后面可以用--databases来指定需要检查的数据库。
--no-check-binlog-format      : 不检查复制的binlog模式，要是binlog模式是ROW，则会报错。
--replicate-check-only :只显示不同步的信息。
--replicate=   ：把checksum的信息写入到指定表中，建议直接写到被检查的数据库当中,(这里写入了tuge库的checksums) 如果没有checksums库.需要手工创建一个.每次监测完成之后干掉它.
这个库表可以随意指定.个人建议把它,放到test 里面去.在test里面建立一个checksums表.  --replicate=test.checksums 
--databases=   ：指定需要被检查的数据库，多个则用逗号隔开。
--tables=      ：指定需要被检查的表，多个用逗号隔开
h=127.0.0.1    ：Master的地址
u=root         ：用户名
p=123456       ：密码
P=3306         ：端口

yum install perl-DBD-MySQL

yum install perl-DBI -y

yum  install -y perl-Time-HiRes


(6)、常见出错误
常见错误:
--set-vars innodb_lock_wait_timeout=120
使用timeout跳过这个错误提示.


5.3、Mysql脚本。
Mysql 主从复制监控脚本，
监控IO和SQL线程。如果问题。发送邮件报警。

5.4、Mysql备份脚本
要求备份所有的库，要求打成压缩包，包名要带年月日时间。
源文件或者源目录，在打完压缩包之后要求删除掉。
tar 带bzip2压缩.计划任务是凌晨1：30执行。成功后要求发送邮件到你的QQ邮箱。
邮件内容。要包含压缩的文件名称是否成功？以及大小？



http://bbs.chinaunix.net/thread-872804-1-1.html








MYSQL数据业务垂直+水平分割+主从复制读写分离
http://www.it165.net/database/html/201405/6451.html

MYSQL 水平+垂直分割
                                        第6章企业实战(垂直+水平切割)



ok，我们第5章讲到垂直切割，如果这个垂直切割不满足企业需求怎么办？
我们需要对架构进行进一步的分析和优化，让水平切割来解决这一问题,
   所有水平切割就是根据USER的ID范围值进划分，比如这里去莫 % 2，最终得到的结果只有0和1
根据0 和1 定位到不同SERVER 上去。此范围使用与中小型DB架构，

项目实战需求说明：
总注册用户数量为500万
User_DB 存储用户基本信息
Blog_DB 存储了博客文章
Other_DB 存储了其它业务

经过垂直切割后份3个DB分割到不同得到服务器上面，然后使用水平切割将DB用户量分割开来。

User_DB1 承载250万用户,取莫运算值为1 % 2 取莫   只实验这一部分
User_DB2 承载250万用户,取莫运算值为0 % 2 取莫   只实验这一部分

Blog_DB1 承载250万用户,取莫运算值为1 % 2 取莫
Blog_DB2 承载250万用户,取莫运算值为0 % 2 取莫

Other_DB1 承载250万用户,取莫运算值为1 % 2 取莫
Other_DB2 承载250万用户,取莫运算值为0 % 2 取莫


一、环境描述
(1) User_DB1 10.0.0.201
(2) User_DB2 10.0.0.202
(3）Amoeba   10.0.0.203 实现水平切割

二、UserDB1和UserDB2授权Amobea远程访问
>>grant all privileges on *.* to amoeba@'%' identified by 'amoeba123';

>>flush privileges;


三、创建测试表UserDB1 UserDB2
>>create database zytest;

>>use zytest;

>>create table zyalvin(
user_id integer unsigned not null,
user_name varchar(45),
user_address varchar(100),
primary key(user_id)
)engine=innodb;

四、配置Amoeba 对外验证的IP 和用户名密码
        <server>
                <!-- proxy server绑定的端口 -->
                <property name="port">9006</property>

                <!-- proxy server绑定的IP -->

                <property name="ipAddress">10.0.0.203</property>

                <!-- proxy server net IO Read thread size -->
                <property name="readThreadPoolSize">20</property>

                <!-- proxy server client process thread size -->
                <property name="clientSideThreadPoolSize">30</property>

                <!-- mysql server data packet process thread size -->
                <property name="serverSideThreadPoolSize">30</property>

                <!-- socket Send and receive BufferSize(unit:K)  -->
                <property name="netBufferSize">128</property>

                <!-- Enable/disable TCP_NODELAY (disable/enable Nagle's algorithm). -->
                <property name="tcpNoDelay">true</property>

                <!-- 对外验证的用户名 -->
                <property name="user">root</property>

                <!-- 对外验证的密码 -->

                <property name="password">123456</property>

四、配置UserDB1服务器信息
                <dbServer name="server1">

                        <!-- PoolableObjectFactory实现类 -->
                        <factoryConfig class="com.meidusa.amoeba.mysql.net.MysqlServerConnectionFactory">
                                <property name="manager">defaultManager</property>

                                <!-- 真实mysql数据库端口 -->
                                <property name="port">3306</property>

                                <!-- 真实mysql数据库IP -->
                                <property name="ipAddress">10.0.0.201</property>
                                <property name="schema">test</property>

                                <!-- 用于登陆mysql的用户名 -->
                                <property name="user">amoeba</property>

                                <!-- 用于登陆mysql的密码 -->


                                <property name="password">amoeba123</property>


                        </factoryConfig>

                        <!-- ObjectPool实现类 -->
                        <poolConfig class="com.meidusa.amoeba.net.poolable.PoolableObjectPool">
                                <property name="maxActive">200</property>
                                <property name="maxIdle">200</property>
                                <property name="minIdle">10</property>
                                <property name="minEvictableIdleTimeMillis">600000</property>
                                <property name="timeBetweenEvictionRunsMillis">600000</property>
                                <property name="testOnBorrow">true</property>
                                <property name="testWhileIdle">true</property>
                        </poolConfig>
                </dbServer>


五、配置UserDB2服务器信息
              <dbServer name="server2">

                        <!-- PoolableObjectFactory实现类 -->
                        <factoryConfig class="com.meidusa.amoeba.mysql.net.MysqlServerConnectionFactory">
                                <property name="manager">defaultManager</property>

                                <!-- 真实mysql数据库端口 -->
                                <property name="port">3306</property>

                                <!-- 真实mysql数据库IP -->
                                <property name="ipAddress">10.0.0.202</property>
                                <property name="schema">test</property>

                                <!-- 用于登陆mysql的用户名 -->
                                <property name="user">amoeba</property>

                                <!-- 用于登陆mysql的密码 -->


                                <property name="password">amoeba123</property>


                        </factoryConfig>

                        <!-- ObjectPool实现类 -->
                        <poolConfig class="com.meidusa.amoeba.net.poolable.PoolableObjectPool">
                                <property name="maxActive">200</property>
                                <property name="maxIdle">200</property>
                                <property name="minIdle">10</property>
                                <property name="minEvictableIdleTimeMillis">600000</property>
                                <property name="timeBetweenEvictionRunsMillis">600000</property>
                                <property name="testOnBorrow">true</property>
                                <property name="testWhileIdle">true</property>
                        </poolConfig>
                </dbServer>
六、配置Amoeba Rule规则
<?xml version="1.0" encoding="gbk"?>
<!DOCTYPE amoeba:rule SYSTEM "rule.dtd">

<amoeba:rule xmlns:amoeba="http://amoeba.meidusa.com/">
        <tableRule name="zyalvin" schema="zytest" defaultPools="server1,server2">

                <rule name="rule1">
                        <parameters>user_id</parameters>
                        <expression><![CDATA[ 
                        user_id between 1 and 5000000 and user_id % 2 =0
                        ]]></expression>
                        <defaultPools>server1</defaultPools>
                        <readPools>server1</readPools>
                        <writePools>server1</writePools>
                </rule>

                <rule name="rule2">
                        <parameters>user_id</parameters>
                        <expression><![CDATA[ 
                        user_id between 1 and 5000000 and user_id % 2 =1
                        ]]></expression>
                        <defaultPools>server2</defaultPools>
                        <writePools>server2</writePools>
                        <readPools>server2</readPools>
                </rule>

七、登录Amoeba 服务器做测试
# mysql -uroot -p123456 -h 10.0.0.203 -P 3006
>>use zytest;
>>insert into zyalvin(user_id,user_name,user_address)values('1','user2','China');
>>insert into zyalvin(user_id,user_name,user_address)values('2','user2','China');
>>insert into zyalvin(user_id,user_name,user_address)values('3','user2','China');
>>insert into zyalvin(user_id,user_name,user_address)values('4','user2','China');
>>insert into zyalvin(user_id,user_name,user_address)values('5','user2','China');
>>insert into zyalvin(user_id,user_name,user_address)values('6','user2','China');
>>insert into zyalvin(user_id,user_name,user_address)values('7','user2','China');
>>insert into zyalvin(user_id,user_name,user_address)values('8','user2','China');
>>insert into zyalvin(user_id,user_name,user_address)values('9','user2','China');
>>insert into zyalvin(user_id,user_name,user_address)values('10','user2','China');


















优缺点
垂直切分的优点

• 数据库的拆分简单明了，拆分规则明确；
• 应用程序模块清晰明确，整合容易；
• 数据维护方便易行，容易定位；

垂直切分的缺点

• 部分表关联无法在数据库级别完成，需要在程序中完成；
• 对于访问极其频繁且数据量超大的表仍然存在性能瓶颈，不一定能满足要求；
• 事务处理相对更为复杂；
• 切分达到一定程度之后，扩展性会遇到限制；
• 过读切分可能会带来系统过渡复杂而难以维护


水平切分的优点

• 表关联基本能够在数据库端全部完成；
• 不会存在某些超大型数据量和高负载的表遇到瓶颈的问题；
• 应用程序端整体架构改动相对较少；
• 事务处理相对简单；
• 只要切分规则能够定义好，基本上较难遇到扩展性限制；

水平切分的缺点

• 切分规则相对更为复杂，很难抽象出一个能够满足整个数据库的切分规则；
• 后期数据的维护难度有所增加，人为手工定位数据更困难；
• 应用系统各模块耦合度较高，可能会对后面数据的迁移拆分造成一定的困难


水平+垂直分割












SHELL


第一节 FIND STAT  (EXEX OK XARGS)
                                      第一章find命令

http://shuany.iteye.com/blog/845748
-name：按文件名称查找
-size：   按文件大小查找
-user：  按文件属主查找
-type：  按文件类型查找
-perm ：按文件权限查找
-mtime ：按文件更改时间查找
-newer：按比某个文件更新的查找
-mmin 根据分钟来查找

-a  and 
-o  or  
 !   取反


find pathname -options [-print -exec -ok]

    参数
        pathname: find命令所查找的目录路径。例如用.来表示当前目录，用/来表示系统根目录。
        -print：     find命令将匹配的文件输出到标准输出。
        -exec：     find命令对匹配的文件执行该参数所给出的shell命令。相应命令的形式为'command' {} \;，注意{ }和\；之间的空格。
        root@teacher bak]# find . -mmin +420 -type f -exec rm -rf {} \;
        -ok：       和-exec的作用相同，只不过以一种更为安全的模式来执行该参数所给出的shell命令，在执行每一个命令之前，都会给出提示，让用户来确定是否执行
        [root@teacher bak]# find . -type f -ok rm -rf {} \;
        。

-mtime  modify  修改时间
-atime	access	访问时间
-ctime	change	改变文件的属性的时候（大小、时间、用户、组、权限）

[root@teacher bak]# stat zhousuo
  File: `zhousuo'
  Size: 31        	Blocks: 8          IO Block: 4096   regular file
Device: 803h/2051d	Inode: 12189704    Links: 1
磁盘分区编号           文件的inode号        链接数
Access: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)
Access: 2013-04-20 08:03:28.082667296 +0800  访问时间
Modify: 2013-04-20 08:03:28.082667296 +0800（时区） 修改时间
Change: 2013-04-20 08:03:28.132543403 +0800  改变属性的时间

(1)、使用-name选项
查找文件
# find /test -name "*.txt" -print 
       
       
(2)、使用perm选项
按照权限查找
# find /shell/ -perm 755 -print


(3)、使用-prune忽略目录
# find 1.txt -path "/shell/aa" -prune -o -print

(4)、使用user和nouser选项
# find /shell/ -user alvin -print

# find /shell/ -nouser  -print

(5)、使用group和nogroup选项
# find /shell/ -group alvin -print
# find /shell/ -nogroup alvin -print


(6)、按照更改时间查找文件
按照更改时间5天以内
# find / -mtime -5 -print 

按照更改时间3天以前
# find / -mtime +3 -print

(7)、使用type选项类型
# find /test -type d -print 

# find /test -type l -print 


(8)、使用size选项
查找当前目录大于10M的文件
# find . -size +10M -print |xargs ls -l

查找当前目录小于10M的文件
# find . -size -10M -print |xargs ls -l


(9)、使用mount选项
-mount表示不能跨文件系统,只能在自己当前mount文件系统下查找
# find / -mount -name "alvin.txt" -print


(10)使用exec来执行shell命令
# find /shell/ -type f -exec ls -l {} \;
# find /shell/ -type f |xargs ls -l









 


第二节 输入输出 ECHO CAT TEE WHO ...
                                             第二章 输入输出
一、echo命令的使用
echo 命令可以显示文本行和变量，
或者把字符串输入到文件当中,
echo -e  后一般会接参数,
-e 若参数出现以下字符，则特别加以处理，而不会将它当成一般
文字输出：
   \a 发出警告声；
   \b 删除前一个字符；
   \c 最后不加上换行符号；
   \f 换行但光标仍旧停留在原来的位置；
   \n 换行且光标移至行首；
   \r 光标移至行首，但不换行；
   \t 插入tab；
   \v 与\f相同；
   \\ 插入\字符；
   \nnn 插入nnn（八进制）所代表的ASCII字符；
echo 语法：echo [-ne][字符串]或 echo [--help][--version]

正常不加-e 想使用\n换行将无效
[root@amoeba ~]# echo "aa\n bb\n"
aa\n bb\n

加上-e之后 \n之后生效了
# echo -e "aa\n bb\n" 
aa
 bb

# echo test > 1.txt 内容重定向

# echo test2 >> 2.txt 内容重定向(追加)




二、read命令
# read myname
alvinzeng
# echo $alvinzeng
alvinzeng


三、cat 命令
cat是一个简单而普通的命令，可以用来显示文件的内容，但是它不会在分页的时候停下来.如果希望分页查询使用| 管道和more
管道的作用用来连接多个命令的执行
# cat myfile | more


四、tee命令
# who | tee who.out 
将who的输出定向到who.out文件里面


# who | tee -a who.out
将将who的输出追加到who.out尾部 -a表示追加

五、标准输入、标准输出、标准错误
(1)、标准输入为 0
(2)、标准输出为 1
(3)、标准错误为 2

(4)重定向标准输出

cat passwd | awk -F: '{print $1}' | sort  1>sort.out

2> 错误的输出，只有发生错误的时候，才会执行错误重定向
2>> 追加
&>  不论是正确的输出，还是错误的输出都往一个文件里重定向.会覆盖原来的内容
2>&1 等效于&>
&>>不会覆盖原来的内容

(5)重定向标准输入
cat >> alvin.log <<EOF
> my name is alvin
> my name is gongda
> good bye,..
> EOF


(6)重定向标准错误
[root@amoeba ~]# grep "gongda" 111.txt
grep: 111.txt: 没有那个文件或目录


正常来说会产生一个错误.次方法标准2错误重定向
# grep "gongda" 111.txt 2>/dev/null


(7)标准输出和标准错误结合使用
# grep "root" /etc/passwd > 1.log 2>&1


ECHO -E
是 echo -e "i will use \n $HOME" 输出的将是
     i will use
     /root(当前用户的主目录)
     如果是 echo "i will use \n $HOME" 则输出是：
     i will use \n $HOME


第三节  GREP +CAT 一般匹配 
一、grep 选项
-c 只输出匹配行的计数
-i 不区分大小写(只适用于单字符)
-h 查询多文件时不显示文件名
-l 查询多文件时至输出包含匹配字符的文件名
-n 显示匹配行以及行号
-s 不显示不存在或匹配文本的错误信息
-v  --invert -match 匹配相反的内容

去除换行
注意在MS的系统下生成的文本文件，换行会加上一个 ^M 字符。所以最后的字符会是隐藏的^M ,在处理Windows
下面的文本时要特别注意！
可以用cat dos_file | tr -d '/r' > unix_file 来删除^M符号。 ^M==/r

1.1、查询多个文件
# echo "sort aa" > 1.txt
# echo "sort bb" > 2.txt
# echo "sort cc" > 1.log
# echo "sort dd" > 2.log
# grep "sort " .txt 在所有.txt文件中查找sort关键字
# grep "sort " *  在所有的文件中查找sort关键字




1.2、行匹配
# grep -c "root" /etc/passwd 意思包含root的字符在passwd 有2行.

/b 单词锁定符，如: '/bgrep/b'只匹配grep。

1.3、行数
# grep -n "root" /etc/passwd  显示内容并且把行号打印出来。

1.4、显示非匹配行
# grep -v "root" /etc/passwd

    、^只匹配行首
# cat /etc/passwd | grep "^root"
  {n}  ??????????
  n 是一个非负整数。匹配确定的 n 次。例如，'o{2}' 不能匹配 "Bob" 中的 'o'，但是能匹配 "food" 中的两个 o。
 {n,}  ???????????
 n 是一个非负整数。至少匹配n 次。例如，'o{2,}' 不能匹配 "Bob" 中的 'o'，但能匹配 "foooood" 中的所有 o。'o{1,}' 等价于 'o+'。'o{0,}' 则等价于 'o*'
 {n,m} ??????????????
 m 和 n 均为非负整数，其中n <= m。最少匹配 n 次且最多匹配 m 次。例如，"o{1,3}" 将匹配 "fooooood" 中的前三个 o。'o{0,1}' 等价于 'o?'。请注意在逗号和两个数之间不能有空格。


\s匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \f\n\r\t\v]
\s匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \f\n\r\t\v]

单边字符 \<     \>

[root@teacher lianxi]# cat grep.txt |grep '\<hello\>' 查找出包含hello单词的行


   、$只匹配行尾
# cat /etc/passwd | grep "bash$"


  、 *匹配单个字符或者多个
# cat /etc/passwd | grep "root*"



 、\屏蔽一个特殊字符的含义(转义)
# echo "
///\@itest
\" > test.txt
# cat 2.txt  | sed 's/\/\/\/\\/aa/g'


 、[]定义一个范围或者一个集合
# cd /opt
# touch log.1123 && touch log.12 && touch LOG.AB && touch log.aa
# ls | grep "[0-9]"
# ls | grep "[A-Z]"
# ls | grep "[a-z]"
# ls | grep "[1 2 3 4 5 6]"  包含 1 2 3 4 6的显出来

 、pattern\{n\}匹配模式
A\{2\}B 匹配字母A出现2次，并且以B结尾
# cat passwd | grep "root\{2\}*"

A\{4,\}B 匹配A至少出现4次 
# cat passwd | grep "spool\{4,\}*"


A\{2,4\}B 匹配A出现次数2-4次之间
# cat passwd | grep "spool\{2,4\}*"




1.5、大小写敏感
缺省情况下区分大小写的，-i可以不区分大小写
#echo "ROOT" > 1.txt
#echo "root" > 1.txt
# grep -i "root"


1.6、$^空行
# echo "
root
ROOT

bb

cc" > 1.txt

# grep -v "^$" 1.txt


1.7、-E参数，可以匹配多个条件
# cat /etc/passwd | grep -E "root|spool"




GREP 详解
http://blog.csdn.net/deyili/article/details/5548603
grep用法详解:grep与正则表达式 
首先要记住的是: 正则表达式与通配符不一样,它们表示的含义并不相同!
正则表达式只是一种表示法,只要工具支持这种表示法， 那么该工具就可以处理正则表达式的字符串。vim、grep、awk 、sed 都支持正则表达式，也正是因为由于它们支持正则，才显得它们强大；

1基础正则表达式
grep 工具，以前介绍过。
grep -[acinv]   '搜索内容串'   filename
-a 以文本文件方式搜索
-c 计算找到的符合行的次数
-i 忽略大小写
-n 顺便输出行号
-v 反向选择，即显示不包含匹配文本的所有行

-h 查询多文件时不显示文件名。
-l 查询多文件时只输出包含匹配字符的文件名。
-s 不显示不存在或无匹配文本的错误信息。
grep命令加- E参数，这一扩展允许使用扩展模式匹配。

其中搜索串可以是正则表达式!

---
先用例子说明问题：
以下为整理的grep 正则表达式的大部分功能,详细参见man
grep: 要用好grep这个工具，其实就是要写好正则表达式，所以这里不对grep的所有功能进行实例讲解，只列几个例子，讲解一个正则表达式的写法。
$ ls -l | grep '^a' 通过管道过滤ls -l输出的内容，只显示以a开头的行。
$ grep 'test' d* 显示所有以d开头的文件中包含test的行。
$ grep 'test' aa bb cc 显示在aa，bb，cc文件中匹配test的行。
$ grep '[a-z]/{5/}' aa 显示所有包含每个字符串至少有5个连续小写字符的字符串的行。
$ grep 'w/(es/)t.*/1' aa 如果west被匹配，则es就被存储到内存中，并标记为1，然后搜索任意个字符（.*），这些字符后面紧跟着另外一个es（/1），找到就显示该行。如果用egrep或grep -E，就不用"/"号进行转义，直接写成'w(es)t.*/1'就可以了。

grep正则表达式元字符集（基本集）
^ 锚定行的开始 如：'^grep'匹配所有以grep开头的行。
$ 锚定行的结束 如：'grep$'匹配所有以grep结尾的行。
. 匹配一个非换行符的字符 如：'gr.p'匹配gr后接一个任意字符，然后是p。
* 匹配零个或多个先前字符 如：'*grep'匹配所有一个或多个空格后紧跟grep的行。
.*一起用代表任意字符。
[] 匹配一个指定范围内的字符，如'[Gg]rep'匹配Grep和grep。
[^] 匹配一个不在指定范围内的字符，如：'[^A-FH-Z]rep'匹配不包含A-R和T-Z的一个字母开头，紧跟rep的行。
/(../) 标记匹配字符，如'/(love/)'，love被标记为1。
/< 锚定单词的开始，
/> 锚定单词的结束，如'grep/>'匹配包含以grep结尾的单词的行。
x/{m/} 重复字符x，m次，如：'o/{5/}'匹配包含5个o的行。 x/{m,/} 重复字符x,至少m次，如：'o/{5,/}'匹配至少有5个o的行。
x/{m,n/} 重复字符x，至少m次，不多于n次，如：'o/{5,10/}'匹配5--10个o的行。
/w 匹配文字和数字字符，也就是[A-Za-z0-9_]，如：'G/w*p'匹配以G后跟零个或多个文字或数字字符，然后是p。
/W /w的反置形式，匹配一个或多个非单词字符，如点号句号等。
/b 单词锁定符，如: '/bgrep/b'只匹配grep。

关于匹配的实例：
grep -c "48" test.txt 统计所有以“48”字符开头的行有多少
grep -i "May" test.txt 不区分大小写查找“May”所有的行）
grep -n "48" test.txt 显示行号；显示匹配字符“48”的行及行号，相同于 nl test.txt |grep 48）
grep -v "48" test.txt 显示输出没有字符“48”所有的行）
grep "471" test.txt 显示输出字符“471”所在的行）
grep "48;" test.txt 显示输出以字符“48”开头，并在字符“48”后是一个tab键所在的行
grep "48[34]" test.txt 显示输出以字符“48”开头，第三个字符是“3”或是“4”的所有的行）
grep "^[^48]" test.txt 显示输出行首不是字符“48”的行）
grep "[Mm]ay" test.txt 设置大小写查找：显示输出第一个字符以“M”或“m”开头，以字符“ay”结束的行）
grep "K…D" test.txt 显示输出第一个字符是“K”，第二、三、四是任意字符，第五个字符是“D”所在的行）
grep "[A-Z][9]D" test.txt 显示输出第一个字符的范围是“A-Z”，第二个字符是“9”，第三个字符的是“D”的所有的行
grep "[35]..1998" test.txt 显示第一个字符是3或5，第二三个字符是任意，以1998结尾的所有行
grep "4/{2,/}" test.txt 模式出现几率查找：显示输出字符“4”至少重复出现两次的所有行
grep "9/{3,/}" test.txt 模式出现几率查找：显示输出字符“9”至少重复出现三次的所有行
grep "9/{2,3/}" test.txt 模式出现几率查找：显示输出字符“9”重复出现的次数在一定范围内，重复出现2次或3次所有行
grep -n "^$" test.txt 显示输出空行的行号
ls -l |grep "^d" 如果要查询目录列表中的目录 同：ls -d *
ls -l |grep "^d[d]" 在一个目录中查询不包含目录的所有文件
ls -l |grpe "^d…..x..x" 查询其他用户和用户组成员有可执行权限的目录集合

更多的例子:
1
搜索有the的行,并输出行号
$grep -n 'the' regular_express.txt
搜 索没有the的行,并输出行号
$grep -nv 'the' regular_express.txt

2 利 用[]搜索集合字符
[] 表示其中的某一个字符 ，例如[ade] 表示a或d或e
woody@xiaoc:~/tmp$ grep -n 't[ae]st' regular_express.txt
8:I can't finish the test.
9:Oh! the soup taste good!

可以用^符号做[]内的前缀，表示除[]内的字符之外的字 符。
比如搜索oo前没有g的字符串所在的行. 使用 '[^g]oo' 作搜索字符串
woody@xiaoc:~/tmp$ grep -n '[^g]oo' regular_express.txt
2:apple is my favorite food.
3:Football game is not use feet only.
18:google is the best tools for search keyword.
19:goooooogle yes!

[] 内可以用范围表示，比如[a-z] 表示小写字母,[0-9] 表示0~9的数字, [A-Z] 则是大写字母们。[a-zA-Z0-9]表示所有数字与英文字符。 当然也可以配合^来排除字符。
搜索包含数字的行
woody@xiaoc:~/tmp$ grep -n '[0-9]' regular_express.txt
5:However ,this dress is about $ 3183 dollars.
15:You are the best is menu you are the no.1.

行首与行尾字符 ^ $. ^ 表示行的开头，$表示行的结尾( 不是字符，是位置）那么‘^$’ 就表示空行,因为只有
行首和行尾。
这里^与[]里面使用的^意义不同。它表示^后面的串是在行的开头。
比如搜索the在开头的行
woody@xiaoc:~/tmp$ grep -n '^the' regular_express.txt
12:the symbol '*' is represented as star.

搜索以小写字母开头的行
woody@xiaoc:~/tmp$ grep -n '^[a-z]' regular_express.txt
2:apple is my favorite food.
4:this dress doesn't fit me.
10:motorcycle is cheap than car.
12:the symbol '*' is represented as star.
18:google is the best tools for search keyword.
19:goooooogle yes!
20:go! go! Let's go.
woody@xiaoc:~/tmp$

搜索开头不是英文字母的行
woody@xiaoc:~/tmp$ grep -n '^[^a-zA-Z]'  regular_express.txt
1:"Open Source" is a good mechanism to develop programs.
21:#I am VBird
woody@xiaoc:~/tmp$

$表示它前面的串是在行的结尾，比如 '/.' 表示 . 在一行的结尾
搜索末尾是.的行
woody@xiaoc:~/tmp$ grep -n '/.$' regular_express.txt //. 是正则表达式的特殊符号，所以要用/转义
1:"Open Source" is a good mechanism to develop programs.
2:apple is my favorite food.
3:Football game is not use feet only.
4:this dress doesn't fit me.
5:However ,this dress is about $ 3183 dollars.
6:GNU is free air not free beer.
.....

注意在MS的系统下生成的文本文件，换行会加上一个 ^M 字符。所以最后的字符会是隐藏的^M ,在处理Windows
下面的文本时要特别注意！
可以用cat dos_file | tr -d '/r' > unix_file 来删除^M符号。 ^M==/r

那么'^$' 就表示只有行首行尾的空行拉！
搜索空行
woody@xiaoc:~/tmp$ grep -n '^$' regular_express.txt
22:
23:
woody@xiaoc:~/tmp$

搜索非空行
woody@xiaoc:~/tmp$ grep -vn '^$' regular_express.txt
1:"Open Source" is a good mechanism to develop programs.
2:apple is my favorite food.
3:Football game is not use feet only.
4:this dress doesn't fit me.
===
grep –E ‘219|216’ tab2
g r e p允许使用国际字符模式匹配或匹配模式的类名形式。

类                        等价的正则表达式

[ [ : u p p e r : ] ]       [ A - Z ]

[ [ : a l n u m : ] ]          [ 0 - 9 a - zA-Z]

[ [ : l o w e r : ] ]        [ a - z ]

[ [ : s p a c e : ] ]         空格或t a b键

[ [ : d i g i t : ] ]         [ 0 - 9 ]

[ [ : a l p h a : ] ]       [ a - z A - Z ]
====







第四节 AWK的部分用法
                         AWK用法
一、知识点一
1、域分割 -F 确定分割符 如果不加-F 默认以空格分割符
 cat /etc/passwd | awk -F: '{print $1,$2,$3}'

2、抽取域
cat /etc/passwd | awk -F: '{print $1}'


3、$0代表全局域，也就是所有的记录
cat /etc/passwd | awk -F: '{print $0}'


4、单独打印记录
cat /etc/passwd | awk -F: '{print $1,$4}'



5、打印报告头
# cat /etc/passwd | awk -F: 'BEGIN{print "This is system user"}{print $1}' | more



6、打印信息尾
# cat /etc/passwd | awk -F: 'BEGIN{print "This is system user"}{print $1}
END{print "==================="}'

二、知识点二
awk正则表达式
(1) ～匹配
cat /etc/passwd | awk '{if($0~/root/) print $0}'

(2) 精确匹配
cat /etc/passwd | awk -F: '{if($1~/root/) print $1}'

(3) 不匹配!
cat /etc/passwd | awk '$0 !~/root/'
cat /etc/passwd | awk -F: '{if($1~/root/)print $1}'



(4) 小于
cat /etc/passwd |awk -F: '{if($3<200)print $3}'




(5) 小于或者等于
cat /etc/passwd | awk -F: '{if($3<=200)print $3}'

(6) 大于或者等于
cat /etc/passwd | awk -F: '{if($3>=200)print $3}'

(7) 匹配多个关键字 
cat /etc/passwd | awk -F: '$1~/(root|user)/'

(8) 匹配行首
cat /etc/passwd | awk -F: '$1~/^root/'






(9) awk 使用&& || 
条件1为真&&则条件二执行
条件1为真|| 则条件二不执行


cat /etc/passwd | awk -F: '{if($1=="root" && $5=="root")print $0}'
cat /etc/passwd | awk -F: '{if($1=="root" || $1=="sdfsfsdsdsd") print $0}'

awk NF 和NR
NF   域的个数  或者说是值的个数
NR 已读的记录数    其实就是行数
$NF  最后一个域的值 
 
打印最后一行   cat /etc/passwd  | awk  'END{print}' 
cat /etc/passwd |sed -n '$p'   OR  sed -n '$p' /etc/passwd 

      awk -F'one|:'     多个分隔符的方法  
  cat /etc/passwd | awk -F: '{print NF}'
  
cat /etc/passwd | awk -F: '{print $1,NR}'

cat /etc/passwd | awk -F: '{if(NR<10 && $1~/root/)print $1}'

awk 替换
gsub(r,s)
cat /etc/passwd | awk -F: 'gsub(/root/,"alvinzeng"){print $0}'



本章练习题：
1 awk 默认以什么为分割符？
2 抽取/etc/passwd 第一个域和第5个域并且统计他们的行号
3 抽取第一个域，并且进行root匹配，然后打印出报告头内容为"This is user"
4 抽取最后一个域，尾部信息用“########”分割
5 请抽取第一个域，请且匹配以user开头的关键字
6 匹配全局域带有[0-9]的关键字的域信息
7 请打印出来行后大于30 并且匹配第一个域为mysql的信息条目
8 请打印出/etc/passwd 里面最后一个域，并且统计bash有多少个？nologin的有多少个？
9 请打印出UID小于500 但是大于200的用户信息
10 请打印出带DHCP关键子的用户信息，并且告诉用户在那一行？
11 请打印出wu开头的用户有几个？
12 抽取全域匹配home关键字的有多少个用户？他们是否具bash登录权限
13 匹配行号大于30 并且球UID大于50或者小于500的用户信息
14 匹配系统用户有多少个？ 以及程序用户有多少个？
15 匹配行号小于30的，并且匹配他们的bash的用户有多少个，在输出他们的行号？












第五节 SED的使用
                                 
                                           sed sed                                   
                                 
环境：
（1）在/opt/tmp 目录
 (2)vim 编辑gongda.txt文件
内容为:
abcdefg!@#$%^&*
!@#$%^&*abcdefg
11111111111111111111
22222222222222222222
333333333333333333333
aa bb cc ff dd ee
a1 a2 a3 a4 a5 a6
11 22 33 44 55 66
@@@@@@@@@@@@@@
#############

一、sed 文本过滤工具，针对于行过滤
(1)sed -n  'xxxp' 参数语法
举例:sed -n '1p' 打印第1行
分别显示gongda 1 2 3 4 5行
显示1,3行  显示3，4行



(2)sed -n ‘/^匹配/p’ gongda.txt
其中^代表以xxx开头字符或者数字
其中$代表以xxx结尾的字符或者数字
练习题如下:
	显示以a开头有多少行？
	显示以1开头有多少？
	包含0-9的数字全部显示出来
	以0-9开头的纯数字显示出来
						
sed -n '/匹配$/p'  gongda.txt 
 	
(3)sed -e 可以执行多少条件
举例说明:sed -n -e '/^a/p' -e '/^[0-9]/p' gongda.txt 
练习题目如下:
	以1结尾请显示出来 
	以e结尾请显示出来
	以6结尾请显示出来
	以#结尾请显示出来
	
	
	
	
	
	
	
	
(4)sed -n '/a1/=' =表示行号
举例说明:# sed -n -e '/^a/p' -e '/^a/=' gongda.txt 
满足匹配条件的行号
练习题目如下:
   	以1结尾请显示出来、并要求显示出行号
	以e结尾请显示出来、并要求显示出行号
	以6结尾请显示出来、并要求显示出行号
	以#结尾请显示出来、并要求显示出行号
	以a-z开头的显示出来，并要显出出行号
	
	
	
	
	
	
	
	
(5)、向文本追加内容 sed -n '/a1/a\hunangongyedaxue'
向匹配行后面追加内容,a\代表向后便追内容，
举例说明:cat gongda.txt | sed -n '/a1/p' | sed '/a1/a\gongdaOK'
   	以1结尾请显示出来、要求显示出行号，后面追加gongda1
	以e结尾请显示出来、要求显示出行号，后面追加gongda1
	以6结尾请显示出来、要求显示出行号，后面追加gongda1
	以#结尾请显示出来、要求显示出行号，后面追加gongda1
    以a-z开头的显示出来，并要显出出行号  后面追加gongda1
	
	
	
	
	
	

(6)、取反!
举例说明：cat gongda.txt | sed -n '1,3!p'
代表1，3行不打印出来.
练习题
	匹配以包含字母a打印出来，过滤掉当前内容的第1行
    匹配以包含字母[0-9]打印出来，过滤掉当前内容的第2行
    匹配以包含字母@#分别打印出来，增加内容：this is gongda
    
    
    
    
    
    
(7)、d表示删除
举例说明: cat gongda.txt  | sed '1,2d'
练习题
	匹配以包含字母a打印出来，删除第1行
    匹配以包含字母[0-9]打印出来，删除第2行
    
    
    
    
    
    
    
(8)、替换sed 's/旧内容/替换成新的内容/g' 
举例说明： # cat gongda.txt  | sed -e 's/#/gongda/g' -e 's/@/gongda/g'  同时将# @替换成gongda

举例说明：# cat gongda.txt | sed -n '1,2s/abcdefg/alvin/p'   同时将1,2行的abcdefg替换alvin






(9)、sed -i file 将更改内容写入文件
#cat gongda.txt| sed -i '1,2s/abcdefg/alvin/g' gongda.txt







sed总结练习题目：




将gongdatext.txt文档过滤要去如下:
(1)、把Jon's 临时替换成Jonathan.
(2)、把"Fred" 全部替换成gongda，其中包括了""号
(3)、删除头三行
(4)、显示5-10行
(5)、显示关键字November-December的行号
(6)、把三个***号加到Fred开头的行后面
(7)、过滤包含JOse的行，然后用He Xi Gong 'da' 替换Jose.
(8)、把Popeye的生日改为11/14/46
(9)、删除所有空白行
(10)、将里面包含关键字/全部替换成-

gongdatext.txt内容如下：
Steve Blenheim:238-923-7366:95 Latham Lane, Easton, PA 83755:11/12/56:20300
Betty Boop:245-836-8357:635 Cutesy Lane, Hollywood, CA 91464:6/23/23:14500
Igor Chevsky:385-375-8395:3567 Populus Place, Caldwell, NJ 23875:6/18/68:23400
Norma Corder:397-857-2735:74 Pine Street, Dearborn, MI 23874:3/28/45:245700
Jennifer Cowan:548-834-2348:583 Laurel Ave., Kingsville, TX 83745:10/1/35:58900
Jon's DeLoach:408-253-3122:123 Park St., San Jose, CA 04086:7/25/53:85100
Karen Evich:284-758-2857:23 Edgecliff Place, Lincoln, NB 92086:7/25/53:85100
Karen Evich:284-758-2867:23 Edgecliff Place, Lincoln, NB 92743:11/3/35:58200
Karen Evich:284-758-2867:23 Edgecliff Place, Lincoln, NB 92743:11/3/35:58200
"Fred" Fardbarkle:674-843-1385:20 Parak Lane, DeLuth, MN 23850:4/12/23:780900
Fred Fardbarkle:674-843-1385:20 Parak Lane, DeLuth, MN 23850:4/12/23:780900
Lori Gortz:327-832-5728:3465 Mirlo Street, Peabody, MA 34756:10/2/65:35200
Paco Gutierrez:835-365-1284:454 Easy Street, Decatur, IL 75732:2/28/53:123500
Ephram Hardy:293-259-5395:235 CarltonLane, Joliet, IL 73858:8/12/20:56700
James Ikeda:834-938-8376:23445 Aster Ave., Allentown, NJ 83745:12/1/38:45000
Barbara Kertz:385-573-8326:832 Ponce Drive, Gary, IN 83756:12/1/46:268500
Lesley Kirstin:408-456-1234:4 Harvard Square, Boston, MA 02133:4/22/62:52600
William Kopf:846-836-2837:6937 Ware Road, Milton, PA 93756:9/21/46:43500
Sir Lancelot:837-835-8257:474 Camelot Boulevard, Bath, WY 28356:5/13/69:24500
Jesse Neal:408-233-8971:45 Rose Terrace, San Francisco, CA 92303:2/3/36:25000
Zippy Pinhead:834-823-8319:2356 Bizarro Ave., Farmount, IL 84357:1/1/67:89500
Arthur Putie:923-835-8745:23 Wimp Lane, Kensington, DL 38758:8/31/69:126000
Popeye Sailor:156-454-3322:945 Bluto Street, Anywhere, USA 29358:3/19/35:22350
Jose Santiago:385-898-8357:38 Fife Way, Abilene, TX 39673:1/5/58:95600
Tommy Savage:408-724-0140:1222 Oxbow Court, Sunnyvale, CA 94087:5/19/66:34200
Yukio Takeshida:387-827-1095:13 Uno Lane, Ashville, NC 23556:7/1/29:57000
Vinh Tranh:438-910-7449:8235 Maple Street, Wilmington, VM 29085:9/23/63:68900



第六节 SORT UNIQ  CUT PASTE JOIN SPLIT
一、sort用法

(1)、-r 对分类进行次序或者比较求逆
# cat 1.txt | sort -r
4:datadir=/sdfsfsd:dd
3:basedir=/data:gg
2:basedir=:cc
1:datadir=/aaa/zzz:bb

(2)、-u 删除所有复制行
# cat 1.txt | sort -u


(3)、-n 指定分类是域上的数据分类
你有没有遇到过10比2小的情况。我反正遇到过。出现这种情况是由于排序程序将这些数字按字符来排序了，排序程序会先比较1和2，显然1小，所以就将10放在2前面喽。这也是sort的一贯作风。
# cat 2.txt | sort 
1
10
11
19
2
5
# cat 2.txt | sort -n
1
2
5
10
11
19

(4)、 sort的-t选项和-k选项
# cat facebook.txt
banana:30:5.5
apple:10:2.5
pear:90:2.3
orange:20:3.4
这个文件有三列，列与列之间用冒号隔开了，第一列表示水果类型，第二列表示水果数量，第三列表示水果价格。那么我想以水果数量来排序，也就是以第二列来排序，如何利用sort实现？幸好，sort提供了-t选项，后面可以设定间隔符。指定了间隔符之后，就可以用-k来指定列数了。
# sort -n -k 2 -t ‘:’ facebook.txt
apple:10:2.5
orange:20:3.4
banana:30:5.5
pear:90:2.3






二、uniq用法
(1)、-u 只显示不重复行
# cat 1.txt 
111
111
2222
2222
3333
3333
4444
# cat 1.txt | uniq -u
4444


(2)、-d 只显示有重复数据行
# cat 1.txt | uniq -d
111
2222
3333


(3)、 -c 打印每一重复行出现的次数 
# cat 1.txt | uniq -c 
      2 111
      2 2222
      2 3333
      1 4444


三、join用法
# cat 1.txt 
name1 alvin1
name2 alvin2
name3 alvin3
name4 alvin4

# cat 2.txt 
name1 100
name2 101
name3 102
cccccccccccccccc

# join 1.txt 2.txt   只显示匹配的行，CC和name4不匹配将忽略。
name1 alvin1 100
name2 alvin2 101
name3 alvin3 102



# join -a1 1.txt 2.txt 拿1.txt内容去2.txt匹配发现name4在2.txt里面没有,那么则显示不匹配，值就为空
name1 alvin1 100
name2 alvin2 101
name3 alvin3 102
name4 alvin4

# join -a2 1.txt 2.txt 拿2.txt内容去1.txt匹配发现ccc在1.txt里面没有,那么则显示不匹配，值就为空
name1 alvin1 100
name2 alvin2 101
name3 alvin3 102
ccccccccccccccc


# join -a1 1.txt -a2 2.txt  两边同时匹配。把不匹配的行全部输出来。
name1 alvin1 100
name2 alvin2 101
name3 alvin3 102
cccccccccccccccc
name4 alvin4

# join -o 1.2 2.2 1.txt 2.txt   连接文件1的第二部分，文件2的第三部分。前提是这两行的域一要匹配。
alvin1 100
alvin2 101
alvin3 102




四、cut用法

-c list 指定剪切字符数
-f field 制定剪切域数
-d 指定与空格和tab键不同的域分割符

(1)、-c 用来指定剪切范围
-c1,5-7 剪切第一个1个字符，然后是第5到第7个字符
-c1-50 、剪切前50个字符
# cat 1.txt 
name1 alvin1
name2 alvin2
name3 alvin3
name4 alvin4
# cat 1.txt  | cut -c1    把第一个字符剪切出来
n
n
n
n
# cat 1.txt  | cut -c1,3-4  第一个字符和3-4个字符剪切出来
nme
nme
nme
nme


(2)、-f格式与-c相同
-f1,5 剪切第1个域，第5个域
-f1,10-12 剪切第1域，第10域到第12域
# cat 1.txt 
name1 alvin1
name2 alvin2
name3 alvin3
name4 alvin4
# cat 1.txt  | cut -d" "  -f1  以空格为分割符，切割第一个域
name1
name2
name3
name4

# cat 2.txt 
name1:100
name2:101
name3:102
# cat 2.txt  | cut -d:  -f1   以：为分割符。切割第一域 
name1
name2
name3

五、paste用法
-d 指定不同于空格或者tab键盘的域分割符
-s 将每个文件合并成行而不是按行粘贴
# cat 2.txt 
name1:100
name2:101
name3:102
# paste 1.txt 2.txt 
name1 alvin1    name1:100
name2 alvin2    name2:101
name3 alvin3    name3:102
name4 alvin4

# paste -d: 1.txt 2.txt 
name1 alvin1:name1 100
name2 alvin2:name2 101
name3 alvin3:name3 102
name4 alvin4:

# paste -s 1.txt 2.txt 
name1 alvin1    name2 alvin2    name3 alvin3    name4 alvin4
name1 100       name2 101       name3 102

[root@master ~]# cat 1.txt | paste -d" " - - - -      将内容以空格为分割符，横向显示
name1 alvin1 name2 alvin2 name3 alvin3 name4 alvin4


六、split用法
split将大文件分割成小文件，特别是日志文件进行分割。

1、举例：文件有1.log文件1万
分别每 1000行分割成1个文件，做分析
# split -1000 1.log 

2、举例：文件1.txt有4行
分别每1行，分割出来做为一个文件
# cat 1.txt 
name1 alvin1
name2 alvin2
name3 alvin3
name4 alvin4
# split -1 1.txt        
# cat xaa  
name1 alvin1
# cat xac
name3 alvin3
# cat xab
name2 alvin2
# cat xad
name4 alvin4


第七节 TR的用法
tr用法：
tr用来从标准输入中通过替换或删除操作进行字符转换。 tr主要用于删除文件中控制字符
或进行字符转换。使用tr时要转换两个字符串：字符串1用于查询，字符串2用于处理各种转换。
tr刚执行时，字符串1中的字符被映射到字符串2中的字符，然后转换操作开始
-c 用字符串1中字符集的补集替换此字符集，要求字符集为 ASCII。
-d 删除字符串1中所有输入字符。
-s 删除所有重复出现字符序列，只保留第一个；即将重复出现字符串压缩为一个字符
串
\ a  Ctrl-G 铃声  \ 0 0 7
\ b  Ctrl-H 退格符 \ 0 1 0
\f   Ctrl-L 走行换页\ 0 1 4
\n   Ctrl-J 新行     \ 0 1 2
\ r  Ctrl-M 回车      \ 0 1 5
\t   Ctrl-I tab键      \ 0 11
\ v  Ctrl-X            \ 0 3 0

1、删除重复出现的字符串
#echo "
And the cowwwwwssssss went homeeeeeeeee
i havvvvve 
theyyyyyyyyy" >test.txt

# cat test.txt |tr -s "[a-z]" 
And the cows went home
i have they


2、删除空行
# cat test.txt  | tr -s "[\n]"

3、小写转成大写
# cat test.txt  | tr  "[a-z]" "[A-Z]" 小写换大写
# cat test.txt  | tr  "[A-Z]" "[a-z]" 大写换小写

4、删除指定字符
# cat test.txt  | tr -d "[And]"

5、转换控制字符
^的八进制代码是136，^ M是015，tab键是011，^Z是032
#vim /test.txt
And the cowwwwwssssss went homeeeeeeeee^M
i havvvvve ^^^theyyyyyyyyy^M
sdfsdsfd

                ^Msdfsfsfs
				
#cat test.txt | tr -s "[\015\032\011]" "[\n]"
				
6、匹配多个字符串
# cat test.txt 
1293 hdisk3
4512 hdisk1
0000 hdisk5
4993 hdisk6
2997 hdisk7
0010 hdisk8


# cat test.txt |tr "[0*4]" "*"			
因此用星号代替所有的 0。模式为[ 0 * 4 ]，意即匹
配至少4个0，替换字符串为星号
1293 hdisk3
4512 hdisk1
**** hdisk5
4993 hdisk6
2997 hdisk7
**1* hdisk8
tr主要用于字符转换或者抽取控制字符。本章所有功能都可以用 sed来完成，但有些人宁
愿使用tr，因为tr更加快捷、容易				
				



LIANXI题目


111
一、#grep练习题:
1、查找/目录下面的"passwd"文件和"profile" 文件

2、查找/tmp下面权限为755的文件，没有的话 自己创建一个，修改权限

3、在/test/aa 下面创建一个名字为 gongda.txt的文件，用find命令把/test/aa目 录给忽略掉是否还可以查找的到？

4、创建一个用户和组 名为gongda，然后 gongda.txt所属用户和所属组全部修改成 gongda，
使用user和group查找gongda的用户组，是否可 以查找到？
然后删除掉gongda用户和组，再用nouser 和 nogroup查找没有所属和说是组的文件是否可以 查到？

5、查找在/目录下面更改时间在5天以内的文件

6、查找在/目录下面更改时间在3天以前的目录

7、在/opt/test/下面创建一个名字为new.txt 文件。等5分钟后再创建一个ok.txt的文件。使 用find命令查找比gongda.txt新比ok.txt旧的 文件。

8、使用find查找/home下面所有的目录

9、使用find查找/home下面所有的文件，非目 录

10、使用find查找/etc/ 下面所有的连接文件

11、查找/etc/目录下面大于1M的文件，并且把 文件大小信息列出来。

12、查找/etc/目录下面小于500K的文件，并且 把文件大小信息列出来

13、查找/opt/test 子目录下面的gongda.txt 文件

14、检查系统有几个挂在的文件系统，比如/  和/home是分开的，。那么在/home/创建一个
sxgongda.txt文件。使用find 参数mount查找
/目录是否可以查到sxgongda.txt文件？

15、查询/opt/下面的gongda.txt文件，并且使 用exec 列出它的详细信息。

16、使用什么参数可以每次find后跟系统命令 时给出安全提示？




二、AWK练习题目：
本章练习题：
1 awk 默认以什么为分割符？
2 抽取/etc/passwd 第一个域和第5个域并且统计他们的行号
3 抽取第一个域，并且进行root匹配，然后打印出报告头内容为"This is user"
4 抽取最后一个域，尾部信息用“########”分割
5 请抽取第一个域，请且匹配以user开头的关键字
6 匹配全局域带有[0-9]的关键字的域信息
7 请打印出来行后大于30 并且匹配第一个域为mysql的信息条目
8 请打印出/etc/passwd 里面最后一个域，并且统计bash有多少个？nologin的有多少个？
9 请打印出UID小于500 但是大于200的用户信息
10 请打印出带DHCP关键子的用户信息，并且告诉用户在那一行？
11 请打印出wu开头的用户有几个？
12 抽取全域匹配home关键字的有多少个用户？他们是否具bash登录权限
13 匹配行号大于30 并且球UID大于50或者小于500的用户信息
14 匹配系统用户有多少个？ 以及程序用户有多少个？
15 匹配行号小于30的，并且匹配他们的bash的用户有多少个，在输出

三、sed总结练习题目：
将gongdatext.txt文档过滤要去如下:
(1)、把Jon's 临时替换成Jonathan.
(2)、把"Fred" 全部替换成gongda，其中包括了""号一起替换
(3)、删除头三行和第11行
(4)、显示5-10行
(5)、显示关键字November-December的行号
(6)、把三个***号加到Fred开头的行后面
(7)、过滤包含JOse的行，然后用He Xi Gong 'da' 替换Jose.
(8)、把Popeye的生日改为11/14/46
(9)、删除所有空白行
(10)、将里面包含关键字/全部替换成-

gongdatext.txt内容如下：
Steve Blenheim:238-923-7366:95 Latham Lane, Easton, PA 83755:11/12/56:20300
Betty Boop:245-836-8357:635 Cutesy Lane, Hollywood, CA 91464:6/23/23:14500
Igor Chevsky:385-375-8395:3567 Populus Place, Caldwell, NJ 23875:6/18/68:23400
Norma Corder:397-857-2735:74 Pine Street, Dearborn, MI 23874:3/28/45:245700
Jennifer Cowan:548-834-2348:583 Laurel Ave., Kingsville, TX 83745:10/1/35:58900
Jon's DeLoach:408-253-3122:123 Park St., San Jose, CA 04086:7/25/53:85100
Karen Evich:284-758-2857:23 Edgecliff Place, Lincoln, NB 92086:7/25/53:85100
Karen Evich:284-758-2867:23 Edgecliff Place, Lincoln, NB 92743:11/3/35:58200
Karen Evich:284-758-2867:23 Edgecliff Place, Lincoln, NB 92743:11/3/35:58200
"Fred" Fardbarkle:674-843-1385:20 Parak Lane, DeLuth, MN 23850:4/12/23:780900
Fred Fardbarkle:674-843-1385:20 Parak Lane, DeLuth, MN 23850:4/12/23:780900
Lori Gortz:327-832-5728:3465 Mirlo Street, Peabody, MA 34756:10/2/65:35200
Paco Gutierrez:835-365-1284:454 Easy Street, Decatur, IL 75732:2/28/53:123500
Ephram Hardy:293-259-5395:235 CarltonLane, Joliet, IL 73858:8/12/20:56700
James Ikeda:834-938-8376:23445 Aster Ave., Allentown, NJ 83745:12/1/38:45000
Barbara Kertz:385-573-8326:832 Ponce Drive, Gary, IN 83756:12/1/46:268500
Lesley Kirstin:408-456-1234:4 Harvard Square, Boston, MA 02133:4/22/62:52600
William Kopf:846-836-2837:6937 Ware Road, Milton, PA 93756:9/21/46:43500
Sir Lancelot:837-835-8257:474 Camelot Boulevard, Bath, WY 28356:5/13/69:24500
Jesse Neal:408-233-8971:45 Rose Terrace, San Francisco, CA 92303:2/3/36:25000
Zippy Pinhead:834-823-8319:2356 Bizarro Ave., Farmount, IL 84357:1/1/67:89500
Arthur Putie:923-835-8745:23 Wimp Lane, Kensington, DL 38758:8/31/69:126000
Popeye Sailor:156-454-3322:945 Bluto Street, Anywhere, USA 29358:3/19/35:22350
Jose Santiago:385-898-8357:38 Fife Way, Abilene, TX 39673:1/5/58:95600
Tommy Savage:408-724-0140:1222 Oxbow Court, Sunnyvale, CA 94087:5/19/66:34200
Yukio Takeshida:387-827-1095:13 Uno Lane, Ashville, NC 23556:7/1/29:57000
Vinh Tranh:438-910-7449:8235 Maple Street, Wilmington, VM 29085:9/23/63:68900


四、脚本练习题目:
(1)、要求编写一个脚本，请给出
系统使用的什么样的Linux系统。
系统内核版本多少 ，
当前登录的用户为：
系统有几块硬盘，每块硬盘的大小
系统内存总量多少
服务器的硬件型号
有几颗CPU，每颗CPU有多少个内核 

(2)、请编辑一个脚本，给出本机IP有多少IP地址。然后每个IP地址的子网掩码，
然后请给出本机的网关IP是多少？
效果输出如下：
本机IP地址有3个 
分别为： 
IPxxxxxx,子网掩码xxxx
IPxxxxxx,子网掩码xxxx
IPxxxxxx,子网掩码xxxx
网关地址为：IPXXXXX


(3)、请编写一个脚本，查看本机有几快硬盘，每块硬盘的分区有几个？
效果输出如下：
本机硬盘有3个
其中sda 有 5个分区
其中sdb 有 3个分区
其中sdc 有 2个分区

(4)、请编写一个脚本，给出目前内存的总使用量，剩余使用量，使用了多少？
效果输出如下：
Mem total:4G
Mem Use:3.2G
Mem free:0.8G

(5)、请编写一个脚本、给出每个程序占用超过0.2%的CPU资源，内存资源，要求
占用资源最大的前10位，
要求输出：
Use Mem:xxxx% 程序为:xxxxxxx
Use cpu:xxxx% 程序为:xxxxxxx


(6)、编写一个脚本，统计服务器IP的链接数，以及每个IP连接状态。


(7)、编写一个脚本，统计/etc/passwd 有多少系统用户，每个系统用户是否拥有登录系统的权限？
效果输出为：
用户：root  拥有登录系统权为：YES
用户：root  拥有登录系统权为：NO




















222
案列1、测试/tmp/aa目录是否具备读和写权限？
如果没有告诉用户是否需要更改权限，不更改权限直接退出，
更改权限，请提示是否更改成功，或者失败？


案列2、测试/etc/passwd 有多少个bash权限的用户，请打印出来，
有多少nologin的用户，请打印出来，nologin用户：有多少个,
判断/etc/passwd 是否有apache存在，存在的话请告诉用户。
如果不存在则告诉用户没有，



案列3、向脚本传递参数，参数值为：个人名字，和年龄.
脚本请判断传值进来的参数必须得是2个，多了。或者少了，直接提示
错误，然后退出，如果传值的参数正确，请判断年龄是否为数字
，否则非数字的话，直接退出。如果是的话，则把传来的2个参数
打印出来给用户看.


案列4、检查当前登录的用户是否为root，如果是的话告诉用户
root为超级管理用户，如果不是，请告诉用户当前登录的用户名，
以及用户为普通用户。

案列5、在/tmp/创建一个目录为aatest目录，将/tmp/aatest目录移动
到/opt下面，脚本请先判断是否有/tmp和/opt目录，在判断是否/tmp/aatest目录
如果有将/tmp/aatest目录移动到/opt下面，移动是否成功，请给出提示。

案列7、编写一个脚本，检查在你网段的用户，有多少个用户是可以进行网络通信的，
那些能通信的。检查它们是否开放了22端口，80端口，20、21端口。然后检查你的本地连接，
有哪人(IP)连接过来了?然后将这些IP以及每个IP连接的数量以及状态。反馈给用户.



案列8、编写一个脚本，创建一个/tmp/misc的目录，创建100个目录，目录名字为m1~m100
，在对应的m1~m100分别创建对应的mp3_1.txt~mp3_2.txt文件,
然后找所有关于.txt文件，将他们改成gongda1.txt~gongda100.txt。



案列9、编写一个脚本。菜单为：
1、创建用户
2、创建目录
3、创建文件
4、修改目录权限
5、修改文件权限
6、删除目录或者文件
7、退出

案例10、编写一个脚本，全自动安装samba服务，共享的目录。由用户输入，
脚本根据用户的输入自动判断。然后写到samba配置文件，访问samba统一用户为:root
密码为:123456，脚本全自动启动服务，请告诉用户samba服务是否运行成功。


案例11、编写一个脚本。全自动安装vsftpd，配置完vsftp之后。每次只能限制一个参数传入。。
然后请确定参数的路径是否正确，然后根据传入的参数自动配置ftp文件，配置用户和密码，
最后效果如下： 
你可访问的FTP目录为：xxxxxx
你可访问FTP用户为:xxxxxx
你可访问FTP用户密码为:xxxxxx













333
1、编写一个shell脚本，完成功能：
1）显示文字“Waiting? for?a?while….”?
2）长格式显示当前目录下面的文件和目录，并输出重定向到/home/file.txt文件?
3）定义一个变量，名为s，初始值“Hello”
4）使该变量输出重定向到/home/string.txt文件


2、编写一个shell脚本，它把第二个位置参数及其以后的各个参数指定的文件复制到第一个位置参数指定的目录中。??



3、编写一个shell脚本，利用for循环将当前目录下的.c文件移动到指定的目录，并按文件大小显示出移动后指定的目录的内容
?

4、利用数组形式存放10个城市的名字，然后利用for循环把它们打印出来。?



5.写一个脚本，执行后，打印一行提示“Please input a number:"，
要求用户输入数值，然后打印出该数值，然后再次要求用户输入数值。直到用户输入"end"停止


6、编写一个备份脚本，全量备份/opt/test目录，然后根据年月日压缩bz2的压缩包。
请修改根据时间进行测试，每天临晨1.30开始备份，然后最后把压缩包放入/backup 目录.


7、设计一个Shell程序，在/userdata目录下建立50个目录，即user1～user50，
并设置每个目录的权限，其中其他用户的权限为：读；文件所有者的权限为：读、
写、执行；文件所有者所在组的权限为：读、执行。

8、请编写一个脚本，当磁盘/ 目录占用的空间超过70%的时候。给出邮件警告，
超过80%的时候给出邮件，为严重级别。


9、编写一个脚本统计每个程序用的swap资源。

10、取出password中shell出现的次数
方法结果
/bin/sync       出现了：1次 
/bin/bash       出现了：1次1
/sbin/nologin   出现了：30次 
/sbin/halt      出现了: 1次 
/sbin/shutdown  出现了: 1次 


11、文件整理employee文件中记录了工号和姓名
employee.txt: 

100 Jason Smith  
200 John Doe  
300 Sanjay Gupta  
400 Ashok Sharma  
bonus
文件中记录工号和工资
bonus.txt: 
100 $5,000  
200 $500  
300 $3,000  
400 $1,250  

要求把两个文件合并并输出如下
 处理结果
: 
400 ashok sharma $1,250 

100 jason smith $5,000 

200 john doe $500 

300 sanjay gupta $3,000 

12、编写个shell脚本将当前目录下大于10K的文件转移到/tmp目录下



第八节  变量的使用
为使s h e l l编程更有效，系统提供了一些 s h e l l变量。s h e l l变量可以保存诸如路径名、文件
名或者一个数字这样的变量名。s h e l l将其中任何设置都看做文本字符串。
有两种变量，本地和环境。严格地说可以有 4种，但其余两种是只读的，可以认为是特殊
变量，它用于向s h e l l脚本传递参数。
本章内容有：
? shell变量。
? 环境变量。
? 变量替换。
? 导出变量。
? 特定变量。
? 向脚本传递信息。
? 在系统命令行下使用位置参数。
变量可以定制用户本身的工作环境。使用变量可以保存有用信息，使系统获知用户相关
设置。变量也用于保存暂时信息


二、本地变量在用户现在的 s h e l l生命期的脚本中使用。例如，本地变量 f i l e - n a m e取值为
l o o p . d o c，这个值只在用户当前s h e l l生命期有意义。如果在s h e l l中启动另一个进程或退出，此
值将无效。这个方法的优点就是用户不能对其他的 s h e l l或进程设置此变量有效
1、变量赋值，
#aa="abcd"

2、显示变量，变量引用需要加$符号
#echo ${aa}  标准取变量写法
#echo $aa    非标准写法，两者效果相同

3、清除变量
#unset aa
#echo $aa 这个时候$aa变量已经为空

4、显示本地所有的变量
# set 

5、变量输出结合
#aa="My"
#bb="name"
#cc="is"
#dd="Alvin"
# echo ${aa} ${bb} ${cc} ${dd}  
# test="$aa $bb $cc $dd"
# echo $test

6、使用变量来保存系统文件路径，或者目录路径
# aa="/tmp/"
# ls $aa
# aa="/tmp/1.txt"
# ls $aa

三、环境变量
环境变量用于所有用户进程（经常称为子进程）。登录进程称为父进程。 shell中执行的用
户进程均称为子进程。不像本地变量（只用于现在的 shell）环境变量可用于所有子进程，这
包括编辑器、脚本和应用。
环境变量可以在命令行中设置，但用户注销时这些值将丢失，因此最好在
. profile文件中
定义。系统管理员可能在 /etc/profile文件中已经设置了一些环境变量。将之放入 profile文件意
味着每次登录时这些值都将被初始化。
传统上，所有环境变量均为大写。环境变量应用于用户进程前，必须用 export命令导出。
环境变量与本地变量设置方式相同

#vim /tmp/test.sh
#!/bin/bash
ls /tmp/

# mv /tmp/alvin.sh /tmp/alvin
# vim /etc/profile
aa="/tmp/"
PATH=$PATH:$aa
export PATH
# source /etc/profile

如果不写入/etc/profile 。那么直限于当前
环境Shell生效。




第九节 传参数
本章开始提到有4种变量，本地、环境，还有两种变量被认为是特殊变量，因为它们是只
读的。这两种变量即为位置变量和特定变量参数。先来看一看位置变量。

一、向脚本传递参数
如果要向一个shell脚本传递信息，可以使用位置参数完成此功能。参数相关数目传入脚
本，此数目可以任意多，但只有前 9个可以被访问，使用 shift命令可以改变这个限制。本书后
面将讲到shift命令。参数从第一个开始，在第 9个结束；每个访问参数前要加 $符号。第一个
参数为0，表示预留保存实际脚本名字。无论脚本是否有参数，此值均可用。
如果向脚本传送Did You See Th e Full Mo o n信息，下面的表格讲解了如何访问每一个参
数。
$0        $1       $2      $3      $4      $5     $6     $7     $8     $9
脚本名字  Did      You    See      The     Full   Moon

案例1:
后面的$7 $8 $9依此类推
#vim /test.sh
#!/bin/bash
echo "$0"
echo "$1"
echo "$2"
echo "$3"
echo "$4"
echo "$5"
echo "$6"
[root@Master /]# ./test.sh  Did you see the Full moon
./test.sh
Did
you
see
the
Full
moon

案例2:
#vim /test1.sh
#!/bin/bash
ls $1

传参数值为/tmp
[root@Master /]# ./test1.sh /tmp
1.log  1.txt  alvin  ssh-mXQMTo3363  yum.log

二、特定变量参数
$!  Shell最后运行的后台Process的PID 
$- 显示shell使用的当前选项，与set命令功能相同
#==============================================
$#  传递到脚本的参数个数，是个数。注意咯。和$@是有区别的
$@  与$#相同，但是使用时加引号，并在引号中返回每个参数值
#!/bin/bash
if [ $# -eq 1 ]
then
    aa="$@"
    if [ $aa == "alvin" ]
    then
        echo $aa
    else
       echo "参数传输虽然等于1，但是$1值不等于alvin"
       exit 1
    fi
else
    echo "参数鼻息是一个参数"
    exit 1
fi



$*  以一个单字符串显示所有向脚本传递的参数。与位置变量不同，此选项参数可超过 9个，
[root@Master /]# cat aatest.sh 
#!/bin/bash
echo $*
[root@Master /]# ./aatest.sh 1 2 3 4 5 7 8 9 10
1 2 3 4 5 7 8 9 10

$$  脚本运行的当前进程ID号
[root@Master /]# cat aatest.sh 
#!/bin/bash
echo $$
[root@Master /]# ./aatest.sh 
3520

$? 显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误
# ls /tmp/ && echo $?



第十节 单引号 双引号  反斜线 等符号的使用
一、概述：
在脚本中执行变量替换时最容易犯的一个错误就是由于引用错误。在命令行中各种引用是很重要的。
由此引号体现了它的重要性。
引用的必要性。
? 双引、单引和反引号。
? 使用反斜线实现屏蔽

shell引用类型
" "双引号   可以转义单引号
｀反引号       
' '单引号      可以转义双引号
\反斜线


1、双引号
使用双引号可引用除字符$、`、\外的任意字符或字符串。这些特殊字符分别为美元符号，
反引号和反斜线，对 shell来说，它们有特殊意义。如果使用双引号将字符串赋给变量并反馈
它，实际上与直接反馈变量并无差别。

#aatest="/etc/passwd"
#echo "$aatest"

[root@Master /]# cat /etc/passwd | grep -E "root|bash"  #有双引号输出
root:x:0:0:root:/root:/bin/bash
operator:x:11:0:operator:/root:/sbin/nologin


[root@Master /]# cat /etc/passwd | grep -E root|bash   #无双引号输出
bash: line 1: root:x:0:0:root:/root:/bin/bash: 没有那个文件或目录
bash: line 2: operator:x:11:0:operator:/root:/sbin/nologin: 没有那个文件或目录



2、 单引号
单引号与双引号类似，不同的是 s h e l l会忽略任何引用值。换句话说，如果屏蔽了其特殊
含义，会将引号里的所有字符，包括引号都作为一个字符串。使用上一个例子，结果如下：
[root@Master /]# aa='This is desk "alvin"'
[root@Master /]# echo $aa
This is desk "alvin"

思考一下。如果这个地方是用但引号。怎么办？
aa='this's desk'  这个变量能使用吗？试试看。


3、反引号
反引号用于设置系统命令的输出到变量。 s h e l l将反引号中的内容作为一个系统命令，并
执行其内容。使用这种方法可以替换输出为一个变量。反引号可以与引号结合使用。

# aa="date"
# echo $aa
尝试一下上面和下面这个语句有什么不同？
# aa=`date`
# echo $aa


4、 反斜线
如果下一个字符有特殊含义，反斜线防止 shell误解其含义，即屏蔽其特殊含义。下述字
符包含有特殊意义：& * + ^ $ ` " | ?。
假定echo命令加*，意即以串行顺序打印当前整个目录列表，而不是一个星号 *。

[root@Master /]# echo *
@ 1.py aatest.sh backup bin boot C cgroup dev etc home lib lib64 lost+found media mnt oops.txt opt proc python root sbin selinux srv sys test1.sh test.sh test.txt tmp usr var
[root@Master /]# echo \*
*

[root@Master /]# echo $$
3365
[root@Master /]# echo \$$
$$

[root@Master /]# expr 12 * 12
expr: 语法错误
[root@Master /]# expr 12 \* 12
144

小结
在引用时会遇到一些问题且经常出错。我在使用引用时遵循两条规则：
1) 反馈字符串用双引号；但不要引用反馈本身。
2) 如果使用引用得到的结果不理想，再试另一种，毕竟只有三种引用方式，可以充分尝
试

第十一节 判断相关TEST [ ]  大于 等于 EXPR的使用
写脚本时，有时要判断字符串是否相等，可能还要检查文件状态或是数字测试。基于这
些测试才能做进一步动作。Test命令用于测试字符串，文件状态和数字，也很适合于下一章将
提到的if、then、else条件结构。


1、test命令测试文件状态
文件状态测试-d目录
-s文件长度大于0、非空
-f正规文件
-w可写
-L符号连接
-u文件有suid位设置
-r可读
-x可执行
 test一般有两种格式，即：
test condition 或 [ condition ]

第一种方式：
# mkdir /shell && cd /shell
# touch 1.txt
# test -w 1.txt;echo $?
# test -s 1.txt;echo $?
# test -f 1.txt;echo $?
# test -L 1.txt;echo $?
# test -u 1.txt;echo $?
# test -r 1.txt;echo $?
# test -x 1.txt;echo $?




第二种方式：
#[ -w 1.txt ];echo $?
#[ -s 1.txt ];echo $?
#[ -f 1.txt ];echo $?
#[ -L 1.txt ];echo $?
#[ -u 1.txt ];echo $?
#[ -r 1.txt ];echo $?
#[ -x 1.txt ];echo $?



2、测试时使用逻辑操作符
测试文件状态是否为OK，但是有时要比较两个文件状态。 shell提供三种逻辑操作完成此
功能。
-a 逻辑与，操作符两边均为真，结果为真，否则为假。
-o 逻辑或，操作符两边一边为真，结果为真，否则为假。
! 逻辑否，条件为假，结果为真.

#[ -w 1.txt -a -w 2.txt ];echo $?  
1.txt 和2.txt必须都用有-w可写的权限。返回至才为0，
否则非0，-a 通俗理解就是“和 和xxxx同时拥有-w 权限”

#[ -x 1.txt -o -x 2.txt ];echo $? 
1.txt 和 2.txt只要其中一个具备-x 满足则返回0
通俗理解就是“-o 或 或者的意思”

# [ ! -x 2.txt ];echo $? 
!就是取返的意思，如果2.txt 没有-x权限，则返回0
否则返回1




3、字符串测试
字符串测试是错误捕获很重要的一部分，特别在测试用户输入或比较变量时尤为重要。
字符串测试有5种格式：
= 两个字字符串相等
! = 两个字符串不等
-z 空串
-n 非空串 

#aa="1"
#bb="2"
#[ "$aa" = "$bb" ];echo $?

#aa="1"
#bb="1"
#[ "$aa" != "$bb" ];echo $?

#aa="1"
#[ -z "$aa" ];echo $?

#aa="1"
#[ -n "$aa" ];echo $?


4、测试数值
测试数值可以使用许多操作符，一般格式如下：
-eq 数值相等。
-ne 数值不相等。
-gt 第一个数大于第二个数。
-lt 第一个数小于第二个数。
-le 第一个数小于等于第二个数。
-ge 第一个数大于等于第二个数。

3 文件的判断
-r file　　　　　用户可读为真
-w file　　　　　用户可写为真
-x file　　　　　用户可执行为真
-f file　　　　　文件为正规文件为真
-d file　　　　　文件为目录为真
-c file　　　　　文件为字符特殊文件为真
-b file　　　　　文件为块特殊文件为真
-s file　　　　　文件大小非0时为真
-t file　　　　　当文件描述符(默认为1)指定的设备为终端时为真
3、复杂逻辑判断
-a 　 　　　　　 与
-o　　　　　　　 或
!　　　　　　　　非



#aa="1"
#[ "$aa" -eq "1" ];echo $?

#aa="1"
#[ "$aa" -ne "1" ];echo $?

#aa="1"
#[ "$aa" -gt 1 ];echo $?

#aa="1"
#[ "$aa" -lt 1 ];echo $?

#aa="1"
#[ "$aa" -le 1 ];echo $?

#aa="1"
#[ "$aa" -ge 1 ];echo $?





5、expr用法
expr命令一般用于整数值，但也可用于字符串。一般格式为:
#expr 10 + 10  注意空格
#expr 900 + 600
#expr 30 / 3
#expr 30 / 3 / 2
#expr 30 \* 3

判断aa变量里面是否为数字
#aa="xx"
#expr $aa + 1;echo $? 2

#vim test.sh
#!/bin/bash
echo -n "Please you enter you old:"
read zytest
cc=`expr $zytest + 1 >/dev/null 2>&1;echo $?`
if [ "$cc" -eq 0 ]
then
     echo "you old is:$zytest"
else
       echo "Enter error,old must be number"
       exit 1
fi


第十二节  IF 语句的部分使用方法    。。。。。
一、所有功能脚本必须有能力进行判断，也必须有能力基于一定条件处理相关命令。本章讲
述这方面的功能，在脚本中创建和应用控制结构。


1、if then elif or else语句
i f语句测试条件，测试条件返回真（0）或假（1）后，可相应执行一系列语句。 i f语句结
构对错误检查非常有用。其格式为：
if 条件1
then 命令1
elif 条件2
then 命令2
else 命令3
======================================
If 条件1 如果条件1为真
Then 那么
命令1 执行命令1
elif 条件2 如果条件1不成立
then 那么
命令2 执行命令2
else 如果条件1，2均不成立
命令3 那么执行命令3
fi 完成

案列1：/tmp/aa目录是否存在，如果存在告诉用户，
不存在提示用户是否需要创建？ 如果不创将直接退出。
创建的话，提示信息，是创建成功？还是创建失败
if [ -d /tmp/aa ]
then
    echo "/tmp/aa already exisits"
else
    echo "The /tmp directory have't aa"
        echo -n "Do you Create it?:[Y:N]"
           read ctaa
        if [ "$ctaa" == "Y" -o "$ctaa" == "y" ]
        then
            mkdir /tmp/aa
                if [ $? -eq 0 ]
                then
                   echo "create $zytest OK.."
                else
                   echo "`basename $0` create $zytest fail.."
                fi

        else
            exit 1
        fi
fi
~                                                                                                                                   
案列2、测试/tmp/aa目录是否具备读和写权限？
如果没有告诉用户是否需要更改权限，不更改权限直接退出，
更改权限，请提示是否更改成功，或者失败？


案列3、测试/etc/passwd 有多少个bash权限的用户，请打印出来，
有多少nologin的用户，请打印出来，nologin用户：有多少个,
判断/etc/passwd 是否有apache存在，存在的话请告诉用户。
如果不存在则告诉用户没有，



案列4、向脚本传递参数，参数值为：个人名字，和年龄.
脚本请判断传值进来的参数必须得是2个，多了。或者少了，直接提示
错误，然后退出，如果传值的参数正确，请判断年龄是否为数字
，否则非数字的话，直接退出。如果是的话，则把传来的2个参数
打印出来给用户看.


案列5、检查当前登录的用户是否为root，如果是的话告诉用户
root为超级管理用户，如果不是，请告诉用户当前登录的用户名，
以及用户为普通用户。

案列6、在/tmp/创建一个目录为aatest目录，将/tmp/aatest目录移动
到/opt下面，脚本请先判断是否有/tmp和/opt目录，在判断是否/tmp/aatest目录
如果有将/tmp/aatest目录移动到/opt下面，移动是否成功，请给出提示。






  



第十三节  CASE语句的使用
case语句
case语句为多选择语句。可以用 case语句匹配一个值与一个模式，如果匹配成功，执行相
匹配的命令。case语句格式如下：
case 值 i n
模式1）
命令1
. . .
; ;
模式2）
命令2
. . .
；；
esac
case工作方式如上所示。取值后面必须为单词 in，每一模式必须以右括号结束。取值可以
为变量或常数。匹配发现取值符合某一模式后，其间所有命令开始执行直至；；。
取值将检测匹配的每一个模式。一旦模式匹配，则执行完匹配模式相应命令后不再继续
其他模式。如果无一匹配模式，使用星号 *捕获该值，再接受其他输入


echo "========欢迎来到湖南工业大学========"
echo "1、查询计算机专业的人数"
echo
echo "2、查询土木工专业的人数"
echo 
echo "3、查询包装设专业的人数"
echo
echo "4、查询学音乐专业的人数"
echo
echo "5、退出"
echo
echo -n "请输入要查询的序列号:"
read test
case $test in 
1)
echo "计算机专业人数为1000"
;;

2)
echo "包装设计专业人数为5000" 
;;

3)
echo "土木工程专业人数为 500"
;;

4)
echo "音乐专业人数为2000"
;;

5)
echo "已经退出"
;;

*)
echo "你输入有误"
;;
esac






第十四节 FOR 循环的不完全使用方法
18.5 for循环
for循环一般格式为：
for 变量名 in 列表
do
命令1
命令2
done

for loop in 1 2 3 4 5
do
  echo $loop
done

for loop in `seq 1 100`
do
  echo $loop
done

for loop in `ls /tmp`
do
   echo $loop
done

#!/bin/bash
IP="10.0.0."
for aa in `seq 1 20`
do
ping -c 1 $IP$aa >/dev/null 2>&1
if [ $? -eq 0 ]
then
    echo "$IP$aa is connection OK." >>iplist.log
else
    echo "$IP$aa is connection fail.." >>ipfail.log
fi
done
~         


第十五节 UNTIL  AND WHILE  的使用


                                        18.6 until循环


until循环执行一系列命令直至条件为真时停止。 until循环与while循环在处理方式上刚好
相反。一般while循环优于until循环，但在某些时候—也只是极少数情况下， until循环更加
有用。
until循环格式为：
until 条件
命令1
. . .
done
条件可为任意测试条件，测试发生在循环末尾，因此循环至少执行一次—请注意这一
点。

#!/bin/bash
aa=`df -lh | awk '{print $5,$NF}' | grep "/$" | sed -e 's/[%]//g' | awk '{print $1}'`

until [ "$aa" -lt "80" ]  #如果少于80%则不执行循环
do
    echo "Filesystem / use 80%"
    exit 1
done
echo "Filesystem 小于80%"

                              
                              
                                  18.7 while循环




while循环用于不断执行一系列命令，也用于从输入文件中读取数据，其格式为：
while 命令
do
命令1
命令2
. . .
done
虽然通常只使用一个命令，但在 while和do之间可以放几个命令。命令通常用作测试条
件。
只有当命令的退出状态为 0时，do和done之间命令才被执行，如果退出状态不是 0，则循
环终止。
命令执行完毕，控制返回循环顶部，从头开始直至测试条件为假。

#!/bin/bash
while true
do
echo -n "Plase enter you number:"
read cc
   if [ $cc -lt 10 ]
   then
      echo "$cc -lt 10"
      continue
   else
      echo "$cc -gt 10"
      break
   fi
done

#!/bin/bash
echo -n "Plase enter you number:"
read cc
while [ $cc -gt 10 ]
do
    echo "yes"
    break
done
 

第十六节
exit 1  


./xxxx  -t

SERVICE


第一章 系统的开机流程
                             第1章 系统的开机流程
一、开机流程
(1)、Power on 开启电源


(2)、启动主板上的BIOS，初始化硬件:
显卡、CPU、内存、硬盘等等，同时也开始查找启动介质，
USB CD-ROM、HDD、PEX..

(3)、读取MBR(master boot record)有称为主引导记录，
MBR 512个字节，446 64 2字节
466字节，因为MBR空间有限，并不能用来存放我们的Linux核心，这里存储了一个小程序
LILO 目前被淘汰了
grub 最常用的.

64个字节，分区表，可以几个记录？(4个记录)

(4)、加载grub(grand unified boot loader) 通过grub来加载Linux内核
grub有几个重要的文件:
         stage1  用来引导和装载stage2，并且控制权交给stage2
         stage1.5 一个通道。用来链接stage1和stage2的.
         stage2  是整个grub的核心，比如：提供菜单，、读取配置文件，用户可以通过菜单的方式调整参数以供系统加载，
       引导顺序:stage1--->stage1.5--->stage2

(5)、加载Linux内核，模块、库之类的，同时检测挂在点，执行rc.local内容，内核进行硬件资源分配.


(6)、加载Shell，进行验证用户和登录

总结:
1、加载BIOS程序，获取启动顺序，找到第一个启动设备
2、读取第一个启动设备的MBR区域的信息，里面有GRUB、LILO引导程序
3、加载核心、开始驱动硬件，并且分配硬件资源
4、执行/sbin/init程序，产生init进程
5、启动核心外的模块以及库,/etc/modeprobe.conf
6、init执行相应运行级别的scripts，并且加载rc.local
7、执行/bin/login程序，等待用户登录.



二、Linux启动运行级别
0-->关机
1-->单用户模式
2-->多用户模式
3-->纯文本模式
4--->unused<系统保留>
5--->图形界面
6--->重启
默认是:5



三、/etc/rc.d/rc.sysinit 
1、获取网络环境与主机类型
  首先读取/etc/sysconfig/network 变量，这里包含了(
主机的名称和默认网关)

2、测试与载入内存设备/proc以及USB设备/sys

3、决定是否启用SELINUX

4、接口设备得见测与即插即用的参数调试

5、用户定义模块的加载

6、加载核心的设置

7、设置系统时间(clock)

8、设置终端控制台

9、设置RAID与LVM等硬盘功能

10、以FSCK检验磁盘文件系统

11、进行磁盘配额的转换

12、重新以读取模式载入系统磁盘

13、启动quota功能

14、启动系统随机数设备

15、清楚启动过程中临时文件

16、将启动相关信息加载到/var/log/dmesg文件中 


四、分析grub的配置文件
配置文件位置？
default=0  表示默认第一个菜单启动，default=1  表示第二个映像所指定的系统，一次类推

timeout=5  在引导之前，提示等待多少秒

splashimage=(hd0,0)/grub/splash.xpm.gz   #GRUB背景图片所在位置

hiddenmenu  隐藏grub菜单

title Red Hat Enterprise Linux (2.6.32-358.el6.x86_64) 系统标识

root (hd0,0) 操作系统内核和引导文件所在的磁盘分区，(hd0,0)表示从第一块硬盘的第一个分区 ，
(hd0,2)第一块硬盘的第3个分区，一次类推...

kernel /vmlinuz-2.6.32-358.el6.x86_64 ro root=UUID=c28805ee-f6f5-44e9-996f-147580d10b09 rd_NO_LUKS  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_MD crashkernel=128M LANG=zh_CN.UTF-8 rd_NO_LVM rd_NO_DM rhgb quiet
系统内核及boot命令用的启动参数

initrd /initramfs-2.6.32-358.el6.x86_64.img 系统引导程序


本章练习题：
1、简述 Linux系统开机的启动流程? （次题目载企业面试题目上，出现的频率高达85%以上)

2、简述Linux下有几种启动模式？默认的是哪一个？如何修改？

3、Grub stage1和stage1.5、stage2.0这三个文件的作用是什么。相互有什么关联？

4、如果root密码忘记了？怎么样修改？如何解决？请大概描述你的思路..





















第二章 网路配置及网络工具使用
                             第2章 网络配置及网络工具使用
一、网络参数修改工具
(1)、ifconfig 查询和设定网卡IP等参数
# ifconfig
Link encap:Ethernet  HWaddr 00:30:67:F2:11:32  #硬件Mac地址
inet addr:10.0.2.253  Bcast:10.0.255.255  Mask:255.255.0.0 #ip 广播地址 子网掩码

inet6 addr: fe80::230:67ff:fef2:1132/64 Scope:Link #IPV6地址
UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1 #最大传输的数据包
RX packets:10945341 errors:0 dropped:0 overruns:0 frame:0    #RX   接收
TX packets:15578498 errors:0 dropped:0 overruns:0 carrier:0  #TX 发送
collisions:0 txqueuelen:1000 #代表封包碰撞情况，如果次数太多，说明你的网络不太好。
RX bytes:1683846326 (1.5 GiB)  TX bytes:15245870737 (14.1 GiB)
RX 网卡接收总数据和TX发送出去的总数据。

临时增加IP地址
# ifconfig eth1:0 10.0.0.204 netmask 255.255.0.0 

关闭一个临时的网络接口
# ifconfig eth1:0 down 


(2)、ifup ifdown 可以简单的启动和关闭网络接口
# ifdown eth1 关闭网络接口
# ifup   eth1 启动网络接口


(3)、查询路由表和设定路由表
# route -n 单纯的查看路由表

增加一条路由
# route add -net 192.168.3.0 netmask 255.255.255.0 dev eth1 

删除一条路由
# route del -net 192.168.3.0 netmask 255.255.255.0 dev eth1

增加一个默认网关
# route add default gw 192.168.3.254 

(4):ip复合指令，包含以上所有功能。
# ip link show  显示MTU相关信息
# ip -s link show eth1 查看某接口流量信息
# ip add list 查询ip地址信息
# ip add list eth1 查询某网络接口的信息
# ip add show 查询ip地址信息 
# ip add show eth1 查询某网络接口的信息
临时增加IP地址
# ip add add 192.168.3.64/24 dev eth1:0

删除临时IP地址
# ip add del 192.168.3.64/24 dev eth1:0

查看路由表 
# ip route show
增加一条路由
# ip route add 192.168.5.0/24 dev eth1 
删除一条路由
# ip route del 192.168.5.0/24

#dhclient eth1  非静态的情况，可是使用此命令获取IP地址

二、网络排错与观察工具
(1)、PING
执行3次ping，发送3个包
# ping -c 3 10.0.2.253
# ping -c 3 -s 1000 -M do 10.0.2.253
# ping -c 3 -s 8000 -M do 10.0.2.253

(2)、tarceroue 路由跟踪
# traceroute -w 1 -n -T qq.com
-w 表示1秒没回复则表示不通
-n 不进行主机名称解析
-T 以TCP探测


(3)、netstat 查看本机的网络链接情况
OSTABLISED 以建立链接
SYS_SENT 发出主动链接(SYN标志)0的链接封包
SYS_RECV 接收到一个需要请求链接的包
FIN_WAIT1 socket已经中断，该联机在正断线当中
FIN_WAIT2 该链接以挂断，但是正在等待对方主机短线确认
TIME_WAIT 该链接以挂断，但是socket还在网络上等待结束
LISTEN 常用服务端口监听.

# netstat -an
# netstat -tunlp 

(4)、host和nslookup

# host www.baidu.com 把域名解析成IP地址
# nslookup www.baidu.com 把域名解析成IP地址

(5)、lsof 查看端口被那些进程占用
# yum -y install lsof
# lsof -i:80 查看那些进程占用了80端口
# lsof `which httpd` 查看哪个进程在使用apache的可以执行文件
# lsof /etc/passwd  查看哪个进程占用/etc/passwd
# lsof /dev/cdrom   查看进程占用光驱
# lsof -p 3873    显示那些文件被PID为3873的进程打开
# lsof -u1000     查看uid是1000的用户进程文件使用情况.
# lsof -utony     查看用户tony的进程的文件使用情况
# lsof -u^tony    查看用户不是tony的进程文件使用情况(^是去反的意思)

三、远程链接工具
(1)、telnet 命令
# yum -y install telnet
# telnet [HOST|PORT]
# telnet baidu.com 80
# telnet qq.com 80


(2)、ftp 和lftp lftp直接用匿名登录
#: ftp 10.0.2.253 需要输入用户名和密码
#: lftp 10.0.2.253 直接跳过，以匿名用户自动登录
dir 显示目录
get 下在一个文件
mget 下载多个文件
put 上传一个文件
delete file 删除一个文件
lcd 切换一个目录
bye  88。。

四、网页浏览工具
(1)links 命令可以打开网页
# yum -y install links
# links http://www.kernel.org

(2)wget 下载命令
#: wget http://xxxxxxx.tar.gz

五、抓包命令
#tcpdump -i lo -nn -X 'port 21' 监听21号端口的包


六、本章联系题目
本章练习题目:
1、常用的网络参数修改命令有哪些？
2、ipconfig 可以看到那些信息？
3、请查eth0或者eth1的详细信息
4、简单的启动和关闭网络接口用那些命令可以实现？
5、请关闭eth1或者eth0的网络接口在启动起来
6、查看本机地址的路由表，
7、使用route增加一条路由为192.168.3.0/24位
8、使用route 删除192.168.3.0/24这条路由
9、增加一个默认网关使用什么命令？
11、使用ip显出所有网络接口的信息
12、使用ip命令查看某个接口的信息
13、使用ip命令关闭eth0或者eth1接口 
14、使用ip命令启动eth1或者eth0接口
15、使用ip add list查看某个接口的详细参数
16、使用ip 查看路由表
17、使用ip增加一条路由为 192.168.5.0/24
18、使用ip删除一条路由为192.168.5.0/24
19、使用什么命令可以使网卡自动获取IP地址？
20、使用那些命令可以查看那网络的联通性？
21、想你的网关地址发送5次次ICMP的包，大小为1024
22、侦测网关的MTU值为多少？
23、使用什么命令侦测路由的跳数？并且使用该命令检测到qq.com大概有几跳路由？
24、使用路由侦测命令看看qq.com 80端口有多少跳
25、查看本网络连接情况如何查看？输出的信息有那些？分别代表什么？
26、请解析www.qq.com baidu.com 域名有多少个主机IP地址
27、查看本地的80端口是否被启用？那些进程占用了？？
28、查看/etc/passwd 有那些进程在使用？
29、查看root用户进程的文件使用情况
30、查看不是root用的进程文件使用情况
31、显出本地所有打开的端口
32、使用telnet连接baidu.com 80端口，并且退出
33、请合适的命令打开http://www.kernel.org
34、使用wget在网上随意下载一个包
35、Linux网络抓包用什么命令？
36、编写一个脚本，显示出本地有那些端口开放，是什么程序？使用的是TCP还是UDP？显示格式为：
Port:21 TCP/UDP:TCP CX:ftp 









第三章 DHCP
第3章DHCP服务
一、预备知识
(1)、什么是同一局域网
相同网络地址的主机为同一个局域网，同一个局域 之间的主机可以相互访问的。
非同一个局域网之间访问需要通过路由才能相互访问.

(2)、局域网内之算机之间的通信方式
单播
  1对1的通信，
组播
  1对多，但是同一个组里面
广播
  广播同一局域内所有的人都能听到.

二、DHCP工作原理
(1)、什么是DHCP
DHCP(dynamic host configure protocol)动态主机配置协议.

(2)、工作原理
 第一步:DHCP客户机以广告播的方式（因为dhcp的服务器IP地址对客户端是未知)
发送DHCP discover信息来寻找DHCP服务器，即向广播地址255.255.255.255发送一个特定的广播信息，只是安装了TCP/IP协议的主机都能接受到这种广播，只有DHCP服务器才作出回应.

 第二步:DHCP服务器响应客户端
  只要接受到DHCP discover信息都会作出响应，它从尚未出租 的IP地址当中挑选未分配的IP地址
，它是通过ARP广播确认该IP地址是否被使用？ 然后向客户机包含了出租IP地址以及其它DHCP offer信息.

 第三步：DHCP客户机发起请求
    如果在网络当中存在了多个DHCP服务器，它选择其中1个，DHCP客户机会接收到第一个收到DHCP offer信息，然后以广播方式回答一个dhcp request，这个信息当中包含了它选择的IP地址以及DHCP的IP地址,

 第四步:DHCP服务器和客户机确定关系
      DHCP和客户机确认组约关系，租约关系确认--》发送一个dhcp ack/dhcp nack包，以
dhcp ack包向客户机广播出去，当客户机确认了收之后，就配置自己的IP地址，完成初始化.

三、DHCP服务安装与配置
(1)环境:
DHCP服务器有2张网卡
server1(DHCP) 
1张网卡对外:10.0.0.201
2张网卡对内:192.168.3.10

server2(client)
1张网卡对外:10.0.0.202
2张网卡对内:DCHP全自动获取

(2)、DHCP安装
# yum -y install dhcp

(3)、拷贝配置文件
# cp /usr/share/doc/dhcp-4.1.1/dhcpd.conf.sample /etc/dhcp/dhcpd.conf 

(4)、编辑配置文件
# vim /etc/dhcp/dhcpd.conf 

ddns-update-style none; 配置DHCP-DNS为互动更新模式
default-lease-time 21600; 指定默认的租约时1间的长度，单位：秒
max-lease-time 43200;     指定默认的最大租约时间 单位：秒
option domain-name "master";  指定域名
option domain-name-servers 192.168.3.1; 指定给客户端分配的DNS

;创建192.168.3.0的网端
subnet 192.168.3.0 netmask 255.255.255.0 {  
  range 192.168.3.100 192.168.3.200;  给客户端分配的范围：100-200
  option subnet-mask 255.255.255.0;   给客户端指定的子网掩码
  option routers 192.168.3.1;         指定网关为192.168.3.1
}

(5)、启动DHCP服务
# /etc/init.d/dhcpd start


四、DHCP客户端配置
(1)、修改第2张网卡为DHCP自动获取
DEVICE="eth2"
BOOTPROTO=dhcp
NM_CONTROLLED="yes"
ONBOOT="yes"
TYPE="Ethernet"
DEFROUTE=yes
IPV4_FAILURE_FATAL=yes
IPV6INIT=no
NAME="System eth2"

(2)、重启network服务
# /etc/init.d/network restart

(3)、检查是否分配成功
# ip add list
# cat /etc/resolv.conf

五、SUDO权限
在企业当中，正常来说都是用户普通用户的身份在操作，如果偶尔也需要用root的权限，这个时候我们怎办法了？我们一起来看看sudo权限

(1)建立一个用户叫做alvin
# useradd alvin
# passwd alvin

(2)在/下面
$ cd / && touch 1.txt 是否权限？


(3)编辑/etc/sudoers
root    ALL=(ALL)       ALL
alvin   ALL=(ALL)       NOPASSWD: ALL  增加一行

(4)在切换到alvin用户

$ cd / && sudo touch 1.txt 是否权限？
$ sudo su - root  是否需要密码？


本章练习题目：
1、请简述DHCP的工作原理
2、企业需求搭建一个DHCP服务
环境：
server1 IP:192.168.3.20 <VMnet1> 
server2 IP:DHCP全自动获取 <VMnet1>
网段：192.168.3.0
网关为：192.168.3.1
DNS:192.168.3.1
IP范围:192.168.3.100~192.168.3.200
掩码:255.255.255.0
3、新建立一个用户为gongda1 切换到gongda1用户
(1)在/目录下创建1.txt是否可以成功？
(2)回到/root，编辑/etc/sudoers把gongda1加入进去。赋予sudo权限
并且要求跳过任何sudo用户的密码



第四章 SSH V
一、SSH服务简介
ssh为Secure Shell的缩写，由IETF的网络工作开发的，SSH建立在应用曾和传输曾的安全协议上.
ssh为系统安全和用户提供了有力的安全保障

二、SSH认证原理
(1)ssh链接的验证、加密方式
ssh链接CS模型(客户端-服务端)，客户端发起链接，服务端对客户端进行验证，再考虑是否要链接

(2) 加密体系：
一种公钥加密：对称的密码加密体系

一种私钥加密: 非对称密码加密体系

(2)ssh验证链接原理
   2.1 客户端向ssh服务器发出请求，服务端将自己的公钥返回给客户端
   2.2 客户端用服务端的公钥加密自己的登录密码，在将信息返回给服务器
   2.3 服务器收到客户端传送的密码，用自己的私钥解码，如果正确，则统一登录，建立起链接，错误则返回。拒绝登录。  

用户A要发送数据给用户B，主要一下步骤：
  第一：用户B通过各种方式向外界公开的公钥PUB_B
  第二：用户A得到用户B的公钥PUB_B 并且使用PUB_B对信息加密发送给用户B。
  第三: 用户B在收到秘文后，使用自己的私自钥进PRI_B就能完美解密

三、ssh安装方法
# yum -y install openssh


四、配置文件介绍
#Port 22  默认端口号，要改的话改成9000以上
#ListenAddress 0.0.0.0 监听主机网卡任何网端的ssh链接服务
#PermitRootLogin yes  如果改成NO 代表root用户禁止登录
#PubkeyAuthentication yes 去掉#号代表可以使用KEY进行登录


五、服务的重启和关闭
# /etc/init.d/sshd start
# /etc/init.d/sshd stop

六、配置案例
(1)密码链接方式
# ssh root@10.0.0.201

   重点：
(2)密钥方式
环境:
server1 10.0.0.201
server2 10.0.0.202
   2.1开启以key的方式登录
   2.2配置修如下:
   #PubkeyAuthentication yes 去掉#号代表可以使用KEY进行登录

   2.3分别在201和202创建用户为gongda
     # useradd gongda
     # passwd gongda
   2.4分别在201和202创建私钥和公钥
     #su gongda
     $ cd ~
     $ssh-keygen 
Generating public/private rsa key pair.
Enter file in which to save the key (/home/alvin/.ssh/id_rsa): 
Created directory '/home/alvin/.ssh'.
Enter passphrase (empty for no passphrase):  要求输入加密短语
Enter same passphrase again:                 再次要求输入加密短语 
Your identification has been saved in /home/alvin/.ssh/id_rsa. 产生的私钥
Your public key has been saved in /home/alvin/.ssh/id_rsa.pub. 产生的公钥
The key fingerprint is:
b0:94:a0:93:d7:2f:ca:6a:4e:c0:18:f9:1a:ab:19:8b alvin@master
The key's randomart image is:
+--[ RSA 2048]----+
|    .            |
| . o o .         |
|o + . =          |
|oo o . +         |
|+..   o S        |
| = . . .         |
|+ . o            |
|o=..             |
|Eoo              |
+-----------------+

     2.5分别在201上面
      # cat id_rsa.pub > authorized_keys  
      # chmod 644 authorized_keys
      # scp authorized_keys 10.0.0.202:/home/gongda/.ssh
 
     2.6 在201验证
      # ssh 10.0.0.202  是否还需要密码？
1.ssh-keygen
2.ssh-copy-id -i id_rsa.pub root@10.0.0.53 


現在的 ssh 使用同樣的方法會出現錯誤訊息

Agent admitted failure to sign using the key
 解決方式 使用 ssh-add 指令將私鑰 
加進來 （根据个人的密匙命名不同更改 id_rsa）
 # ssh-add   ~/.ssh/id_rsa  
 
给予权限也是必要的一步


七、配置案例
/etc/hosts.allow 允许
sshd:10.0.0.*:allow 在允许针对某一个服务 某些IP 可以访问这个服务

/etc/hosts.deny  拒绝
sshd:all:deny  先拒绝所有

当deny和allow相冲突的时候。以allow以准。


本章练习题目：
   企业SSH登录安全需求：
1、要求堡垒机那个以KEY的方式的登录
2、要求内部的WEB机器只能通过KEY的方式登录
3、外部禁止ROOT通过密码认证链接
4、内部可以同sudo方式进入ROOT权限







PROBLEM 1

    SSH登陆错误 WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!   
       


Connection to 192.168.10.20 closed.
[root@localhost ~]# ssh 192.168.10.88
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@     WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!      @
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!
Someone could be eavesdropping on you right now (man-in-the-middle attack)!
It is also possible that the RSA host key has just been changed.
The fingerprint for the RSA key sent by the remote host is
b6:0c:41:43:60:79:eb:05:9e:c9:72:1d:a0:41:9a:50.
Please contact your system administrator.
Add correct host key in /root/.ssh/known_hosts to get rid of this message.
Offending key in /root/.ssh/known_hosts:5
RSA host key for 192.168.10.88 has changed and you have requested strict checking.
Host key verification failed.

由于账户信息发生改变 
导致密钥发生改变

1.在客户端执行下述指令即可 #mv /root/.ssh/known_hosts  /tmp
2.当然也可以直接编辑known_hosts文件,把里面与所要连接IP(192.168.10.20)相关的内容删掉即可. 



SSH DENY
资源介绍：
SSH的安装及登录提示:connection refused的解决办法
2011-08-03 23:41:05 by 【6yang】, 90 visits, 收藏 | 返回
转载请注明出处：http://hi.baidu.com/leejun_2005/blog/item/fbc27c4b20e83d3a08f7ef23.html?timeStamp=1309179713928
from：http://hi.baidu.com/tunaisen/blog/item/85e0a41805ed9fb24bedbcf3.html
如果出现ssh: connect to host XX.XX.XX.XX port 22: Connection refused
请按如下步骤检查：
1、目标主机的ssh server端程序是否安装、服务是否启动，是否在侦听22端口；
检查方法：
june@ubuntu:~$ ps -ef|grep sshd
root      2859     1  020:29 ?        00:00:00 /usr/sbin/sshd -D
root      2901  2859  020:31 ?        00:00:00 sshd: june[priv]   
june      2971  2901  020:31 ?        00:00:00 sshd:june@pts/1    
june@ubuntu:~$
其中/usr/sbin/sshd为ssh clinet/server中server端的守护进程，如果上述结果中没有sshd出现，那么可能就是你的server端程序没有安装（Ubuntu 11.04 默认没有安装ssh server，只安装了ssh client），或者sshd服务没有启动，这两者的解决办法请见下文详述。
2、是否允许该用户登录；
3、本机是否设置了iptables规则，禁止了ssh的连入/连出；
检查方法：
june@ubuntu:~$sudo  iptables -L
[sudo] password for june: 
Chain INPUT (policy ACCEPT)
target    prot opt source               destination         
ACCEPT    tcp  --  anywhere             anywhere            tcp dpt:ssh 
 
Chain FORWARD (policy ACCEPT)
target    prot opt source              destination         
 
Chain OUTPUT (policy ACCEPT)
target    prot opt source              destination         
june@ubuntu:~$
4、查查ssh的配置文件
 ls -lrt /etc/ssh
针对第一点没有安装ssh server或者没开启sshd的用户，可以参考这篇：
Ubuntu如何开启SSH服务
SSH分客户端openssh-client和openssh-server
  如果你只是想登陆别的机器的SSH只需要安装openssh-client（ubuntu有默认安装，如果没有则sudo apt-get install openssh-client），如果要使本机开放SSH服务就需要安装openssh-server：sudo apt-get install openssh-server然后确认sshserver是否启动了：
ps -e |grep ssh
  如果看到sshd那说明ssh-server已经启动了。
  如果没有则可以这样启动：sudo /etc/init.d/ssh start
ssh-server配置文件位于/etc/ssh/sshd_config，在这里可以定义SSH的服务端口，默认端口是22，你可以自己定义成其他端口号，如222。
  然后重启SSH服务：
sudo /etc/init.d/ssh stop
sudo /etc/init.d/ssh start
  然后使用以下方式登陆SSH：
ssh tuns@192.168.0.100    tuns为192.168.0.100机器上的用户名，需要输入密码。
  断开连接：exit
完整过程如下所示：
june@~ 19:57:22>
ssh june@192.168.1.101
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@   WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
IT IS POSSIBLE THAT SOMEONE IS DOINGSOMETHING NASTY!
Someone could be eavesdropping on you rightnow (man-in-the-middle attack)!
It is also possible that a host key hasjust been changed.
The fingerprint for the RSA key sent by theremote host is
7f:57:35:cf:23:86:12:cb:e5:51:7a:a3:57:71:15:71.
Please contact your system administrator.
Add correct host key in/home/june/.ssh/known_hosts to get rid of this message.
Offending RSA key in/home/june/.ssh/known_hosts:8
RSA host key for 192.168.1.101 has changedand you have requested strict checking.
Host key verification failed.
june@~ 20:30:55>
june@~ 20:31:36>
rm /home/june/.ssh/known_hosts
june@~ 20:31:46>
ssh june@192.168.1.101
The authenticity of host '192.168.1.101(192.168.1.101)' can't be established.
ECDSA key fingerprint is50:9b:b7:15:c0:57:aa:d6:22:7c:97:40:6e:49:6e:94.
Are you sure you want to continueconnecting (yes/no)? yes
Warning: Permanently added '192.168.1.101'(ECDSA) to the list of known hosts.
june@192.168.1.101's password:
Welcome to Ubuntu 11.04 (GNU/Linux2.6.38-8-generic i686)
 
 *Documentation:  https://help.ubuntu.com/
 
Last login: Sat Jun 25 12:38:24 2011
june@ubuntu:~$

小总结


第五章 NTP
                                第5章NTP服务
一、什么是NTP？
NTP(Network Time Protocol)一种时间同步协议(全称网络时间协议). 它可以使计算机对其他服务器或者钟源做同步化。
它可以提高精准度比较高的一个时间校正，在LAN上与标准时间差小于1毫秒，WAN上几十毫秒。

二、NTP体系架构
Startum0(时间根服务器)--->Startum1(一级时间服务器)---->Startum2(二级时间服务器)xxxxxxx

三、NTP如何工作？
NTP提供准确时间的，它的时间来源可以有很多种方式“原子钟 天文台 卫星”等等。。
整个流程上面：
Startum0(时间根服务器)--->Startum1(一级时间服务器)---->Startum2(二级时间服务器)xxxxxxx 从顶级服务器源开始获取时间。进行分发同步，一级一级的往下分发.
Strtum时间层面也有限之，最大在15以内.
   在正常情况下NTP发出请求的时间与时间服务器交换的时间，这个交换结构由客户端计算出时间的延迟和它的一个值，大概在5分-10分钟和时间服务器有6次交换，一旦同步之后，每10分钟与时间服务器进行一次同步。


四、NTP服务器安装
4.1、安装NTP服务器
# yum -y install ntp

4.2、时间设置的相关配置文件
(1)/etc/ntp.conf NTP主服务的配置文件
(2)/usr/share/zoneinfo （此目录)规定个主要时区的时间设定文件，比如:中国大陆地区的时间设置文件是/usr/share/zoneinfo/Asia/Shanghai
(3)/etc/sysconfig/clock Linux的主要时区设定文件,Linux每次启动会自动读取这个文件来设定我们系统预设显示时间，此文件调用/usr/share/zoneinfo/Asia/Shanghai 这个文件。
(4)/etc/localtime 如果clock文件规定了使用的时间设定文件为/usr/share/zoneinfo/Asia/Shanghai，Linux操作系统将会将Shanghai这个文件复制一份到/etc/改名叫做/etc/localtime,所有系统的时间显示就会以Shanghai这个文件为标准。



4.3、基本时间命令
# date 时间显示和修改
# hwclock 
-r:查看现有BIOS时间
-w:将现在的Linux系统的时间写入BIOS当中。
当我们的Linux时间校对后，还要以hwclock -w将它写入BIOS当中。保持和系统时间的一致 。
# ntpdate，客户端和时间服务器同步的命令
ntpdate -d xxx.xxx.xx.x 调试命令，调试客户端和服务器同步是否正常？报什么错误？
ntpdate 10.0.0.201 表示。客户端从10.0.0.201上发送请求。要求同步时间。
# ntpq -p 显示NTP服务器与它的上级同步情况。
# chkconfig 
参数 
--add 增加所指定的服务，
--del 删除所指定服务
NetworkManager 	0:off	1:off	2:off	3:off	4:off	5:off	6:off
状态：off 代表关闭 on代表启动

以上代表解释如下：
0 关机    --》0:off 表示在这个模式下不启动此服务,
1 单用户模式--》1:off 表示在这个模式下不启动此服务,
2 多用户模式--》2:off 表示在这个模式下不启动此服务,
3 文本模式--》3:off 表示在这个模式下不启动此服务,
4 保留--》4:off 表示在这个模式下不启动此服务,
5 图形界面--》5:off 表示在这个模式下不启动此服务,
6 重启--》6:off 表示在这个模式下不启动此服务,

chkconfig --list  列出所有的服务启动级别
chkconfig --add httpd 增加http服务
chkconfig --level httpd 2345 on  
chkconfig --del httpd
chkconfig --level httpd 2345 off



五、NTP服务器的配置在NTP_Server端
restrict  设置权限的，
restrict IP 地址 mask 参数
ingore 关闭所有的NTP联机服务
nomodify 客户端不能更改服务端的时间参数
notrust 客户端除非通过认证。否则步能同步，将被视为不信任的子网。
noquery 步提供客户端的时间查询。


5.1、编辑ntp.conf配置文件
# vim /etc/ntp.conf
driftfile /var/lib/ntp/drift 与上1级时间服务器同步所花费的时间记录再此文件
restrict default kod nomodify notrap nopeer noquery
restrict -6 default kod nomodify notrap nopeer noquery
restrict 10.0.2.0 mask 255.255.0.0 nomodify   允许10.0.2.0 255.255.0.0网段访问
restrict 127.0.0.1 
restrict -6 ::1
restrict 10.0.2.201  指定NTPSERVER的地址
server 0.centos.pool.ntp.org  指定NTP上级的同步源
server 1.centos.pool.ntp.org  指定NTP上级的同步源
server 2.centos.pool.ntp.org  指定NTP上级的同步源
server	127.127.1.0	开启内部递归网络接口
fudge	127.127.1.0 stratum 10  #LCL步同步，startum最大步能超过15
includefile /etc/ntp/crypto/pw
keys /etc/ntp/keys


5.2、同步NTPserver本身的时间钟源
# ntdate 0.centos.pool.ntp.org


5.3、启动NTP服务
# /etc/init.d/ntp restart

5.4、随机启动
#chkconfig --add ntp
#chkconfig --level 235 on

5.5、查看NTP本身的源的一个同步情况
Every 2.0s: ntpq -p                                     Sun May 25 20:49:03 2014

     remote           refid	 st t when poll reach   delay   offset  jitter
==============================================================================
 dns.sjtu.edu.cn .INIT.          16 u    -   64    0    0.000    0.000   0.000
 dns1.synet.edu. 202.118.1.46     2 u   57   64    7   56.624  -368.17  42.908
 dns2.synet.edu. 202.118.1.46     2 u   58   64    5  162.209  -419.51  84.540
*LOCAL(0)        .LOCL.          10 l   61   64   17    0.000    0.000   0.000



remote 响应这个请求的NTP服务器名称，如果+代表也链接着上线，
refid  NTP服务器使用的上一级NTP的服务器IP地址
st  remote远程服务器的级别。
when 上一次请求成功后到现在的秒数
poll 本机和远程服务器多少时间进行一次同步(单位为秒)
reach  用来测试是否和服务器链接，每成功一次它的值就会增加一个


五、NTP服务器的配置在NTP_Client端操作
#:yum -y intall ntpdate
ntpdate NTP服务器的IP地址
# ntpdate 10.0.2.201 

# ntpdate -d 10.0.2.201 调试



六、本章练习题：
1、如何查看BIOS里面的时间
2、怎么样查看系统时间？怎么修改年月日和时分秒？
3、如何开机自动动NTP服务
4、怎么样将系统的时间同步到硬件BIOS？
5、如果NTPserver以1.centos.pool.ntp.org同步，该怎么做？
6、最后，搭建一个NTPserver服务器
 NTPserver同步源为：1.centos.pool.ntp.org
 NTPCient同步源为:NTP_server ，
编写一个计划任务，每15分钟同步一次。
















NTP
一、搭建时间同步服务器 
1、编译安装ntp server 
rpm -qa | grep ntp 
若没有找到，则说明没有安装ntp包，从光盘上找到ntp包，使用 
rpm -Uvh ntp***.rpm 
进行安装 
2、修改ntp.conf配置文件 
vi /etc/ntp.conf 
①、第一种配置：允许任何IP的客户机都可以进行时间同步 
将“restrict default nomodify notrap noquery”这行修改成： 
restrict default nomodify notrap 
配置文件示例：/etc/ntp.conf 
②、第二种配置：只允许192.168.211.***网段的客户机进行时间同步 
在restrict default nomodify notrap noquery（表示默认拒绝所有IP的时间同步）之后增加一行： 
restrict 192.168.211.0 mask 255.255.255.0 nomodify notrap 
3、启动ntp服务 
service ntpd start 
开机启动服务 
chkconfig ntpd on 
4、ntpd启动后，客户机要等几分钟再与其进行时间同步，否则会提示“no server suitable for synchronization found”错误。 
二、配置时间同步客户机 
手工执行 ntpdate <ntp server> 来同步 
或者利用crontab来执行 
crontab -e 
0 21 * * * ntpdate 192.168.211.22 >> /root/ntpdate.log 2>&1 
每天晚上9点进行同步 


附： 
当用ntpdate -d 来查询时会发现导致 no server suitable for synchronization found 的错误的信息有以下2个： 

错误1.Server dropped: Strata too high 
在ntp客户端运行ntpdate serverIP，出现no server suitable for synchronization found的错误。 
在ntp客户端用ntpdate –d serverIP查看，发现有“Server dropped: strata too high”的错误，并且显示“stratum 16”。而正常情况下stratum这个值得范围是“0~15”。 
这是因为NTP server还没有和其自身或者它的server同步上。 
以下的定义是让NTP Server和其自身保持同步，如果在/ntp.conf中定义的server都不可用时，将使用local时间作为ntp服务提供给ntp客户端。 

server 127.127.1.0 
fudge 127.127.1.0 stratum 8 
 

在ntp server上重新启动ntp服务后，ntp server自身或者与其server的同步的需要一个时间段，这个过程可能是5分钟，在这个时间之内在客户端运行ntpdate命令时会产生no server suitable for synchronization found的错误。 
那么如何知道何时ntp server完成了和自身同步的过程呢？ 
在ntp server上使用命令： 

# watch ntpq -p 

出现画面： 
Every 2.0s: ntpq -p                                                                                                             Thu Jul 10 02:28:32 2008 
     remote           refid      st t when poll reach   delay   offset jitter 
============================================================================== 
192.168.30.22   LOCAL(0)         8 u   22   64    1    2.113 179133.   0.001 
LOCAL(0)        LOCAL(0)        10 l   21   64    1    0.000   0.000  0.001 
注意LOCAL的这个就是与自身同步的ntp server。 
注意reach这个值，在启动ntp server服务后，这个值就从0开始不断增加，当增加到17的时候，从0到17是5次的变更，每一次是poll的值的秒数，是64秒*5=320秒的时间。 
如果之后从ntp客户端同步ntp server还失败的话，用ntpdate –d来查询详细错误信息，再做判断。 

错误2.Server dropped: no data 

从客户端执行netdate –d时有错误信息如下： 

transmit(192.168.30.22) transmit(192.168.30.22) 
transmit(192.168.30.22) 
transmit(192.168.30.22) 
transmit(192.168.30.22) 
192.168.30.22: Server dropped: no data 
server 192.168.30.22, port 123 

..... 
28 Jul 17:42:24 ntpdate[14148]: no server suitable for synchronization found出现这个问题的原因可能有2： 
1。检查ntp的版本，如果你使用的是ntp4.2（包括4.2）之后的版本，在restrict的定义中使用了notrust的话，会导致以上错误。 

使用以下命令检查ntp的版本： 
# ntpq -c version 

下面是来自ntp官方网站的说明： 
The behavior of notrust changed between versions 4.1 and 4.2. 
In 4.1 (and earlier) notrust meant "Don't trust this host/subnet for time". 
In 4.2 (and later) notrust means "Ignore all NTP packets that are not cryptographically authenticated." This forces remote time servers to authenticate themselves to your (client) ntpd 
解决： 
把notrust去掉。 


2。检查ntp server的防火墙。可能是server的防火墙屏蔽了upd 123端口。 
可以用命令 
#service iptables stop 
 

来关掉iptables服务后再尝试从ntp客户端的同步，如果成功，证明是防火墙的问题，需要更改iptables的设置。 

第六章 FTP


FTP
                                           第6章 FTP服务
一、什么是FTP？
ftp即是文件传输协议
   文件传输协议可以使得主机之间可以共享文件，FTP使用TCP生成一个虚拟链接用于控制链接，然后在生成一个单独的TCP链接用户数据传输，




二、控制链接与数据链接
一个完整的FTP 文件传输需要建立两种类型的链接，
(1)一种为文件传输下命令（称为:控制链接)
客户端希望与FTP服务器建立上传下载的数据传输时，它首先向服务器的TCP 21端口发起一个建立链接的请求，
FTP服务器接受来自客户端的请求，完成链接的建立过程，这样链接就称为FTP控制链接.

(2)一种为实现真正的文件传输(称为:数据链接)
FTP控制链接建立后，即可开始传输文件，传输文件的链接称为：FTP数据链接，FTP数据链接就是FTP传输数据的过程。

它有两种传输模式:
主动传输模式(PORT）
   主动模式下，FTP服务器使用20端口与客户端暂时端口进行链接，并传输数据，客户端只处于接收状态，
   (通俗说明：服务器主动链接客户端数据端口)
   
被动传输模式(PASV)
   被动模式下，FTP服务器打开一个状态端口，等待客户端对其进行连接，并传输数据，服务器并不参与数据的主动传输，只是被动接受.
   (通俗说明:ftp服务器被动等待客户端链接自己的数据端口)





三、工作原理
                      客户端发起请求
FTP客户端(端口1025)----------------------->(端口21)FTP服务端
(1)客户端向服务器发送链接请求，同时客户端动态的打开一个大于1024的端口等待服务器链接(比如:1025)
                      

                      双方建立链接
FTP客户端(端口1025)<----------------------->(端口21)FTP服务端
(2)若FTP服务器在21端口监听到请求，则会在客户端1025和服务器21端口之间建立链接

                   
FTP客户端(端口1025)<----------------------->(端口21)FTP服务端(控制链接)
FTP客户端(端口1026)<----------------------->(端口20)FTP服务端(数据链接)
                      开始传输数据
(3)当需要传输数据时，FTP客户端动态的打开一个大于1024的端口(比如:1026)服务端的数据端口20会主动链接客户端的1026端口，
并且在这两个端口之间传输数据，数据传输完毕，这两个口端20-1026链接会自动关闭
   也就说。每传输一次文件，就会建立一起一次链接，当文件传输完毕之后。会自动断开1026和20端口，自动断开。


FTP客户端---------xxxxx--------------FTP服务端 FPT客户段关闭后。那么自动断开了21端口链接。
                会话终止，链接终断
(4)当FTP客户端断开与FTP服务器链接时，链接即将被释放终止掉。




四、ASCII和BINDRY传输模式
ASCII和BINDRY两种传输模式的区别:
 ascii 传输方式:作相应的转换，ascii模式传输时会将其他系统下的回车换行符转换为本机回车字符，适合传输：html文件与文本文件
 Bindry传输方式:源封不动的传输文件，不作任何转换，比较适合传输执行文件、压缩文件和图片文件（那么也可已传输ascii所支持的文件传输)
   如果你用ascii模式传执行文件、压缩文件、会显示一堆乱码、损坏文件，一般来说，我们最好都用binary方式，这样可以保证不出错，
如果有本文本格式转换的问题，即UNIX格式的文本和DOS的文本之间转换，有很多工具可以作的。不要在ftp传输的时候冒险，尤其是你对这些东西不是非常清除的情况下.


五、FTP软件安装
安装vsftpd
# yum -y install vsftp*

安装 db_load加密工具
# yum -y install db4-utils


配置文件详解：
===================================================================
#ACCESS
listen=YES   //设置vsftpd服务器是否以standalone模式运行。以standalone模式运行是一种较好的方式，此时listen必须设置为YES，此为默认值，建议不要更改。
listen_port=21  //监听端口为21
local_enable=YES     //是否允许本地用户登录FTP服务器。默认为NO
write_enable=YES 开放本地用户写的权限 本地用户还可对根目录下的文件进行改写操作，一般配合chroot_local_user来作限制

#Security anonymous&chroot&userlist
anonymous_enable=NO    //允许匿名登陆 YES为允许 NO为禁止
anon_world_readable_only=NO //匿名用户浏览权限
download_enable=NO //禁止用户下载
anon_upload_enable=NO //是否开放上传权限。只有在write_enable设置为YES时，才有效果
anon_mkdir_write_enable=NO //是否允许匿名用户创建目录,只有在write_enable设置为    YES时有效
anon_other_write_enable=NO //是否允许匿名用户拥有删除除的权限，
anon_umask=022 //设置匿名用户新增文档的umask。默认077
chroot_local_user=YES // 本地用户只能在自家目录
chroot_list_enable=YES  当chroot_list_enable=YES，chroot_local_user=YES时，在/etc/vsftpd/chroot_list文件中列出的用户，可以切换到上级目录；未在文件中列出的用户，不能切换到站点根目录的上级目录。
chroot_list_file=/etc/vsftpd/user_list  前提是chroot_local_user=no，在文件中加入用户名
local_umask=022 //设置本地用户新增文档的umask，默认为022，对应的权限为755
guest_enable=YES  //如果开启，所有的非匿名用户以'guest'登录，一个'guest'登录后，会映射到guest_username指定文件中的用户上面
guest_username=user_00 //映射用户为user_00
user_config_dir=/etc/vsftpd/user_conf //允许你覆盖任何配置文件中的选项
pam_service_name=vsftpd //设置在PAM所使用的名称，默认值为vsftpd。

# Session & Connetion
idle_session_timeout=300 //设置多长时间不对FTP服务器进行任何操作，则断开该FTP连接，单位为秒，默认为600秒。
data_connection_timeout=120  //设置建立FTP数据连接的超时时间，默认为300秒。
accept_timeout=60 //设置建立被动（PASV）数据连接的超时时间，单位为秒，默认值为60。
connect_timeout=60 // PORT方式下建立数据连接的超时时间，单位为秒。
port_enable=NO 如果你想禁止通过PORT方法获取数据连接，可以设置为No，默认Yes 
pasv_min_port=50000  //在PASV模式下，可以分配给数据连接的最大端口号，默认0(可以使用任何端口)
pasv_max_port=51000   //在PASV模式下，可以分配给数据连接的最小端口号，默认0(可以使用任何端口)   
connect_from_port_20=YES 控制在PORT模式下，数据连接是否使用20端口。默认是No
ascii_upload_enable=YES   //如果开启，则以ASCII模式上传数据，默认No
ascii_download_enable=YES //如果开启，则以ASCII模式下载数据，默认No
hide_file={.ssh,.kde,.bash*,.vi*,.gt*,.em*}

#ftpd_banner=Signbook FTP service.
hide_ids=YES //如果开启，所有的用户和组信息在目录中被显示时，都会显示为ftp，默认No
ls_recurse_enable=NO //如果开启，则允许用户使用'ls -R'命令，默认No
use_localtime=YES    //如果开启，vsftp将会在显示目录时显示你的本地时间，默认No
file_open_mode=0777 //上传的文件具有的权限，默认0666
tcp_wrappers=YES //如果开启，vsftp支持tcp_wrappers，默认No
===================================================================


六、普通默认匿名访问
默认匿名用户只能下载，而且只能在自己的默认目录下，默认匿名用户:ftp 密码:ftp
#配置保持默认
# /etc/vsftpd/vsftpd.conf 
anonymous_enable=YES   //允许匿名登陆 YES为允许 NO为禁止
local_enable=YES     //是否允许本地用户登录FTP服务器。默认为NO
write_enable=YES 开放本地用户写的权限 本地用户还可对根目录下的文件进行改写操作，一般配合chroot_local_user来作限制
local_umask=022
dirmessage_enable=YES
xferlog_enable=YES
connect_from_port_20=YES
xferlog_std_format=YES
listen=YES
pam_service_name=vsftpd
userlist_enable=YES
tcp_wrappers=YES

#启动FTP
# /etc/init.d/vsftp start

#默认的FTP匿名目录为;
# /var/ftp

# ftp 10.0.0.201测试
put 文件上传
get 文件下载
mkdir 创建目录
rmdir 删除目录
delete 删除文件名

练习题目：
1、请根据配置文件详解，增加或者修改配置文件，允许匿名用户有创建目录的功能，然后测试。
2、请根据配置文件详解，增加或者修改配置文件put 云寻匿名用户拥有删除的目录的权限，然后测试
3、不允许匿名用户拥有创建目录，和删除目录的权限，只允许下载，不能上传。
4、禁止匿名用户、创建、删除 目录、下载目录，只能上传目录
5、禁止、创建目录、删除目录、下载、上传，最后禁止用户登录




















七、本地用户访问
可以自由的切换浏览其它目录但是没有权限(也可以只能锁定自己的家目录，不能浏览其它的目录)，可以在自己的家里目录上传和下载
(1)#配置保持默认
 # /etc/vsftpd/vsftpd.conf 

(2)先看可以自由切换目录的本地用户
#/etc/init.d/vsftp stop 
# useradd alvin1
# passwd alvin1 

(3)用户登录
# ftp 10.0.0.201
Connected to 10.0.0.201(10.0.0.201)
220(vsFTd 2.2.2)
Name(10.0.0.201:root):alvin1
331 Please specify the password.
Password:123456


(4)、黑名单与白名单
在/etc/vsftpd/目录中有一个user_list，主配置文件，vsftpd.conf中，userlist_enble=yes/no选项表示是否加载user_list文件
，如果userlist_enable=yes 那么此名单为、黑名单，禁止表列中的用户登录ftp.
 如果userlist_enable=no  那么此名单为、白名单，只允许表列中的用户登录ftp.其它的用户全部被禁止

练习题目：
创建一个本地用户叫做gongda，并且设置密码.
要求如下：
(1)禁止匿名用户登录、上传、下载、创建文件、删除权限
(2)允许本地用户、登录 上传 下载
(3)要求本地用户只能在自己的家目录下。不能切换到别的目录















九、虚拟用户访问FTP配置文件
(1)、创建用户
# useradd user_00 -s /sbin/nologin

(2)建立虚拟用户配置文件
# cd /etc/vsftpd
# mkdir user_conf
# vim user_conf/module
anon_world_readable_only=YES
write_enable=YES
anon_upload_enable=YES
anon_other_write_enable=YES
anon_mkdir_write_enable=YES


(3)、修改PAM权限,全部注释掉，增加以下2行
# vim /etc/pam.d/vsftpd
#auth       required    pam_shells.so
#auth       include     system-auth
#account    include     system-auth
#session    include     system-auth
#session    required     pam_loginuid.so
auth        required    /lib64/security/pam_userdb.so db=/etc/vsftpd/vsftpd.login
account     required    /lib64/security/pam_userdb.so db=/etc/vsftpd/vsftpd.login



(4)、编辑/etc/vsftpd/vsfpd.conf配置文件
# vim /etc/vsftpd/vsftpd.conf
# ACCESS
listen=YES
listen_port=21
local_enable=YES
write_enable=YES

# Security  anonymous&chroot&userlist
anonymous_enable=NO
anon_world_readable_only=NO
anon_upload_enable=NO
anon_mkdir_write_enable=NO
anon_umask=022
chroot_local_user=YES
chroot_list_enable=YES
chroot_list_file=/etc/vsftpd/user_list
local_umask=022
guest_enable=YES
guest_username=user_00
user_config_dir=/etc/vsftpd/user_conf
pam_service_name=vsftpd

# Session & Connetion
idle_session_timeout=300
data_connection_timeout=120
accept_timeout=60
connect_timeout=60
port_enable=NO
pasv_min_port=50000
pasv_max_port=51000
connect_from_port_20=YES
ascii_upload_enable=YES
ascii_download_enable=YES
hide_file={.ssh,.kde,.bash*,.vi*,.gt*,.em*}

#ftpd_banner=Signbook FTP service.
hide_ids=YES
ls_recurse_enable=NO
use_localtime=YES
file_open_mode=0777
tcp_wrappers=YES



(5)、验证测试
# touch vsftpd.login  创建一个记录用户和密码的文件
# mkdir /opt/zeng/www.gongda.com  创建一个gognda目录

# cp user_conf/module user_conf/www.gongda.com   拷贝一个模板把它改名叫做www.gongda.com
# vim user_conf/www.gongda.com  #编辑www.gongda.com 
anon_world_readable_only=YES
write_enable=YES
anon_upload_enable=YES
anon_other_write_enable=YES
anon_mkdir_write_enable=YES
local_root=/opt/zeng/www.gongda.com/  #把此行加入进去，限制一下它的家目录

#echo "www.gongda.com" >vsftpd.login
#echo "www.gongda.com" |base64|md5sum | awk '{print $1}' >>vsftpd.login
# db_load -T -t hash -f /etc/vsftpd/vsftpd.login /etc/vsftpd/vsftpd.login.db  将login里面的数据导入db




















(6)、本章练习题目:
  公司要求搭建一个FTP，所有的用户都通过gonda_00 这个用户进行映射.
  请编写一个脚本全自动化，每次只要输入用户输入路径：/opt/www/www.zeng.com 这个路径，提取用户输入的的值的最后一个目录 ，比如脚本就提取www.zeng.com， 作为用户写入vsftpd.login里面
  并且使用md5加密，加密内容也为www.zeng.com 后把密码也写入vsftpd.login.
  写入vsfpd.login内容如下:
  www.zeng.com   这个为用户
  13213asdfb12311231  这个为密码
  最后使用db_load加密，然后登录使用这个用户名登录。
























出现的问题1 不能创建文件夹

vsftpd匿名用户新建目录提示：550 Create directory operation failed.  

可能性一：
在 CentOS 上配置完vsFTPD，很认真的检查过配置文件，连接服务器后，在创建文件、上传文件的时候始终显示错误信息 “550 create directory operation failed”， 配置vsFTPD怎么说也不少于5次了，之前都没有出现过这样的问题， 开始以为是用户权限问题，干脆来了个给目录配置 chmod -R 777，在  vsftpd.conf 中配置 local_umask=000(其实肯定不关这个配置的事，心理作用就改了)，结果问题依旧。
跑vsftpd官方网站上 寻找答案，原来问题出在SELinux上，说起这个selinux，本人对他痛恨入骨，正常情况下都是在安装完系统后，直接 yum remove  selinux* -y 删除掉。今天快下班的时候在虚拟机 Virtualbox上安装了CentOS，就急着下班了，所以忘记做这一个动作了。
解决办法：
1、如何禁止SELinux。
# vi /etc/selinux/config
修改为：SELINUX=disabled
如果不想重启系统的话，在终端中输入：setenforce 0。
重新启动vsftpd进程，问题解决。
不如直接删除这个恼人的SELinux
yum remove selinux* -y
这个世界终于清净了…


可能性二：
匿名用户的目录（/var/ftp/pub）没有写权限，需要将其设置为具有写权限。
首先转到/var/ftp
然后在终端中输入：chmod 777 pub。
也许就是这个问题绊倒了你，:-)





问题2  权限给予过度

今天准备用vsftpd传些东东，确encounter这个错误：500 OOPS: vsftpd: refusing to run with writable anonymous root
无奈google一下，原来是这样呀：
对于vsftpd的根目录 /home/ftp 其权限为：drwxrwxrwx 即完全没有限制（或许是不小心执行了 chmod 777 /home/ftp）；
但vsftpd出于安全考虑对 /home/ftp是不允许没有限制的，这导致了上述错误的发生。
所以我们只需做如下更改：
chown root:root /home/ftp
chmod 755 /home/ftp
(如果你不是以root登录，或许前面要加上 sudo ,别忘记)
OK，问题解决了。

ADDUSER.SH
#!/bin/bash
#Title:adduser
#Decription:Auto add ftp user
#system:Use Linux
#Author:Alvin_zeng
#Version:1.0
#==========================================
#Set the global variables
pathdir=$1
#========================================
Check_pahtdir()
{
#:检查路径是否正确，
checktest=`echo $pathdir |awk -F'/' '{print NF}'`
if [ ${checktest} -lt 1 ]
then
 echo "Please enter path"
 echo "Example:./adduser.sh /data/www/php_code"
 return 1
fi
}
#========================================
#:Create_user
#========================================
Create_user()
{
#：验证检查 
Check_pahtdir
   if [ $? -eq 1 ]
   then
      exit 1
   fi
  
#：
checkname=`echo ${pathdir} |awk -F'/' '{(tot+=NF)};END{print $tot}' | grep [a-Z,0-9]| wc -l`
if [ ${checkname} -eq 0 ] 
then
Username=`echo ${pathdir} |awk -F'/' '{(tot+=NF-1)};END{print $tot}'`
else
Username=`echo ${pathdir} |awk -F'/' '{(tot+=NF)};END{print $tot}'`
fi

Passwd=`echo $Username |base64|md5sum|awk '{print $1}'`
echo -e $Username"\n"$Passwd | tee -a /etc/vsftpd/vsftpd.login
if [ $? -eq 0 ]
then
db_load -T -t hash -f /etc/vsftpd/vsftpd.login /etc/vsftpd/vsftpd.login.db
else 
  echo "echo Username and passwd error"
   return 1
fi

/bin/cp /etc/vsftpd/user_conf/{module,$Username}  
  if [ $? -ne 0 ]
  then
   echo "cp /etc/vsftpd/user_conf/module [error]"
   return 1
  else
    echo "local_root=$pathdir" >> /etc/vsftpd/user_conf/$Username
  fi
}
#========================================
#:Main
#========================================
Main()
{
Create_user
  if [ $? -eq 1 ]
  then
   echo "Create_user error,Pls check it"
   exit 1
  fi
}
Main;


MODELE
anon_world_readable_only=YES
write_enable=YES
anon_upload_enable=YES
anon_other_write_enable=YES
anon_mkdir_write_enable=YES

VSFTPD.CONF
# ACCESS
listen=YES
listen_port=21
local_enable=YES
write_enable=YES

# Security  anonymous&chroot&userlist
anonymous_enable=NO
anon_world_readable_only=NO
anon_upload_enable=NO
anon_mkdir_write_enable=NO
anon_umask=022
chroot_local_user=YES
chroot_list_enable=YES
chroot_list_file=/etc/vsftpd/user_list
local_umask=022
guest_enable=YES
guest_username=user_00
user_config_dir=/etc/vsftpd/user_conf
pam_service_name=vsftpd

# Session & Connetion
idle_session_timeout=300
data_connection_timeout=120
accept_timeout=60
connect_timeout=60
port_enable=NO
pasv_min_port=50000
pasv_max_port=51000
connect_from_port_20=YES
ascii_upload_enable=YES
ascii_download_enable=YES
hide_file={.ssh,.kde,.bash*,.vi*,.gt*,.em*}

#ftpd_banner=Signbook FTP service.
hide_ids=YES
ls_recurse_enable=NO
use_localtime=YES
file_open_mode=0777
tcp_wrappers=YES

ETC-PAM.D-VSFTPD.CONF
#auth       required    pam_shells.so
#auth       include     system-auth
#account    include     system-auth
#session    include     system-auth
#session    required     pam_loginuid.so
auth        required    /lib64/security/pam_userdb.so db=/etc/vsftpd/vsftpd.login
account     required    /lib64/security/pam_userdb.so db=/etc/vsftpd/vsftpd.login
~

第七章 NFS
                                  第7章 NFS服务
一、NFS概述
  NFS为Network File System 的缩写，最早由Sun公司开发，目的在于使用不同的机器，在不同的操作系统上面实现文件共享，目前在UNIX(UNIX Like)主机上通常用来作为File Server，用于类Unix主机之间的文件共享，因为实现类Unix主机之间的文件共享时，NFS要比Samba更快快捷，因为NFS的设置非常简单，但是要实现Linux与Windows之间的通信时，使用Samba就更好了。
  

二、NFS进程
2.1、RPC(Remont Procedure Call)：远程调用
   NFS本身是没有提供信息传输的协议和功能的，但是NFS却能让我们通过网络进行资料的分享，这是因为NFS使用了一些其他的传输协议，而这些协议需要用到这个RPC协议，NFS是一个文件系统，而RPC是负责信息的传输。


2.2、NFS需要启动的Daemons(守护进程)
  rpc.nfsd：这个daemon的主要功能是管里Client端是否能够登录主机，其中包含复杂的登录权限检测
  rpc.mound：这个负责NFS的文件系统，当Client端通过rpc.nfsd登录server后，对Client存取server的文件进行一系列的管理，NFS，server和Redhat Linux平台一下一共需要两个套件:
  nfs-utils:提供rpc.nfsd及rpc.mountd这两个NFS DAEMONS的套件.
  portmap：NFS其实可以被看作一个RPC server 程序而启动。rpc server program都要做好port的对应工作，而且这样的任务就是由portmap来完成，通俗一点来说：portmap就是用来做port(端口)的匹配工作的.





2.3、服务端和客户端之间通信

NFS服务器<--------->NFS客户端
1、NFS服务共享目录、目录的权限检查
2、NFS服务使用RPC协议进行数据的传输
3、服务器上启动一堆RPC的服务、进程、端口
4、portmap启动一个111端口，客户端链接服务器的时候需要链接111端口
5、portmap会把访问111端口的数据发送给rpc服务对应的端口
6、因此只需要把111端口和portmap进程共享出去`


2.4、工作原理
(1)客户机：RPC 请问nfsd的端口号多少呀？
(2)服务器：是2049
(3)客户机:那测试一下2049通不通
(4)服务器:收到是通的
(5)客户机:RPC,请问mountd的端口号多少?
(6)服务器:是1234
(7)客户机：那测试一下1234是否通畅 
(8)服务器：收到了是通的
(9)客户机：我要挂在/aaa01
(10)服务器：根据这个配置的权限，你有有权限，你可以挂在，批准
(11)客户机：我测试一下挂载上了没有？
(12)服务器：挂上了。
(13)客户机：我想看看这个文件系统的属性
(14)服务器:给就这些
(15)客户机：开始读取文件系统属性
(16)客户机：停止挂在，两边中断通信。










三、NFS安装
#yum -y install setup-*  initscripts-*  nfs-utils-*  portmap  quota-*



四、配置文件及命令

NFS的软件很简单，配置文件只有一个，就是我们下面介绍的，同时还有几个执行文件和记录文件。下面就为大家一一列举出来。
1)	/etc/exports
   这个文件就是NFS的主配置文件，但系统并没有默认值，所以一开始的时候这个文件可能并不存在，需要自己用vi创建，若是存在的话一般都为空文件，没有任何内容。

2)	/usr/sbin/exportfs
这是维护NFS共享资源的命令，我们可以使用这个命令重新共享/etc/exports更改的目录资源、将NFS服务器共享的目录卸载或重新共享等，是NFS服务器中非常重要的一个命令，在后面实际使用中我们会详细介绍它的使用。
3)	/usr/sbin/showmount
这是另外一个重要的命令，exportfs主要用在服务端，而showmount主要用在客户端。可以用它查看NFS服务器共享出来的目录资源。
4)	/var/lib/nfs/*tab
NFS服务器的日志文件都放置在/var/lib/nfs目录里，在该目录下有两个比较重要的日志文件，一个是etab，主要记录NFS共享出来的目录的完整的权限设置值;另外一个是xtab,记录曾经连接到此NFS主机的相关客户端数据。
5)	/etc/init.d/nfs
     这是NFS服务所在，配置好NFS服务器之后，就要使用其启动nfs服务。
6)	/etc/init.d/portmap
     这是portmap守护进程，基本上第一次启动之后以后每次都会开机自启动，不会关闭。
无疑这里最重要的就是配置文件的设置，下面我们就详细介绍/etc/exports配置文件的语法与参数。
NFS服务器的搭建非常简单，配置好/etc/exports文件之后，启动portmap,再启动nfs，NFS服务器就架设成功了，但是这样的设置到底能不能对客户端生效，就要看我们在权限方面的设置到底准不准确了。下面我们看一个简单的配置。







五、权限详解
rw：可读写的权限

ro：只读的权限

no_root_squash：如果root用户登入nfs的共享目录，那么就是root身份，对于这个共享目录来说，
它就具有root权限。这个参数"极不安全"，请慎用。

root_squash：如果root用户登入nfs的共享目录，那么这个用于权限会被压缩成为匿名用户，通常它的UID与GID都会变成nobody（nfsnobody）系统账号的身份。

all_squash：任何登入用户，身份都会被压缩成为匿名用户，默认是 nobody 。

anonuid：anon是anonymous(匿名者)的缩写，通常是nobody(nfsnobody)身份的uid，但是我们可以自己设定uid。

anongid：anon是anonymous(匿名者)的缩写，通常是nobody(nfsnobody)身份的gid，但是我们可以自己设定gid。

sync：数据同步写入到内存与硬盘中。

async：数据会先暂存与内存中，而不是直接写入硬盘。

这些是NFS服务器搭建过程中用到的最多的权限参数，如果对其它参数有兴趣的同学可以使用man
exports查看更多的参数。






六、Server端案例配置：

环境：10.0.0.201 Server端
     10.0.0.202 Client端


需求一：让以root身份登入NFS服务器的用户保留root身份权限
   如果我想将/test目录共享出去，想让所有的用户都能读写，并且让root用户写入文件时仍具有root权限。如何编辑配置文件？
# vi /etc/exports
/test *(rw,no_root_squash)







需求二：同一目录针对不同范围设置不同权限
如果我想将/tmp目录共享出去，让和我一个网段(我的实验网段是172.30.209.0/24)的人都能够读写，其它网段的人只读，并且所有root身份登入的用户被压缩成匿名用户。如何编辑配置文件？
[root@server /]# vi /etc/exports
/test *(rw,no_root_squash)
/tmp 172.30.209.0/24(rw,root_squash) *(ro,root_squash)







需求三：仅给单一用户提供目录共享
     像大家做实验的时候，仅仅给指定的PC机提供目录共享。譬如我这里只给172.30.209.106这台机器提供/testnfs目录的共享，让这台机器的用户有读写的权限，该如何设计？
# vi /etc/exports
/test *(rw,no_root_squash)
/tmp 172.30.209.0/24(rw,root_squash) *(ro,root_squash)
/testnfs 172.30.209.106(rw)  =>直接指定IP就可以







需求四：开发匿名登入的情况
  现在我将/home/test目录共享出去，让172.30.209.0/24网段的人都能够读写，但是所有登入的用户身份都变成我指定的在/etc/passwd中已经存在的某个UID，GID。这里是500。该如何设计？
# vi /etc/exports
/test *(rw,no_root_squash)
/tmp 172.30.209.0/24(rw,root_squash) *(ro,root_squash)
/testnfs 172.30.209.106(rw)
/home/test 172.30.209.0/24(rw,all_squash,anonuid=500,anongid=500)
重点是all_squash，与anonuid，anongid配合。





查找端口是否生效
# netstat -tunlp | grep portmap

# netstat -tunlp | grep rpc

# rpcinfo -p localhost   
     程序   版本   协议    端口
   program vers proto   port  service
    100000    4   tcp    111  portmapper
    100000    3   tcp    111  portmapper
    100000    2   tcp    111  portmapper
    100000    4   udp    111  portmapper
    100000    3   udp    111  portmapper
    100000    2   udp    111  portmapper
    100024    1   udp  44032  status
    100024    1   tcp  58092  status

最后重启服务：
# /etc/init.d/rpcbind start
# /etc/init.d/nfs    restart

使配置生效：
# exportfs -au   =>卸载掉NFS服务器的所有共享目录
# exportfs -av   =>加载NFS服务器的所有共享目录
exporting 172.30.209.0/24:/home/test
exporting 172.30.209.106:/testnfs
exporting 172.30.209.0/24:/tmp
exporting *:/test
exporting *:/tmp
# exportfs -r    =>重载NFS服务器的共享目录 
   使用-r最方便，当你对/etc/exports配置文件做了更改之后，执行此命令就可以在不需要重启服务情况下使更改生效。



七、Client配置：
# yum -y install nfs-utils protmap
# showmount -e 10.0.0.201
# mkdir /aatest
# mkdir aatest
# mount -t nfs 10.0.0.201:/test /aatest







第八章 SAMBA
                                  第7章 NFS服务
一、NFS概述
  NFS为Network File System 的缩写，最早由Sun公司开发，目的在于使用不同的机器，在不同的操作系统上面实现文件共享，目前在UNIX(UNIX Like)主机上通常用来作为File Server，用于类Unix主机之间的文件共享，因为实现类Unix主机之间的文件共享时，NFS要比Samba更快快捷，因为NFS的设置非常简单，但是要实现Linux与Windows之间的通信时，使用Samba就更好了。
  

二、NFS进程
2.1、RPC(Remont Procedure Call)：远程调用
   NFS本身是没有提供信息传输的协议和功能的，但是NFS却能让我们通过网络进行资料的分享，这是因为NFS使用了一些其他的传输协议，而这些协议需要用到这个RPC协议，NFS是一个文件系统，而RPC是负责信息的传输。


2.2、NFS需要启动的Daemons(守护进程)
  rpc.nfsd：这个daemon的主要功能是管里Client端是否能够登录主机，其中包含复杂的登录权限检测
  rpc.mound：这个负责NFS的文件系统，当Client端通过rpc.nfsd登录server后，对Client存取server的文件进行一系列的管理，NFS，server和Redhat Linux平台一下一共需要两个套件:
  nfs-utils:提供rpc.nfsd及rpc.mountd这两个NFS DAEMONS的套件.
  portmap：NFS其实可以被看作一个RPC server 程序而启动。rpc server program都要做好port的对应工作，而且这样的任务就是由portmap来完成，通俗一点来说：portmap就是用来做port(端口)的匹配工作的.





2.3、服务端和客户端之间通信

NFS服务器<--------->NFS客户端
1、NFS服务共享目录、目录的权限检查
2、NFS服务使用RPC协议进行数据的传输
3、服务器上启动一堆RPC的服务、进程、端口
4、portmap启动一个111端口，客户端链接服务器的时候需要链接111端口
5、portmap会把访问111端口的数据发送给rpc服务对应的端口
6、因此只需要把111端口和portmap进程共享出去`


2.4、工作原理
(1)客户机：RPC 请问nfsd的端口号多少呀？
(2)服务器：是2049
(3)客户机:那测试一下2049通不通
(4)服务器:收到是通的
(5)客户机:RPC,请问mountd的端口号多少?
(6)服务器:是1234
(7)客户机：那测试一下1234是否通畅 
(8)服务器：收到了是通的
(9)客户机：我要挂在/aaa01
(10)服务器：根据这个配置的权限，你有有权限，你可以挂在，批准
(11)客户机：我测试一下挂载上了没有？
(12)服务器：挂上了。
(13)客户机：我想看看这个文件系统的属性
(14)服务器:给就这些
(15)客户机：开始读取文件系统属性
(16)客户机：停止挂在，两边中断通信。










三、NFS安装
#yum -y install setup-*  initscripts-*  nfs-utils-*  portmap  quota-*



四、配置文件及命令

NFS的软件很简单，配置文件只有一个，就是我们下面介绍的，同时还有几个执行文件和记录文件。下面就为大家一一列举出来。
1)	/etc/exports
   这个文件就是NFS的主配置文件，但系统并没有默认值，所以一开始的时候这个文件可能并不存在，需要自己用vi创建，若是存在的话一般都为空文件，没有任何内容。

2)	/usr/sbin/exportfs
这是维护NFS共享资源的命令，我们可以使用这个命令重新共享/etc/exports更改的目录资源、将NFS服务器共享的目录卸载或重新共享等，是NFS服务器中非常重要的一个命令，在后面实际使用中我们会详细介绍它的使用。
3)	/usr/sbin/showmount
这是另外一个重要的命令，exportfs主要用在服务端，而showmount主要用在客户端。可以用它查看NFS服务器共享出来的目录资源。
4)	/var/lib/nfs/*tab
NFS服务器的日志文件都放置在/var/lib/nfs目录里，在该目录下有两个比较重要的日志文件，一个是etab，主要记录NFS共享出来的目录的完整的权限设置值;另外一个是xtab,记录曾经连接到此NFS主机的相关客户端数据。
5)	/etc/init.d/nfs
     这是NFS服务所在，配置好NFS服务器之后，就要使用其启动nfs服务。
6)	/etc/init.d/portmap
     这是portmap守护进程，基本上第一次启动之后以后每次都会开机自启动，不会关闭。
无疑这里最重要的就是配置文件的设置，下面我们就详细介绍/etc/exports配置文件的语法与参数。
NFS服务器的搭建非常简单，配置好/etc/exports文件之后，启动portmap,再启动nfs，NFS服务器就架设成功了，但是这样的设置到底能不能对客户端生效，就要看我们在权限方面的设置到底准不准确了。下面我们看一个简单的配置。







五、权限详解
rw：可读写的权限

ro：只读的权限

no_root_squash：如果root用户登入nfs的共享目录，那么就是root身份，对于这个共享目录来说，
它就具有root权限。这个参数"极不安全"，请慎用。

root_squash：如果root用户登入nfs的共享目录，那么这个用于权限会被压缩成为匿名用户，通常它的UID与GID都会变成nobody（nfsnobody）系统账号的身份。

all_squash：任何登入用户，身份都会被压缩成为匿名用户，默认是 nobody 。

anonuid：anon是anonymous(匿名者)的缩写，通常是nobody(nfsnobody)身份的uid，但是我们可以自己设定uid。

anongid：anon是anonymous(匿名者)的缩写，通常是nobody(nfsnobody)身份的gid，但是我们可以自己设定gid。

sync：数据同步写入到内存与硬盘中。

async：数据会先暂存与内存中，而不是直接写入硬盘。

这些是NFS服务器搭建过程中用到的最多的权限参数，如果对其它参数有兴趣的同学可以使用man
exports查看更多的参数。






六、Server端案例配置：

环境：10.0.0.201 Server端
     10.0.0.202 Client端


需求一：让以root身份登入NFS服务器的用户保留root身份权限
   如果我想将/test目录共享出去，想让所有的用户都能读写，并且让root用户写入文件时仍具有root权限。如何编辑配置文件？
# vi /etc/exports
/test *(rw,no_root_squash)







需求二：同一目录针对不同范围设置不同权限
如果我想将/tmp目录共享出去，让和我一个网段(我的实验网段是172.30.209.0/24)的人都能够读写，其它网段的人只读，并且所有root身份登入的用户被压缩成匿名用户。如何编辑配置文件？
[root@server /]# vi /etc/exports
/test *(rw,no_root_squash)
/tmp 172.30.209.0/24(rw,root_squash) *(ro,root_squash)







需求三：仅给单一用户提供目录共享
     像大家做实验的时候，仅仅给指定的PC机提供目录共享。譬如我这里只给172.30.209.106这台机器提供/testnfs目录的共享，让这台机器的用户有读写的权限，该如何设计？
# vi /etc/exports
/test *(rw,no_root_squash)
/tmp 172.30.209.0/24(rw,root_squash) *(ro,root_squash)
/testnfs 172.30.209.106(rw)  =>直接指定IP就可以







需求四：开发匿名登入的情况
  现在我将/home/test目录共享出去，让172.30.209.0/24网段的人都能够读写，但是所有登入的用户身份都变成我指定的在/etc/passwd中已经存在的某个UID，GID。这里是500。该如何设计？
# vi /etc/exports
/test *(rw,no_root_squash)
/tmp 172.30.209.0/24(rw,root_squash) *(ro,root_squash)
/testnfs 172.30.209.106(rw)
/home/test 172.30.209.0/24(rw,all_squash,anonuid=500,anongid=500)
重点是all_squash，与anonuid，anongid配合。





查找端口是否生效
# netstat -tunlp | grep portmap

# netstat -tunlp | grep rpc

# rpcinfo -p localhost   
     程序   版本   协议    端口
   program vers proto   port  service
    100000    4   tcp    111  portmapper
    100000    3   tcp    111  portmapper
    100000    2   tcp    111  portmapper
    100000    4   udp    111  portmapper
    100000    3   udp    111  portmapper
    100000    2   udp    111  portmapper
    100024    1   udp  44032  status
    100024    1   tcp  58092  status

最后重启服务：
# /etc/init.d/rpcbind start
# /etc/init.d/nfs    restart

使配置生效：
# exportfs -au   =>卸载掉NFS服务器的所有共享目录
# exportfs -av   =>加载NFS服务器的所有共享目录
exporting 172.30.209.0/24:/home/test
exporting 172.30.209.106:/testnfs
exporting 172.30.209.0/24:/tmp
exporting *:/test
exporting *:/tmp
# exportfs -r    =>重载NFS服务器的共享目录 
   使用-r最方便，当你对/etc/exports配置文件做了更改之后，执行此命令就可以在不需要重启服务情况下使更改生效。



七、Client配置：
# yum -y install nfs-utils protmap
# showmount -e 10.0.0.201
# mkdir /aatest
# mkdir aatest
# mount -t nfs 10.0.0.201:/test /aatest







SAMBA
                                     第9章<--->SAMBA
一、Samba概述
Samba起源于Linux和Windows之间的通信需求，早期的Linux和Windows两大平台之间不能直接沟通。
比如：像拷贝文件之类的。需要通过第三方移动媒体(介质)来实现，那么在Linux和Windows共存的网络中，这种两大平台之间
不能直接沟通产生了很大的不便，随着Linux的用户日益增多，使得两个平台之间的通信的问题的解决更加的迫切，最后呢，借助SMB(
Server Message Block）解决了这一个问题.
 SMB协议是由微软和因特尔在1987年定制的协议，SMB是一个遵循客户机服务器（C/S）模式的协议，SMB服务器主要是负责通过网络提供可用的共享资源，至于服务器和客户机之间的链接，那就要通过TCP/IP 或者IPX 或者NetBIOS协议进行链接了，一旦服务器和客户机之间建立了稳定的链接，那么客户机就可以向服务器发送命令完成操作。
 该协议主要用于，共享文件、共享打印机、共享串口等用途，Windows系统下通过访问网络邻居用的就是此协议。



二、Samba简介
Samba是属于(GNU Public License)简称(GPL)的软件，可以合法免费使用，它的核心就是SMB（Server Message Block)通信协议，让运行Linux系统的电脑能够用Microsoft网络通信协议，使它能够和Windows平台进行通信。
  samba主要由两个进程:
  (1)、smbd进程，主要用来管理共享文件，smdb运行在TCP的 139 445端口.
  (2)、nmdb进程，主要用来实现主机名到IP地址的转换(NetBIos名称解析)_，nmdb运行在UDP的137、138端口，
  如果不运行nmbd进程，那么客户端只能用IP地址来访问samba服务器，那么我们知道SAMBA是基于C/S模式的。既然是C/S模式那么就应该由服务器和客户端。
  
   Windows主机之间使用SMB/CIFS网络协议实现文件共享和打印资源的共享
   139端口为SMB协议
   445端口为CIFS协议
   137端口为NetBIOS名称解析协议
   138端口为NetBIOS数据包
#=============================================================================================

三、Samba功能
   Samba提供了一下功能:
     (1)、共享Linux的文件系统
     (2)、共享安装在Samba服务器上的打印机
     (3)、使用Windows系统共享的文件和打印机
     (4)、支持Windows域控制器和Windows成员服务器对使用samba资源的进行用户认证
     (5)、支持WINS名字服务器解析及浏览
     (6)、支持SSL安全套接层协议.

   
四、Samba工作原理
    工作原理分为4个步骤
    (1)、客户端--->服务端 发起negprot命令数据包，告诉服务器，客户端支持SMB类型，然后服务器根据客户端的情况来选择最优的SMB类型，并作出回应.
    
    (2)、当SMB类型确认后，客户端发送session setup数据包，提交帐号和密码，请求与Samba服务器建立链接，
    如果这个身份验证通过了。Samba服务器会对Session报文作出回应，并且为用户分配一个唯一的UID，在于客户端通信使用。
    


    (3)、当完成第2步以后，客户端访问Samba共享资源，发送tree connect命令数据包，通知服务器需要访问的共享资源名，如果设置允许，Samab为每个客户端与共享资源链接分配一个TID，客户端既可以访问需要的共享文件。


    
    (4)、共享完毕，客户端向服务器发送数据报文关闭共享，然后与服务器断开链接.
    
 
五、Samba安装
(1)、安装包说明
samba-3.0.33-3.28		# 服务器端程序
samba-client-3.0.33		# 客户端程序
samba-common-3.0.33	    # 公共组件
samba-swat-3.0.33    	#web方式配置程序，可不选



(2)、安装samba
# yum -y install samba



(3)、配置Samba文件说明
# vim /etc/samba/smb.conf
[global]										
#配置文件中的全局配置部分
workgroup = MYGROUP					
#工作组的名字，设置服务器加入的共组，在windows的网上邻居会看见。
server string = Samba Server Version %v
#服务器的说名信息，在windows访问的时候，出现在“名称、备注”栏中。
#并描述服务器版本 %v是变量 取当前版本

hosts allow = 10.0.0.21 10.0.0.22   允许特定IP 地址可以访问，此处可以可写IP和主机名，默认是注释的。一般和deny之需要开启其中一个。就行。，
hosts deny = 10.0.0.23 10.0.0.24    禁止特定IP 地址可以访问，此处可以可写IP和主机名


security = user
# 指明验证模式  share匿名模式 不验证用户名和密码
#				user验证模式  验证用户名和密码
#				注意:匿名用户此时依旧可用 用空密码验证则通过
#				限制匿名需要用valid users = 
#	   			server验证服务器模式 
#				domain由WINDOWS域服务器验证
passdb backend = tdbsam
# 密码的加密存储模式
load printers = yes
#允许共享打印机，指定是否加载打印机（使打印机共享），
cups options = raw
#默认打印系统类型
[homes]								
#每个用户的家目录默认情况下会开启用户家目录和打印机的共享设置,
通过[homes]实现系#统中的用户并被smbpasswd添加后的用户可以直接访问各自的家目录
comment = Home Directories
#目录的说明
browseable = no
#是否启用此共享目录
writable = yes
#是否可写入共享目录
[printers]						
#打印机的一些配置信息
comment = All Printers
#为了配置共享打印机，所有用户都能访问共享打印机
path = /var/spool/samba
#设置打印机的队列位置，用户必须自行创建目录，存放打印临时文件
browseable = no
#是否允许浏览共享打印机
guest ok = no
#是否允许匿名用户访问
writable = no
#是否可写入共享
printable = yes
#是否允许用户更改打印队列的文件




六、samba常用命令

(1)、客户端常用命令
sambaclient命令，查看及登录使用共享
  smbclient -L 10.0.0.201 查看smb服务器201上共享了那些目录,默认以root方式验证。需要输入密码
  smbclient -U root //10.0.0.201/test 登录共享。使用方法跟FTP差不多。
  mount -o username=root,password=123456 //10.0.0.201/test1/ /mnt
  mount -t cifs -o username=root,password=123456 //10.0.0.201/test /mnt 将201上的/test共享目录挂在到本地/mnt下面
  
(2)、服务端常用命令

smbpasswd 增加samba用户帐号
#smbpasswd -a alvin 
-a 添加指定的samba帐号
-d 禁用指定的samba帐号
-e 启动指定的samba帐号
-x 删除指定的samba帐号
-h 显示帮助相信.
不加任何选项，就是直接改帐号密码smbpasswd alvin 修改samba帐号的alvin密码.







(3)、samba/etc/samba/smbusers 可以设定账户的别名
# vim /etc/samba/smbusers
alvin=test1  给alvin帐号设置一个别名为test1


(4)、配置文件可以写定义
用户能否写某个共享资源由以下几个参数决定。

（1）readonly：是否将共享资源设置为只读。当readonly = yes时表示只读共享，readonly = no时表示不使用只读方式共享。


（2）read list：设置只读的用户或组（如果使用组时，需要在组名称前加@）。

（3）writable：是否允许共享资源设置为可写。当writable = yes时表示可写，writable = no时表示不可写。

（4）write list：设置可写的用户或组（如果使用组时，需要在组名称前加@）。

（5）force user：指定通过Samba服务器访问共享资源建立的文件或目录时的拥有者。（通过该参数指定用户后，无论以什么身份登录Samba服务器，都会被重定向到指定的用户，相当于以指定身份访问共享文件夹）

（6）group：指定通过Samba服务器访问共享资源建立的文件或目录的拥有组。（该参数与force user的作用类似）

当readonly、read list、writable及write list在对某一共享资源的设置发生冲突时，使用以下规则。

（1）readonly、writable发生冲突时，在后面的参数优先。

（2）readonly、wirte list发生冲突时，除write list指定用户可写外，其他用户只读。

（3）read list、writable发生冲突时，除read list指定用户只读外，其他用户可写。

（4）read list、write list发生冲突时，write list优先。

（5）writable = no时，只有write list的用户可写。

（6）同时配置writable = yes、write list时，write list无效。

当writable、write list及readonly同时出现在一个共享资源时，最后的结果可根据上面提到的几个规则来判定是否可写

(7) browseable = no 表示应藏该目录，需要通过完整的路径访问：\\10.0.0.201\test

(8) valid users=用户或者组，允许那访问该共享的用户

(9) invalid users=用户或者组，禁止那些用户访问该共享。




  
七、samba案例实战
(1)匿名访问
# vim /etc/samba/smb.conf
[global]
security = share
[test1]
path = /test1
comment = share test1
writeable = yes
browseable = yes
public = yes
# mkdir /test1    #创建目录，再touch两个文件用来测试
# cd /test1 && touch 1.txt 2.txt 
验证在windows下面直接输入//10.0.0.201 不需要密码可以直接进入



(2)、用户验证的文件共享
配置文件如下r
# vim /etc/samba/smb.conf
[global]
security = user
[test2]
Path=/test2
Comment = share test2
writable = no
public = no
valid users = aixocm  用户
write list = @aixocm  用户组
如果想在目标目录中进行操作（添删改查），需要将共享的目录的权限授予需要操作此目录的用户。
例如：我想让aixocm用户对共享目录进行操作
只要在服务器端：
# useradd aixocm
# chown aixocm:aixocm  /test2
[root@server samba]# smbpasswd -a aixocm
New SMB password:
Retype new SMB password:



八、练习题目:
公司有财务，技术，领导3个部门，我们分别为3个部门建立3个用户组为caiwu,network,lingdao;

三个部门里各有2个用户，我们建用户分别为 caiwu01,caiwu02,network01,network02,lingdao01,lingdao02

然后我们分别就公司的具体情况建立相应的目录及访问权限，通过以下的例子，希望大家能在平时的工作中灵活的应用samba的安全权限来设置你们的 samba 文件服务器。

1。首先服务器采用用户验证的方式，每个用户可以访问自己的宿主目录，并且只有该用户能访问宿主目录，并具有完全的权限，而其他人不能看到你的宿主目录。

2。建立一个 caiwu 的文件夹，希望 caiwu 组和 lingdao 组的人能看到，network02 也可以访问，但只有 caiwu01 有写的权限。

#mkdir /caiwu
#chmod 777 /caiwu
#vim /etc/samba/smb.conf
[caiwu]
comment=test
path=/caiwu
public= no
valid users=@caiwu,@lingdao,network02,caiwu02
read list=@caiwu,@lingdao,network02
write list=caiwu02


3。建立一个 lingdao 的目录，只有领导组的人可以访问并读写，还有 network02 也可以访问，
[lingdao]
comment=test
path=/lingdao
public=no
valid users=@lingdao,network02
read list=@lingdao,network02
write list=@lingdao


4。建立一个文件交换目录 exchange，所有人都能读写，包括 guest 用户，但每个人不能删除别人的文件。
[exchange]
comment=test
path=/exchange
public=yes
writable=yes
valid users=@lingdao,@caiwu,@network

5。建立一个公共的只读文件夹 public，所有人只读这个文件夹的内容。
[publicaa]
comment=public
path=/public
public=yes
readonly=yes


脚本需求：
(1)要求安装samba服务，
(2)要求根据用户输入、用户名，和目录路径，目录所有的人可以访问，但是用户自己输入的用户名可以读写。
(3)最后启动服务，判断是否成功

















     
  
  
  


SAMBA_INSTALL.SH
#!/bin/bash
#Title:samba_install.sh
#Description:Auto install samba
#system:Use Linux
#Author:Alvin
#Date:2014-3-21
#Version:1.0
#==========================================
. smbconfig
#:Use Common
#:Use Client
#:Use Master
#:Use Smbconf
#=================
#Set PWD
PWDDIR=`pwd`
C1=`rpm -qa | grep $Common | wc -l`
C2=`rpm -qa | grep $Client | wc -l`
C3=`rpm -qa | grep $Master | wc -l`
#=================
#Check_error()
#=================
Check_error()
{
if [ $? -ne 0 ]
then
    echo "$1 Fail...." >>$PWDDIR/smb.log
    return 1
else
    return 0
fi
}
#=========================================
#Function-->Check_packet()
#=========================================
Check_packet()
{
ALLB=`expr $C1 + $C2 + $C3`
if [ $ALLB -gt 2 ]
then
  B1=`cat /etc/samba/smb.conf  | grep -vE ";|#" | grep "path" | grep -v "samba" | wc -l`
 B2=`cat /etc/samba/smb.conf  | grep -vE ";|#" | grep "path" | grep -v "samba"` 
 if [ $B1 -gt 0 ]
 then
    Y1=`/etc/init.d/smb status | wc -l`
    if [ $Y1 -eq 0 ] 
    then
        echo "smb alyready install ok you can loking path:$B2"
        exit 1
    else
        /etc/init.d/smb start  >>/dev/null
        echo "smb already install ok you can loking path:$B2"
        exit 1
    fi
 fi  
fi


if [ $C1 -lt 1 ]
then
    echo "$Common packet have't install"
    echo "Now_install int..."
    yum -y install $Common
    Check_error $Common
fi

if [ $C2 -lt 1 ]
then
    echo "$Client packet have't install"
    yum -y install $Client
    Check_error $Client
fi

if [ $C3 -lt 1 ]
then
    echo "$Master packet have't intall"
    yum -y install $Master
    Check_error $Master
fi
}
#===========================================
#Function-->Config_file
#===========================================
Config_file()
{
if [ -f $Smbconf ]
then
  echo "
[test]
comment=alvin
path=/test
public=yes
writable=yes
" >>$Smbconf	
Check_error $Smbconf
fi
  B1=`cat /etc/samba/smb.conf  | grep -vE ";|#" | grep "path" | grep -v "samba" | wc -l`
  if [ $B1 -gt 0 ]
  then
   echo "/test path already excist"
   exit 1
  fi
  /etc/init.d/smb restart
  Check_error service

  User1=`cat /etc/passwd | grep "smbtest" | wc -l`
 if [ $User1 -eq 0 ]
  then
  useradd smbtest
  Check_error useradduser

  smbpasswd -a smbtest 
  if [ $? -eq 0 ]
  then
     mkdir -p /test && chmod 777 /test
     echo "Set smb password OK....."
  else
     echo "smbpasswd Set error,Please try again..."
     exit 1
  fi
else
  echo "smb user already excist"
  exit 1
fi
}
#=====================================================
#:Function-Main
#=====================================================
Main()
{
Check_packet
  if [ $? -eq 0 ]
  then
     Config_file 
     if [ $? -eq 1 ]
     then
         echo "Please check log"
         exit 1
     fi
  else
    echo "Please check install log"
    exit 1
  fi
}
Main;



SMBCONFIG
##############Set Packet Info#######################
Common="samba-winbind-clients"
Client="samba-common"
Master="samba-3.5.10"
Smbconf="/etc/samba/smb.conf"


第九章 DNS服务
DNS服务
一、DNS基础部分
1、域名的概念
说到DNS，那我们必须来看一下域名的概念，平常我们打开一个网页使用的都是域名。而不是IP地址，
在早期的互联网，都是通过IP地址来访问网页的，后来由于IP地址难以记忆，于是人们就在思考以一种比较容易记忆的方式来实现
互联网的访问，于是就有域名管理系统，也叫(名称服务DNS Domain name System).



2、域名主要分为四个部分：
如:www.baidu.com. 严格意义来上来说在.com后面后还有一个点(.)只是这个点一般不写
(1)根  称（根域)   
.(点) 
(2)类型 称(顶级域)   
组织
gov(政府部门) com(商业部门) edu(教育部门) org(民间团体组织) net(网络服务机构) mil(军事部门)
国家/地区
cn(中国) jp(日本) uk(英国) au(澳大利亚) hk(中国香港)
(3)域名 称(二级域)
baidu
(4)域名 称(三级域)或者主机名
www
 
 
 
 
3、域名对应IP
上面说到IP地址难以记忆，然后就有了域名管理，那么一个域名(www.baidu.com)对应一个IP地址。
这个IP地址通常指的是主机名---对应的IP地址。
  日常使用的计算机通常作为一个DNS的客户端，比如说我们的浏览器.
  在Linux中一般使用系统底层的提供的函数gethostbyname(）功能进行域名解析
  解析可以基于以下几种方式:
    基于文件(/etc/hosts)
    DNS
  
  客户端------------------------------->DNS服务器 8.8.8.8 发起请求
        www.baidu.com的IP地址是多少？

  客户端<--------------------------------DNS服务器 8.8.8.8 回应请求
        www.baidu.com=115.239.210.27
        
  
  客户端-------------------------------->找到115.239.210.27(www.baidu.com)服务器 
        然后客户端找到这个服务器发起要访问的内容
        
  客户端<---------------------------------115.239.210.27想应请求，返回数据
            响应应请求，返回数据
 Linux常用DNS查询命令
   #host (输出信息简单)
   #dig  (输出相信的信息）
    
  #host www.baidu.com
  #dig  www.baidu.com 
              
            
(4)DNS查询图
                      www.baidu.com.
                        .(点根域root）-------------------> 保存了(顶级域服务器的IP地址)
                                                     |
-------------------------------------               \|/
|         |        |       |        |----------------->（顶级域)(保存各二级域的对应的IP地址) 
|         |        |       |        |                |
net      com      org     cn       gov     等等       |
          |                                          |
          |                                          |
          |                                         \|/
          |--------------------------------------------->(二级域)(保存各对应的三级域的IP地址)
--------baidu-------------------------               |
          |                                          |
          |                                          |
          |                                          |
------------------------------------------          \|/
      |   |   |------------------------------------------>(三级域或者主机名)(保存了主机名对应的IP地址)
    mail www ftp                         
    
可以是Linux命令查看验证                           
# dig +trace www.baidu.com
    



   
5、DNS查询类型
(1)递归查询
     Client------>本地DNS<-->查询根(.)  一级一级查询                            
     Client------>本地DNS<-->查询顶级域(com)                
     Client------>本地DNS<-->查询二级域(baidu)                                  
(2)迭代查询(也称循环查询)
     Client------>本地DNS<-->查询根(.)由根代查询所有. 这种方式根会缓存所有的IP信息.导致信息库庞大。
                                /|\
                                 |
                                 |
                                \|/
                               查询顶级域(com)
                                /|\
                                 |
                                 |
                                \|/                
                                查询二级域(baidu)
正常来说。这两种都不会独立指使用某一套。都是混合起来用。比如本地DNS使用循环（可以缓存信息)，其它的用递归.


6、DNS资源记录
$ttl 1D
@ IN SOA  @  root(
              0 ;serital 作为 slave和master更新的依据，一般利用年月日期来设定
              3H;refresh 作为 slave多久进行一次主动更新
              15M;retry 如果到refresh的时间，但是slave却无法链接master，多久之后，slave会再次重式链接master
              1W;expire 如果slave一直无法与master链接，那么经过多久时间之后，则命令slave不在链接master
              1D);minimum 没有制定生存周期的数据，可以保存在数据库中的时间以及TTL.
              name  class   type  rdata
www    IN      A    10.0.0.201   
mail   IN      A    10.0.0.202
aaww   IN      A    10.0.0.201
@      IN      mx 10 mail.zytest.com
ppser  IN      cname www.baidu.com
www    IN      cnme  sdfdsfsfsfs

记录类型:
A 记录(IPV4地址）
AAAA 表示IPV6记录
MX   表示邮件记录
cname表示别名
PTR  指针(逆向指针)
SRV  服务资源

7、DNS服务器类型
Primay DNS server(Master)主服务器
一个域的主服务器保存该域的zone配置文件，该域所有的配置文件、更改都在该服务器上进行

Seconday DNS server(Slave)从服务器
从服务器一般作为冗余负载使用，一个域的从服务器从该域的主服务器上抓取zone配置文件，从服务器不进行信息修改，
所有的修改都去主服务器上同步。

Caching only server
DNS缓存服务器不存在任何ZONE文件，仅仅是依靠缓存文件客户端提供服务，通常用于负载均和以及加速访问使用.

#dig -t mx qq.com  查询QQ的邮件服务器地址
#dit -x www.qq.com 
#dit -t soa www.qq.com





 
二、DNS基本配置
2.1、BIND
如今DNS使用最广泛的DNS服务器软件是BIND(Berkeley Internet Name Domain)，最早由伯克利大学的一名学生编写，现在最新的版本是9，由ISC（Internet Systems Consortium)编写和维护.
BIND支持大多数的操作系统(Linux、UNIX、Mac、Windows)
BIND服务的名称成为(named)

2.2、BIND的安装
# yum -y install bind bind-chroot bind-utils
DNS默认使用UDP，TCP协议，使用默认端口为53号(domain)，953(mdc) 

2.3、BIND配置文件
BIND配置文件主要由两个位置
/etc/named.conf --BIND服务主配置文件
/var/named/     --zone文件

如果安装了bind-chroot，BIND会被封装到一个伪根目录下，配置文件路径为
/var/named/chroot/etc/named.conf ----BIND服务主配置文件 这个文件默认是没有的。
/var/named/chroot/var/named/ --zone文件--这里面默认是空的。
chroot是通过相关文件封装在一个伪根目录当中，达到安全防护的目的，如果DNS服务被攻破。黑客只能在chroot下活动。不能
切换到真实的根目录。


2.4、BIND模板拷贝
DNS根其它的服务不同，BIND安装后，不会在预设的目录下面生成配置文件，但是在BIND的文档文件夹内/usr/share/doc/bind-9.8.2/sample/，为我们提供了配置文件的模板
sample/etc BIND主服配置文件
sample/var --zone文件。
# cp -r /usr/share/doc/bind-9.8.2/sample/etc/* /var/named/chroot/etc/
# cp -r /usr/share/doc/bind-9.8.2/sample/var/* /var/named/chroot/var/










2.5、配置主配置文件named.conf
# vim /var/named/chroot/etc/named.conf
options
{

        directory               "/var/named";
        listen-on port 53       { 10.0.0.201; };

        listen-on-v6 port 53    { ::1; };
};

        zone "zytest.com" {
                type master;
                file "zytest.com.zone";
        };

# named-checkconf /var/named/chroot/etc/named.conf 检查是否有语法错误。





$TTL 1D
@       IN SOA  zytest.com. rname.invalid. (
                                        0       ; serial
                                        1D      ; refresh
                                        1H      ; retry
                                        1W      ; expire
                                        3H )    ; minimum
@       NS      zytest.com.
        A       10.0.2.19
        AAAA    ::1
www     IN  A   10.0.2.128
gongda  IN  A   10.0.2.128
mail    IN  A   10.0.2.128
        IN MX 10 mail.zytest.com.


2.5、配置zone配置文件
# cd /var/named/chroot/var/named
# cp named.localhost zytest.com.zone 这个zytest.com.zone要和主配置文件里面的相对应.
# vim zytest.com.zone
$TTL 1D
@       IN SOA  zytest.com. rname.invalid. (
                                        0       ; serial
                                        1D      ; refresh
                                        1H      ; retry
                                        1W      ; expire
                                        3H )    ; minimum
@       NS      zytest.com.
        A       10.0.2.19
        AAAA    ::1
www     IN  A   10.0.2.128
gongda  IN  A   10.0.2.128
mail    IN  A   10.0.2.128
        IN MX 10 mail.zytest.com.

		
启动 bind 时，需产生 rndc.key 文件，但长时间无响应解决办法，建议先手动添加 rndc.key 文件
记得之前版本中， bind  默认会安装该文件，但导致每台机器 key 文件一致 可通过下面先方法手动生成文件

# rndc-confgen -r /dev/urandom -a
wrote key file "/etc/rndc.key"
之后启动 bind 服务一切正常 
# service named restart
停止 named：                                               [确定]
启动 named：                                               [确定]




2.6、验证DNS
# host www.zytest.com
# dig  www.zytest.com

   










三、DNS主从配置(Master-Slave)
在正常的企业当中，特别是一些CDN的公司。如果只有一个DNS远远不够的。
由于负载压力大，没有数据冗余这个是非常危险的一件事情，下面我们通过slave来冗余Master。，
当master出现故障后，那么不至于域名无法解析，slave照样可以替代master工作。



3.1、Master配置
# vim /var/named/chroot/etc/named.conf
options
{

        directory               "/var/named";
        listen-on port 53       { any; };

        listen-on-v6 port 53    { any; };
		forwarders { 218.30.19.40; }; //提供公网的DNS，如果内部有个DNS，所有客户端对局域网内部的DNS访问，但是外部的访问
		//我们可以直接指定外部 DNS，这样我们的内部客户机即可以在内部访问本地DNS，也可以访问 外部 DNS
		
};

        zone "zytest.com" {
                type master;
                file "zytest.com.zone";
        };







3.2、Slave配置
# yum -y install bind bind-chroot bind-utils
# cp -rv /usr/share/doc/bind-9.8.2/sample/etc/* /var/named/chroot/etc/
# cp -rv /usr/share/doc/bind-9.8.2/sample/var/* /var/named/chroot/var/
# vim /var/named/chroot/etc/named.conf

        // Put files that named is allowed to write in the data/ directory:
        directory               "/var/named";           // "Working" directory
        listen-on port 53       { 127.0.0.1; };

        listen-on-v6 port 53    { ::1; };
};

        zone "zytest.com" {
                type slave;
                masters { 10.0.0.201; }; //注意空格
                file "slaves/zytest.com.zone";
        };

# cd /var/named/chroot/var/named
# chown named.named slaves/ 
drwxr-xr-x 2 named named 4096 3月  31 02:43 slaves //权限是否为named？

# rndc-confgen -r /dev/urandom -a
# /etc/init.d/named restart 重启服务。

# ls -l /var/named/chroot/var/named/slaves 
-rw-r--r-- 1 named named 369 3月  31 02:43 zytest.com.zone //是否已经把主的配置文件抓取过来了？

# vim /etc/resolv.conf 
nameserver 127.0.0.1   //把DNS指自己，看看是否可以解析？
# host www.zytest.com
# dig  www.zytest.com



  
                   


第十章 APACHE WEB服务
                                       第11章 Apache(WEB服务)
 一、Web服务的概念
1.1、Web服务通常来说都是C/S架构，分为服务端和客户端，通常我们接触最多的就是客户端了。
我们常浏览的网站都是以WEB服务的方式为我们呈现.
 WEB服务分为服务端和客户端
 常见的服务端有(apache nginx tomcat jetty lighttp IIS等)，WEB容器，
 常见的客户端有(IE浏览器，火狐浏览器、谷歌浏览器、360浏览器等等)
  
 
1.2、通信协议
那么既然有服务端和客户端之分。那么就会有服务端和客户端之间的通信。
WEB服务端和客户端之间的通信主要是依赖于(http协议 Hypertext Transfer Protocol)协议传输数据.
俗称(超文本传输协议)
   当前使用最多的HTTP版本是http/1.1。
   http://www.baidu.com
   
   WEB浏览器-------------------------------> Web Server
    打开一个port:>1024的端口                    
    WEB浏览器<-------------------------------Web Server
                        Port:80   Http默认使用80端口.
1.3、Http方法
Http定义了很多种方式，客户端通过不同的方式与Web服务器进行交互，常见的方法有：
-GET 从服务器上获取一个资源(一般是网页)
-POST 向服务器提交数据(可能会创建一个新的资源)
-PUT 向服务器提交数据
-DELETE 删除制定的资源
-HEAD 只请求网页的头部信息.

1.4、Http返回状态
-200 正常，请求成功
-301 永久移动，一般用于域名重定向
-304 未修改，一般用于缓存 
-401 禁止访问，未授权
-403 禁止访问，通常代表以认证通过，但是没有访问权限。
-404 未找到资源
-500 服务器内部错误.




1.5、Web静态程序
HTML语言(Hyper Text Makup Language）是绝对大多数网页使用的语言，几乎所有的网页都是以HTML作为源代码，通过浏览器就解释之后在呈现出来。
HTML拥有的语法是固定的，主要是用来存储网页数据，定义不同的元素，比如：文字，标题，段落，图片等等，现在代网页通过CSS语言来存储网页的表现样式，
  目前主流网页设计框架：
     内存存储:HTML
     网页架构:Div
     网页样式:CSS
我们可以通过打开浏览器，右击选择源码来查看网页的HTML源码。
HTML形式的页面我们称为：静态网页.
  
1.6、Web动态程序
HTML格式的网页文件只能提供静态的内容，但是我们根据不同的业务，以及不同的用户提供不同的内容，也就是说，希望同一个页面针对不同的用户、不同的时间、或者不同的区域反馈和展现不同的内容，这样我们就需要一个动态的网页语言。
  目前主流的网站使用动态语言技术有:
      常见的动态语言:JSP、asp.net(微软) JSP(JAVA)、PHP等
      新出来的敏捷行比较高的语言:python或者ruby on rails等.
动态语言和静态最大的区别。就是数据库，动态语言存储数据都放在数据库里面，而静态的语言可能就放在某一个文件目录下。所有的文件都不变的。






二、Apache概念
2.1、基本概述
在企业实际的生产环境当中，有很多多WEB服务器的种类，我们上面有提到过的（IIS，Apache，Nginx，lighttp等）
Apache是最为老牌的WEB服务器，基础支持所有的操作系统。
  那么几乎所有的Linux发型版都支持Apache，Apache具有一下特点:
    动态的、预创进程
    (apache 可以动态去预建一些服务进程，可以更好的利用服务器资源，可以基于网站的压力。动态创建一些进程)  
    
    动态模块加载
    (比如：给apache增加一些功能，可以支持的动态的模块加载。什么意思？比如我这个apache服务正在运行，我需要加一个新的功能模块，正常来说都需要停止服务，对于真是环境种，不能去停止WEB服务，但是apache可以不用停止服务，就可以动态加载模块，把功能加入进去)
    
    虚拟主机
    (可以通过虚拟主机，跑多个网站程序)
                 用户来访问的时候
  
    SSL主机
    (支持SSL协议加密)
    
    
2.2、工作模式<重点>
   Apache有两种工作模式:
     Prefork模式(进程模式)：
         使用多个子进程，但是每一个子进程只有一个线程，每个进程在某个确定的时间只能维持一个链接，
         大多数的平台上Prefork MPM 在效率上要比Worker MPM要高，但是内存使用要大的多，
         对于那些使用线程困难的平台，可以选择Prefork MPM模式
     
      Worker模式(线程模式)： 
          worker MPM使用多个子进程，但是每个一个进程可以有多个线程，每个一个线程在某个确定的时间只能维持一个链接，
          通常来说，那些个高流量的HTTP服务器上，Worker MPM是一个比较好的选择.
          因为worker MPM的内存要比Prefork MPM 要低的多.
         
MPM(Mutil-Processing-Modules）的缩写,就是多处理模块的意思.
          
     
    
    
    
     
     
三、Apache基础安装
默认使用80端口(HTTP) 安全协议端口为443(HTTPS）

3.1、Apache配置文件
主配置文件
# /etc/httpd/httpd.conf

模块配置文件
# /etc/httpd/conf.d/

默认网站日志
# /var/log/httpd

默认WEB目录为
# /var/www/html



3.2、安装Apache服务
# yum -y install httpd

# /etc/init.d/httpd start   //apache默认不需配置就可以启动.

# echo "this is test"  >/var/www/html/index.html

# vim /etc/httpd/httpd.conf
KeepAlive Off  #是否允许保持链接(每个链接有多个请求)OFF无效。
MaxKeepAliveRequests 100 #每个链接最大的请求数量 0表示无限制,根据企业实际来做调整.
KeepAliveTimeout 15 #在同一链接同一客户端连个请求之间的等待时间.
Listen 80   #允许将Aapche绑定到指定的端口，
LoadModule auth_basic_module modules/mod_auth_basic.so  #增加模块的区域
User apache #使用帐号
Group apache #使用组
ServerName localhost:80 
ServerAdmin root@localhost #设置管理员邮箱
DocumentRoot "/var/www/html" #设置默认的WEB程序目录
<Directory "/var/www/html"> #设置默认的WEB程序目录
<Directory/>
DirectoryIndex index.html index.html.var #设置网站首页的网页文件名称.



四、Apache配置简单用户认证
我们可以通过配置Apache位特定文件夹进行简单的HTTP用户认证，达到简单的访问控制功能。
可以使用那些用户可以访问，那些用户不可访问.

4.1、创建Apache密码文件
#useradd alvin
# htpasswd -cm /etc/httpd/.htpasswd alvin  #创建一个密码文件，同时设置密码 
# htpasswd -m /etc/httpd/.htpasswd alvin   #更改现有的用户密码

4.2、更改配置文件
# vim /etc/httpd/httpd.conf
ServerName localhost:80
<Directory /var/www/>  #要配置用户认证的WEB目录
AuthName "Linux alvin"
Authtype basic #基本认证
AuthUserFile /etc/httpd/.htpasswd  #指定密码文件
Require valid-user  #打开用户认证
</Directory>






五、Apache配置虚拟主机
5.1、默认的apache的配置，只提供了一个网站服务，但是我们可以配置一台apahce服务器为多个网站提供服务，
我们称为:虚拟主机
   虚拟主机分为两种:
    基于IP的虚拟主机: apache服务通过不同IP访问不同的虚拟主机
    基于域名的虚拟主机:apache服务通过访问不同域名，访问不同的虚拟主机
一般情况都是域名的虚拟主机，如果需要搭建SSL的虚拟主机，则必须使用基于IP的虚拟主机
一般的网站往往不需一个独立的服务器的硬件资源，使用虚拟主机技术在一个服务器上运行多个网站可以大大的节省成本，提高服务器资源使用的效率.









5.2、基于域名的虚拟主机


# mkdir /opt/web1/
# mkdir /opt/web2/
# mkdir /opt/web3/
# echo "this is web1" > /opt/web1/index.html
# echo "this is web2" > /opt/web2/index.html
# echo "this is web3" > /opt/web2/index.html
# chown apache:apache /opt/web1/ -R
# chown apache:apache /opt/web2/ -R
# chown apache:apache /opt/web3/ -R

(1)相同的端口号，区分不同主机名，
www1.zytest.com-->10.0.0.201 端口号:80
www2.zytest.com-->10.0.0.201 端口号:80
# vim /etc/httpd/conf/httpd.conf
 #打开它。
NameVirtualHost *:80  

<VirtualHost *:80>
    ServerName www1.zytest.com
    ServerAdmin alvintest@163.com
    DocumentRoot /opt/web/www1.zytest.com/
   ErrorLog logs/zytest.com-error_log
    CustomLog logs/zytest.com-access_log common
</VirtualHost>

<VirtualHost *:80>
    ServerName www2.zytest.com
    ServerAdmin alvintest@163.com
    DocumentRoot /opt/web/www2.zytest.com/
   ErrorLog logs/zytest.com-error_log
    CustomLog logs/zytest.com-access_log common
</VirtualHost>

# /etc/init.d/httpd restart

    
   
    
        

(2)相同的端口号。区分不同的域名
www1.zytest.com-->10.0.0.201 端口号:80
www2.cctest.com-->10.0.0.201 端口号:80

# vim /etc/httpd/conf/httpd.conf
<VirtualHost *:80>
    ServerName www1.zytest.com
    ServerAdmin alvintest@163.com
    DocumentRoot /opt/web1/
   ErrorLog logs/zytest.com-error_log
    CustomLog logs/zytest.com-access_log common
</VirtualHost>

<VirtualHost *:80>
    ServerName www2.cctest.com
    ServerAdmin alvintest@163.com
    DocumentRoot /opt/web2/
   ErrorLog logs/zytest.com-error_log
    CustomLog logs/zytest.com-access_log common
</VirtualHost>

# /etc/init.d/httpd restart


(3)、不同的端口号，不同域名
www1.zytest.com-->10.0.0.201 端口号:80
www2.cctest.com-->10.0.0.201 端口号:8080
www.zyalvin.com-->10.0.0.201 端口号:81

# vim /etc/httpd/conf/httpd.conf

#修改 重点
Listen 80
Listen 8080
Listen 81

#修改 重点
NameVirtualHost *:80
NameVirtualHost *:8080
NameVirtualHost *:81
<VirtualHost *:80>
    ServerName www1.zytest.com
    ServerAdmin alvintest@163.com
    DocumentRoot /opt/web1/
   ErrorLog logs/zytest.com-error_log
    CustomLog logs/zytest.com-access_log common
</VirtualHost>

<VirtualHost *:8080>
    ServerName www2.cctest.com
    ServerAdmin alvintest@163.com
    DocumentRoot /opt/web2/
   ErrorLog logs/zytest.com-error_log
    CustomLog logs/zytest.com-access_log common
</VirtualHost>

<VirtualHost *:81>
    ServerName www.zyalvin.com
    ServerAdmin alvintest@163.com
    DocumentRoot /opt/web3/
   ErrorLog logs/www.zyalvin.com-error_log
    CustomLog logs/www.zyalvin.com-access_log common
</VirtualHost>

# /etc/init.d/httpd restart
 
 

本章作业题目：
(1)要求搭建一个简单的默认HTTPD服务器，访问内容为:this is shuangxikeji

(2)要求搭建一个简单的用户认证服务器，用户为：gonda，密码自由定义。

(3)要求搭建基于虚拟主机WEB服务器
      .1 要求基于相同的端口号，区分不同的主机名
      .2 要求基于相同的端口号，分区不同的域名访问
      .3 要求基于不同的端口号，分区不同的域名访问.
      
         
     
  
   
   
   
       
    




                    
    
                        
                        
                        
                        
   
 
 
 
 
 
                                       


第十一章 安全服务IPTALES
安全服务--Iptales
一、网络安全访问控制
我们都知道，Linux一般作为服务器使用，对外提供一些基于网络的服务，通常我们都需要对服务器进行一些网络控制，
类似防火墙的功能，
  常见的访问控制包括：那些IP可以访问服务器，可以使用那些协议，那些接口。那些端口 是否需要对数据包进行修改
  等等。
如果某服务器受到攻击，或者来自互联网哪个区域或者哪个IP的攻击，这个时候应该禁止所有来自该IP的访问。
那么Linux底层内核集成了网络访问控制，通过netfilter模块来实现.



二、IPTables
Linux内核通过netfilter模块实现网络访问控制功能，
在用户层我们可以通过iptables程序对netfiter进行控制和管理
netfilter支持通过以下方式对数据包进行分类:
-源IP地址
-目标IP地址
-使用接口
-使用协议(TCP、UDP、ICMP等)
-端口号
-链接状态(new、ESTABLISHED、RELATED、INVALID）




三、Netfilter概念
Netfileter分为:5条链和3张表

链                                             表
                             filter表         nat表              mange表                                                                                       

INPUT(输入进来的数据)       只支持filter和mangle表
FORWARD(转发的数据)        只支持filter和mangle表
OUTPUT(输出，出去的数据)    支持filter nat和mangle表
PREROUTING((DNAT)要把别人的公网地址转换成你们内部的IP，数据流入必然经过PRE)   支持nat和mangle表
POSTROUTING（（SNAT）把内部的私有地址转换成公有地址,数据流出必然经过POS)  支持nat和mangle表

filter表--用以对数据进行过滤
nat表 --用以对数据包的源、目标地进行修改
mangle表--用以对数据进行高级修改


总结如下:
1：filter表
***************************************************************************
INPUT 		链 ：应用于发往本机的数据包

OUTPUT		链 ：应用于路由经过本地的数据包

FORWARD	链 ：本地产生的数据包	
***************************************************************************
2：nat表
PREROUTING  	链 ：修改到达的数据包

OUTPUT     	链 :  路由之前，修改本地产生数据包

POSTROUTING	链 :  数据包发送前，修改该包
****************************************************************************
3：mange表
PREROUTING   	链 ：(DNAT)要把别人的公网地址转换成你们内部的IP，数据流入必然经过PRE

INPUT   	   链 ：应用于发送给本机的数据包

FORWARD 	   链 ：修改经过本机路由的数据包

OUTPUT 	       链 ：路由之前，修改本地产生的数据包

POSTROUTING 	链 ：（SNAT）把内部的私有地址转换成公有地址,数据流出必然经过POST
******************************************************




四、常用的功能
iptbales作为服务器使用;
（1）过滤到本机的流量 -input链、filter表
（2）过滤到本机的流量 -output链、filter表

iptbales作为路由器使用:
(1) 过滤转发的流量 -forward链、filter表
(2) 对转发数据的源、目标IP进行修改(NAT功能) -forward链、nat表

iptables规则属性
iptables -t filter -A INPUT -s 10.0.0.201 -j DROP
              |         |          |          | 
              表        链       匹配属性       动作


一个iptables命令创建一个规则。主要包含以下几个部分
表:规定使用得表(filter nat mangle，不同的表不同的功能)
链:规定过滤点
匹配属性:规定匹配数据包的特征
匹配后的动作：放行、丢弃、记录 



五、iptables参数定义
以配置参数可以自由组合

－v 显示端口流量
－a  所有  all缩写
－D 删除
－I 		插入，往所有规则第一条上面插入
－s 		源IP
--sport 	源端口
－d 		目标IP
--dport 	目标端口
-i  input
接口 eth0 

-o Output
接口 eth0

-A  增加一条策略

-p 指定匹配的协议

-j 动作，是丢弃还是通过 DROP(丢弃包) REJECT(拦阻该封包) ACCEPT(允许放行)
/etc/sysconfig/iptables 配置文件
service iptables save 保存规则
--line-numbers 显示规则编号


常用命令(-A追加规则、-D删除规则、-R修改规则、-I插入规则、-L查看规则)

命令 -D, --delete删除规则
iptables -D INPUT 1

	  
  
命令 -R, --replace修改规则
范例 iptables -R INPUT 1 -s 192.168.0.1 -j DROP



命令 -I, --insert 插入规则
范例 iptables -I INPUT 1 --dport 80 -j ACCEPT
说明 插入一条规则，原本该位置(这里是位置1)上的规则将会往后移动一个顺位。


命令 -L, --list
范例 iptables -L INPUT
说明 列出某规则链中的所有规则。



命令 -F, --flush
范例 iptables -F INPUT
说明 删除某规则链(这里是INPUT规则链)中的所有规则。



命令 -Z, --zero
范例 iptables -Z INPUT
说明 将封包计数器归零。封包计数器是用来计算同一封包出现次数，是过滤阻断式攻击不可或缺的工具。



命令 -N, --new-chain
范例 iptables -N allowed
说明 定义新的规则链。


命令 -X, --delete-chain
范例 iptables -X allowed
说明 删除某个规则链。

命令 -P, --policy
范例 iptables -P INPUT DROP
说明 定义过滤政策。 也就是未符合过滤条件之封包，预设的处理方式。


命令 -E, --rename-chain
范例 iptables -E allowed disallowed
说明 修改某自订规则链的名称。






六、IPTBALES案例
如果想清空的话，先执行/sbin/iptables -P INPUT ACCEPT 
然后执行/sbin/iptables -F 
通过iptables -L 看到如下信息
注意防火是先允许后拒绝，如果先拒绝的话。那么后面允许将不会生效。


#filter 表操作
(1)允许10.0.0.254 PING我的主机10.0.0.201
# iptables -t filter -I INPUT 2 -s 10.0.0.254 -d 10.0.0.201 -p icmp -j ACCEPT 



(2)禁止所有人PING我的主机10.0.0.201
# iptables -t filter -A INPUT -d 10.0.0.201 -p icmp -j DROP


(3)允许10.0.0.254 和我的笔记本 访问我的80端口和SSH端口
# iptables -t filter -A INPUT -s 10.0.0.254 -d 10.0.0.201 -p tcp --dport 22 -j ACCEPT 
# iptables -t filter -A INPUT -s 10.0.0.3 -d 10.0.0.201 -p tcp --dport 22 -j ACCEPT

# iptables -t filter -A INPUT -s 10.0.0.254 -d 10.0.0.201 -p tcp --dport 80 -j ACCEPT
# iptables -t filter -A INPUT -s 10.0.0.3 -d 10.0.0.201 -p tcp --dport 80 -j ACCEPT  


(4)其余的人全部拒绝连接SSH 端口号
# iptables -t filter -A INPUT -d 10.0.0.201 -p tcp --dport 22 -j DROP
# iptables -t filter -A INPUT -d 10.0.0.201 -p tcp --dport 80 -j DROP



#nat表操作
POSTROUTING 链 是将本地ip地址伪装成公网ip地址<源>
-o eth0 是 –output eth0 的缩写
-i eth0 是  –input eth0  的缩写
PREROUTING 链 是将外网地址IP转换成内网地址 <目标>
DNAT     转换目标地址
SNAT      转换源地址
1024:65535 端口转换范围 中间段写法
1024-65535 端口转换范围 最后一段写法
 any/0    所有IP地址，不限制范围  -d any/0   -s any/0

 
(1)、启动内部对外转址
#,将10.0.0.0 这个网段，伪装成118.251.117.250出去，此IP为防火墙外网IP。
(DNAT)要把别人的公网地址转换成你们内部的IP，数据流入必然经过PRE
#iptables -t nat -A POSTROUTING -o eth0 -s 10.0.0.0/16 -j SNAT --to-source 118.251.117.250
# iptables -L -t nat 查看


-----
|网口公网地址。
IPTABLES
|
|
LVS
\
WEB WE
\REDIS
\MYSQL
\















(2)、启动内部对外转址
#,将10.0.0.0/16 这个网段，允许访问外网的http 80端口，到公网后转换成118.251.117.250
 #iptables -t nat -A POSTROUTING -o eth1 -p tcp -s 10.0.0.0/16 --dport 80 -j SNAT --to-source 118.251.117.250
 
(3):启动端口影射
将内网的web服务器10.0.0.201的80端口发布出去
当外网地址访问$FW_IP 80端口的时候，将其转发到10.0.0.201
#:$FW_IP=”118.251.117.250”
#iptables -t nat -A PREROUTING -i eth1 -p tcp -d 118.251.117.250 --dport 80 -j DNAT --to-destination 10.0.0.201




七、IPTBALES本章作业
(1)允许10.0.2.254可以PING你的地址，其它人全部禁止

(2)允许10.0.2.254和你目前用的真实机可以ssh登陆你的机器，其它的全部禁止掉

(3)允许10.0.2.254访问你的20 和21号端口，其它人全部禁止

(4)禁止10.0.2.254访问你的53号端口。其它的人全部允许

(5)禁止10.0.2.254访问你的80端口，其它人全部允许

(6)允许10.0.0.2.254访问你的23端口。其它人全部禁止

(7)通过NAT表WEB服务器10.0.2.231的80端口发布出去。

(8)通过NAT表FTP服务器10.0.2.232的20 21端口发布出去








端口号
smaba服务，启用端口tcp139，和tcp445
nfs服务：nfsd：2049，portmap ：111
bind服务：监听端口：53（tcp/udp），解析域名为udp
xinetd服务：监听端口：37
https服务：443（tcp）
http服务 ：80
mysql 3306
ssh 22 
echo  7
ftp   21   
telnet 23
time 37 
http 80 
kerberos kerberos 网络掩张系统  88
ntp 123 
tcp login 远程的登陆  513 
kermit  文件传输和管理服务 1649
HTTP     超文本传输协议 8008  
www 万维网 8080  
SMTP 25 简单邮件传输协议
pop3 110 

小总结


1
1：查看指定端口的进程
  root用户权限
  1、ps -ef| grep 端口
  2、lsof -i:端口
  普通用户权限
  1、ps -ef| grep 端口
2：查看http服务是否正常
  1、w3m http://******* (通过使用"q"退出该命令)
  2、wget http://*******
  ping
3：使用tar命令打包和解包
  打包：
  tar cvzf 文件名.tar.gz 文件名 文件夹/
  
  解包
  tar xzfv 文件名.tar.gz

  
5：查看执行命令历史记录
  1、history | grep 命令名
  2、linux用户下面指定的文件(.bash_history)
  
6：修改本次操作的系统环境
  export JAVA_HOME=/home/taps/jdk1.6.0_13
  export JRE_HOME=$JAVA_HOME/jre
  export CLASSPATH=.:$JAVA_HOME/jre/lib:$JAVA_HOME/lib/tools.jar
  export PATH=:$JAVA_HOME/bin:$PATH
  export CATALINA_HOME=/home/taps/apache-tomcat-5.5.23
  export PATH=$CATALINA_HOME/bin:$PATH
  
  上述命令可以将其放入至.profile文件中，然后执行命令(source .profile)即加载运行变量


13：检测linux系统内存
    权限：root
    more /proc/meminfo | grep MemTotal
14：检查网络配置
   权限：root
   netstat -r n

16：检测CPU占用率
   权限：root
   top
17：检查内存占用率
   权限：root
   free -t
18：查看进程
   权限：root
   统计总进程数
   ps -ef | wc -l
   查看Z（僵死zombie）进程
   ps -elf | awk '{print $2}' | grep Z

20：zip压缩和解压
    压缩
    zip -r /opt/abc.zip /opt/abc/ 
    解压
    unzip ***.zip
21：使用scp远程拷贝文件/文件夹
    
    注意：使用这个命令的前提条件是需要开通ssh服务。
    
    拷贝文件：
    scp 文件或文件夹 需要拷贝至目标机器IP:需要保持目录
    scp 本地用户名 @IP 地址 : 文件名 1 远程用户名 @IP 地址 : 文件名 2 
    例题：scp /iso/install.tar 10.128.100.116:/home/
    拷贝文件夹：
    scp -r db/ 10.128.100.117:/temptest/
22：linux中增加域名映射
    即将所需要映射的IP及域名映射关系关系写入 /etc/hosts文件中。
    如：echo "19.145.19.52 image.baidu.com" >> /etc/hosts
23：Linux抓包
    tcpdump -i bond0 -s 0 -w update2.pcap host 118.123.253.67 and tcp port 8080
    
    tcpdump -i bond1 -s 0 -w test8999.cap -X  port 8999(监控8999端口所有数据)
    tcpdump -i bond1 -s 0 -w test8999.cap -X (监控网卡bond1所有数据)

    说明：
    1)-i eth9
       指明抓取网卡eth9上的包
    2)-s 0
       指明每个包的最大大小，默认为96 Bytes，这样会导致抓到的包只有前96字节，因此一般设为0，表示不限制大小。
    3)-w update.pcap
       指明将抓到的包存储到update.pcap文件中
    4)host 10.168.22.220 and tcp port 80
       抓包过滤条件表达式，该表达式和wireshark的过滤表达式类似
24：查看所有用户命令
    cat /etc/passwd |cut -f 1 -d : 
25：查看系统目前资源限制的设定
    操作权限：root
    ulimit -a 
    如：
    core file size        (blocks, -c) 0 
    data seg size         (kbytes, -d) unlimited 
    file size             (blocks, -f) unlimited 
    max locked memory     (kbytes, -l) unlimited 
    max memory size       (kbytes, -m) unlimited 
    open files                    (-n) 1024 
    pipe size          (512 bytes, -p) 8 
    stack size            (kbytes, -s) 8192 
    cpu time             (seconds, -t) unlimited 
    max user processes            (-u) 7168 
    virtual memory        (kbytes, -v) unlimited 
26：修改open files文件句柄大小
    ulimit -n 4068(这个只是在当初有效)
    要使永久有效，可操作如下：
    /etc/profile ulimit -n 10000
    source /etc/profile 
 
30：查看linux服务所在地址
    whereis ftp(查看ftp服务)
31：ssh 出现如下异常
    It is also possible that the RSA host key has just been changed.
    The fingerprint for the RSA key sent by the remote host is
    
    将本地的/root/.ssh/kown_hosts删除，然后再从ssh操作下。
32：Netstat用于显示与IP、TCP、UDP和ICMP协议相关的统计数据，一般用于检验本机各端口的网络连接情况
    
    netstat -r：检查机器路由信息
33：通过使用netstat查看具体某个端口
    netstat -an|grep -w 22


38：添加静态路由命令（重启机器则失效）
    当从A机器不能访问B机器时，可以通过添加静态路由解决此问题，只需要在B机器配置如下命令
   如：route add -net 192.168.9.0 netmask 255.255.255.0 gw 192.168.4.1（网关） eht1（网卡） 
 
39：查看进程详细信息
   ps -auxef|grep 进程名 
 
40：查看进程所占端口
   ps -npl |grep 进程名
 


 
44：查看系统所有用户组信息
vi /etc/group
 
45：给网卡增加IP地址
ifconfig  eth6 192.168.3.111 netmask 255.255.255.0

 
46：挂载和反挂载
挂载mount /dev/mapper/vg_virtual-lv_virtual_1 /home/test/sharevolume  反挂载umount /dev/mapper/vg_virtual-lv_virtual_1或umount /home/test/sharevolume 
47：类似Dos时代的autoexec.bat，和Windows开始菜单中的启动菜单组 
将脚步增加至该文件中/etc/init.d/boot.local48：卸载裸设备指定major 和 minor 为 0 0，即可卸载裸设备的绑定。#/usr/sbin/raw /dev/raw/raw1 0 0/dev/raw/raw1: bound to major 0, minor 049：查找文件find ./ -name "alert*.log"50：手工绑定浮动IP地址到网卡上ifconfig bond0:1 IP netmask 子网掩码 up51：SUSE单网卡虚拟成多网卡案例SUSE单网卡虚拟成多网卡案例：
   1：用户root用户登录
   2：cd /etc/sysconfig/network/
   3: 打开物理网卡配置
       vi ifcfg-eth-id-xx.xx.xx.xx.xx
   
   4: 加入虚拟网卡配置至文件中。
      IPADDR_1='192.168.0.174'
      NETMASK_1='255.255.255.0'
      LABEL_1='1'
     IPADDR_2='192.168.0.175'
      NETMASK_2='255.255.255.0'
      LABEL_2='2'
      IPADDR_3='192.168.0.176'
       NETMASK_3='255.255.255.0'
      LABEL_3='3'    5：重启网卡
    /etc/rc.d/network restart52：卸载raw设备和卸载裸设备指定major 和 minor 为 0 0，即可卸载裸设备的绑定。#/usr/sbin/raw /dev/raw/raw1 0 0/dev/raw/raw1: bound to major 0, minor 053：卸载loop$ umount /dev/loopN
$ losetup -d /dev/loopN
$ rm FS_on_file



NC NETCAT
        NC


语　法：nc [-hlnruz][-g<网关...>][-G<指向器数目>][-i<延迟秒数>][-o<输出文件>][-p<通信端口>][-s<来源位址>][-v...][-w<超时秒数>][主机名称][通信端口...]
参　数：
 -g<网关> 设置路由器跃程通信网关，最丢哦可设置8个。
 -G<指向器数目> 设置来源路由指向器，其数值为4的倍数。
 -h  在线帮助。
 -i<延迟秒数> 设置时间间隔，以便传送信息及扫描通信端口。
 -l  使用监听模式，管控传入的资料。
 -n  直接使用IP地址，而不通过域名服务器。
 -o<输出文件> 指定文件名称，把往来传输的数据以16进制字码倾倒成该文件保存。
 -p<通信端口> 设置本地主机使用的通信端口。
 -r  乱数指定本地与远端主机的通信端口。
 -s<来源位址> 设置本地主机送出数据包的IP地址。
 -u  使用UDP传输协议。
 -v 详细输出--用两个-v可得到更详细的内容
 -w<超时秒数> 设置等待连线的时间。
  -z  使用0输入/输出模式，只在扫描通信端口时使用。
 
1. 端口扫描
# nc -v -w 2 192.168.2.34 -z 21-24
nc: connect to 192.168.2.34 port 21 (tcp) failed: Connection refused
Connection to 192.168.2.34 22 port [tcp/ssh] succeeded!
nc: connect to 192.168.2.34 port 23 (tcp) failed: Connection refused
nc: connect to 192.168.2.34 port 24 (tcp) failed: Connection refused

http://blog.csdn.net/xifeijian/article/details/9348277


双机-- 两台机器之前进行冗余
热备--不影响正常业务进行的条件下进行备份 
LVS LB

XARGS  



find /sbin -perm +700 |xargs ls -l   这样才是正确的

args用法详解
1. 简介
  之所以能用到这个命令，关键是由于很多命令不支持|管道来传递参数，而日常工作中有有这个必要，所以就有了xargs命令，例如：
find /sbin -perm +700 |ls -l       这个命令是错误的
find /sbin -perm +700 |xargs ls -l   这样才是正确的
xargs 可 以读入 stdin 的资料，并且以空白字元或断行字元作为分辨，将 stdin 的资料分隔成为 arguments 。 因为是以空白字元作为分隔， 所以，如果有一些档名或者是其他意义的名词内含有空白字元的时候， xargs 可能就会误判了～他的用法其实也还满简单的！就来看一看先！
2. 选项解释
-0 当sdtin含有特殊字元时候，将其当成一般字符，想/'空格等
例如：root@localhost:~/test#echo "//"|xargs  echo 
      root@localhost:~/test#echo "//"|xargs -0 echo 
       /
-a file 从文件中读入作为sdtin，（看例一）
-e flag ，注意有的时候可能会是-E，flag必须是一个以空格分隔的标志，当xargs分析到含有flag这个标志的时候就停止。（例二）
-p 当每次执行一个argument的时候询问一次用户。（例三）
-n num 后面加次数，表示命令在执行的时候一次用的argument的个数，默认是用所有的。（例四）
-t 表示先打印命令，然后再执行。（例五）
-i 或者是-I，这得看linux支持了，将xargs的每项名称，一般是一行一行赋值给{}，可以用{}代替。（例六）
-r no-run-if-empty 当xargs的输入为空的时候则停止xargs，不用再去执行了。（例七）
-s num 命令行的最好字符数，指的是xargs后面那个命令的最大命令行字符数。（例八）
 
-L  num Use at most max-lines nonblank input lines per command line.-s是含有空格的。
-l  同-L
-d delim 分隔符，默认的xargs分隔符是回车，argument的分隔符是空格，这里修改的是xargs的分隔符（例九）
-x exit的意思，主要是配合-s使用。
-P 修改最大的进程数，默认是1，为0时候为as many as it can ，这个例子我没有想到，应该平时都用不到的吧。


3. 使用情况

xargs 是给命令传递参数的一个过滤器，也是组合多个命令的一个工具。它把一个数据流分割为一些足够小的块，以方便过滤器和命令进行处理。通常情况下，xargs 从管道或者stdin中读取数据，但是它也能够从文件的输出中读取数据。xargs的默认命令是echo，这意味着通过管道传递给xargs的输入将会包 含换行和空白，不过通过xargs的处理，换行和空白将被空格取代。
xargs 是一个强有力的命令，它能够捕获一个命令的输出，然后传递给另外一个命令，下面是一些如何有效使用xargs 的实用例子。

1. 当你尝试用rm 删除太多的文件，你可能得到一个错误信息：/bin/rm Argument list too long. 用xargs 去避免这个问题
find ~ -name ‘*.log’ -print0 | xargs -0 rm -f


2. 获得/etc/ 下所有*.conf 结尾的文件列表，有几种不同的方法能得到相同的结果，下面的例子仅仅是示范怎么实用xargs ，在这个例子中实用 xargs将find 命令的输出传递给ls -l
# find /etc -name "*.conf" | xargs ls –l

3. 假如你有一个文件包含了很多你希望下载的URL, 你能够使用xargs 下载所有链接
# cat url-list.txt | xargs wget –c



4. 查找所有的jpg 文件，并且压缩它
# find / -name *.jpg -type f -print | xargs tar -cvzf images.tar.gz


5. 拷贝所有的图片文件到一个外部的硬盘驱动 
# ls *.jpg | xargs -n1 -i cp {} /external-hard-drive/directory

举例：例一：
root@localhost:~/test#cat test 
#!/bin/sh
echo "hello world/n"
root@localhost:~/test#xargs -a test echo
#!/bin/sh echo hello world/n
root@localhost:~/test#
例二：
root@localhost:~/test#cat txt
/bin tao shou kun
root@localhost:~/test#cat txt|xargs -E 'shou' echo
/bin tao
root@localhost:~/test#
例三：
root@localhost:~/test#cat txt|xargs -p echo
echo /bin tao shou kun ff ?...y
/bin tao shou kun ff
例四：
root@localhost:~/test#cat txt|xargs -n1 echo
/bin
tao
shou
kun
root@localhost:~/test3#cat txt|xargs  echo
/bin tao shou kun
例五：
root@localhost:~/test#cat txt|xargs -t echo
echo /bin tao shou kun 
/bin tao shou kun
例六：
$ ls | xargs -t -i mv {} {}.bak
例七：
root@localhost:~/test#echo ""|xargs -t mv
mv 
mv: missing file operand
Try `mv --help' for more information.
root@localhost:~/test#echo ""|xargs -t -r  mv
root@localhost:~/test#
（直接退出）
例八：
root@localhost:~/test#cat test |xargs -i -x  -s 14 echo "{}"
exp1
exp5
file
xargs: argument line too long
linux-2
root@localhost:~/test#
例九：
root@localhost:~/test#cat txt |xargs -i -p echo {}
echo /bin tao shou kun ?...y
root@localhost:~/test#cat txt |xargs -i -p -d " " echo {}
echo /bin ?...y
echo tao ?.../bin
y
echo shou ?...tao
再如：
root@localhost:~/test#cat test |xargs -i -p -d " " echo {}
echo exp1
exp5
file
linux-2
ngis_post
tao
test
txt
xen-3
 ?...y
root@localhost:~/test#cat test |xargs -i -p echo {}
echo exp1 ?...y
echo exp5 ?...exp1
y
echo file ?...exp5
y
  

特殊符号
. dot  当前目录  .. 上层目录 

'string' 单引号 (single quote)
被单引号用括住的内容，将被视为单一字串。在引号内的代表变数的$符号，没有作用，也就是说，他被视为一般符号处理，防止任何变量替换。

"string" 双引号 (double quote)
被双引号用括住的内容，将被视为单一字串。它防止通配符扩展，但允许变量扩展。这点与单引数的处理方式不同。

\ 倒斜线
在交互模式下的escape 字元，有几个作用；放在指令前，有取消 aliases的作用；放在特殊符号前，则该特殊符号的作用消失；放在指令的最末端，表示指令连接下一行。
# type rmrm is aliased to `rm -i'# \rm ./*.log
上例，我在 rm 指令前加上 escape 字元，作用是暂时取消别名的功能，将 rm 指令还原。
# bkdir=/home# echo "Backup dir, \$bkdir = $bkdir"Backup dir,$bkdir = /home
上例 echo 内的 \$bkdir，escape 将 $ 变数的功能取消了，因此，会输出 $bkdir，而第二个 $bkdir则会输出变数的内容 /home。


$*  以一个单字符串显示所有向脚本传递的参数。与位置变量不同，此选项参数可超过 9个，
[root@Master /]# cat aatest.sh 
#!/bin/bash
echo $*
[root@Master /]# ./aatest.sh 1 2 3 4 5 7 8 9 10
1 2 3 4 5 7 8 9 10
以"$1 $2 … $n"的形式输出所有参数。 


$@
$@ 与 $* 具有相同作用的符号，不过她们两者有一个不同点。
符号 $* 将所有的引用变量视为一个整体。但符号 $@ 则仍旧保留每个引用变量的区段观念。

以"$1" "$2" … "$n" 的形式输出所有参数。

$$  脚本运行的当前进程ID号
[root@Master /]# cat aatest.sh 
#!/bin/bash
echo $$
[root@Master /]# ./aatest.sh 
3520

$? 显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误
# ls /tmp/ && echo $?

$#
这也是与引用变量相关的符号，她的作用是告诉你，引用变量的总数量是多少。
echo "$#"
$# 是传给脚本的参数个数 $0 是脚本本身的名字 $1 是传递给该shell脚本的第一个参数 $2 是传递给该shell脚本的第二个参数 $@ 是传给脚本的所有参数的列表$* 是以一个单字符串显示所有向脚本传递的参数，与位置变量不同，参数可超过9个$$ 是脚本运行的当前进程ID号$? 是显示最后命令的退出状态，0表示没有错误，其他表示有错误
!$  代表上一次路径的参数
修改/etc/group
	[root@teacher ~]# vim /etc/group
[root@teacher ~]# tail -1 !$     !$代表上一次的路径参数
tail -1 /etc/group   #注意和passwd文件里gid一致
zhugeliang:x:888:
$# 是传给脚本的参数个数 
$0 是脚本本身的名字
 $1 是传递给该shell脚本的第一个参数
 $2 是传递给该shell脚本的第二个参数
 $@ 是传给脚本的所有参数的列表
 $* 是以一个单字符串显示所有向脚本传递的参数，与位置变量不同，参数可超过9个$$ 是脚本运行的当前进程ID号
 $? 是显示最后命令的退出状态，0表示没有错误，其他表示有错误 


http://blog.csdn.net/xifeijian/article/details/9253011


LSOF 
lsof命令简介：
lsof（list open  files）是一个列出当前系统打开文件的工具。在linux环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，还可以访问网络连接 和硬件。所以，lsof的功能很强大。一般root用户才能执行lsof命令，普通用户可以看见/usr/sbin/lsof命令，但是普通用户执行会显 示“permission denied”。因此通过lsof工具能够查看这个列表对系统监测以及排错将是很有帮助的。
 
在终端下输入lsof即可显示系统打开的文件，因为 lsof 需要访问核心内存和各种文件，所以必须以 root 用户的身份运行它才能够充分地发挥其功能。 
 
每行显示一个打开的文件，若不指定条件默认将显示所有进程打开的所有文件。lsof输出各列信息的意义如下： 
 COMMAND：进程的名称
 PID：进程标识符
 USER：进程所有者
 FD：文件描述符，应用程序通过文件描述符识别该文件。如cwd、txt等
 TYPE：文件类型，如DIR、REG等
 DEVICE：指定磁盘的名称
 SIZE：文件的大小
 NODE：索引节点（文件在磁盘上的标识）
 NAME：打开文件的确切名称
 
lsof指令的用法如下：
lsof abc.txt 显示开启文件abc.txt的进程
lsof 目录名 查找谁在使用文件目录系统

lsof -i :22 知道22端口被哪个进程占用
lsof -c abc 显示abc进程现在打开的文件
lsof -g gid 显示归属gid的进程情况
lsof -n 不将IP转换为hostname，缺省是不加上-n参数
lsof -p 12 看进程号为12的进程打开了哪些文件
lsof -u username 查看用户打开哪些文件
lsof -i @192.168.1.111 查看远程已打开的网络连接（连接到192.168.1.111）
 －－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－
lsof -i 用以显示符合条件的进程情况
语法: lsof -i[46] [protocol][@hostname|hostaddr][:service|port]
46 -> IPv4 or IPv6
protocol -> TCP or UDP
hostname -> Internet host name
hostaddr -> IPv4位置
service -> /etc/service中的 service name (可以不只一个)
port -> 端口号 (可以不只一个)
－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－
 lsof +|-r [t] 控制lsof不断重复执行，缺省是15s刷新
-r，lsof会永远不断的执行，直到收到中断信号
+r，lsof会一直执行，直到没有档案被显示
例子：不断查看目前ftp连接的情况：lsof -i tcp@192.168.1.111:ftp -r


NETSTAT
-a (all)显示所有选项，默认不显示LISTEN相关
 -t (tcp)仅显示tcp相关选项
 -u (udp)仅显示udp相关选项
 -n 拒绝显示别名，能显示数字的全部转化成数字。
 -l 仅列出有在 Listen (监听) 的服務状态
-p 显示建立相关链接的程序名
 -r 显示路由信息，路由表
 -e 显示扩展信息，例如uid等
 -s 按各个协议进行统计
 -c 每隔一个固定时间，执行该netstat命令。
提示：LISTEN和LISTENING的状态只有用-a或者-l才能看到

  列出所有 tcp 端口 netstat -at
  
  列出所有 udp 端口 netstat -au
  
  
  
2. 列出所有处于监听状态的 Sockets
  只显示监听端口 netstat -l

 只列出所有监听 tcp 端口 netstat -lt
 
 只列出所有监听 udp 端口 netstat -lu
 
 列出端口进程占用情况 netstat -pan |grep 8019
 
 
1）查看端口占用情况
netstat -ntlp|grep 端口号   好像-nt就可以查看所以建立链接的IP
 
2）查看某个端口的连接数
netstat -antlp |grep 端口号 |wc -l

 
 

博文
http://os.51cto.com/art/201407/446547.htm   



http://blog.csdn.net/zzz_781111/article/details/11127421  
系统日常管理

TAIL HEAD TAC
[root@teacher lianxi]# tail -n +5 zhaoshiguer.txt |head -n -3
显示从第5行开始到去掉末尾3行之间的内容
zhao suo
tu an gu
tu an wu jiang
xiang ling
cao  er
hou chao
wu juan 
zhao wei


[root@teacher zhaowei]# cat -n passwd |head -8|tail -6
     3	daemon:x:2:2:daemon:/sbin:/sbin/nologin
     4	adm:x:3:4:adm:/var/adm:/sbin/nologin
     5	lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin
     6	sync:x:5:0:sync:/sbin:/bin/sync
     7	shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown
     8	halt:x:7:0:halt:/sbin:/sbin/halt
    
tac 倒着显示 

CAT  EOF  $PATH
# cat >qiwufeiyang <<EOF  在当前目录下产生一个qiwufeiyang的文件，等待你输入，当你输入EOF这个字符串的时候就停止（可以是其他的字符）
> jazz
> du pi wu
> qia qia wu
> pi li wu
> zombi wu
> eof
> EOF


                                         $PATH
[root@teacher lianxi]# echo  $PATH 输出当前用户的查找命令的路径变量（环境变量中的一个变量）
/usr/lib/qt-3.3/bin:/usr/local/sbin:/usr/sbin:/sbin:/usr/local/bin:/usr/bin:/bin:/root/bin
各个路径使用冒号隔开，查看命令的时候就到上面的路径（目录）下查找
[root@teacher lianxi]#
===
[root@teacher lianxi]# which tree 
/usr/bin/tree
[root@teacher lianxi]# mv /usr/bin/tree  /  将tree命令移走
[root@teacher lianxi]# which tree 找不了，因为PATH变量的路径里没有了
/usr/bin/which: no tree in (/usr/lib/qt-3.3/bin:/usr/local/sbin:/usr/sbin:/sbin:/usr/local/bin:/usr/bin:/bin:/root/bin)
[root@teacher lianxi]# tree
bash: /usr/bin/tree: No such file or directory
[root@teacher lianxi]# /tree  使用绝对路径可以使用
[root@teacher lianxi]# echo $PATH
/usr/lib/qt-3.3/bin:/usr/local/sbin:/usr/sbin:/sbin:/usr/local/bin:/usr/bin:/bin:/root/bin
[root@teacher lianxi]# PATH=$PATH:/china  修改PATH变量的值
[root@teacher lianxi]# echo $PATH
/usr/lib/qt-3.3/bin:/usr/local/sbin:/usr/sbin:/sbin:/usr/local/bin:/usr/bin:/bin:/root/bin:/china
[root@teacher lianxi]#

WHEREIS WHICH LOCATE
which和whereis的异同：
	都是在PATH变量的路径下查找命令
	但是whereis可以查看命令的man手册文件的路径，同时不要求命令具有可执行权限
====



locate  ：在整个根目录下查找，比较适合查找文件
which   ：在PATH变量值路径下查找，比较适合查找命令
whereis  ：在PATH变量值路径下查找，比较适合查找命令

env   查看系统里面的环境变量 


ftp://10.0.2.253/note/2ban-linux/system1/di5zhang-5.txt

RPM包下载
http://www.rpmfind.net
http://www.sourceforge.net
其它下载地址：
http://rpm.pbone.net/
http://freshrpms.net/ 或者直接到这里下载： http://ayo.freshrpms.net/redhat/
http://atrpms.physik.fu-berlin.de/ 或者直接到这里下载： http://apt.physik.fu-berlin.de/redhat/
http://dag.wieers.com/ 或者直接到这里下载： http://apt.sw.be/redhat/
http://www.fedora.us/ 或者直接到这里下载： http://download.fedora.us/fedora/redhat/
http://newrpms.sunsite.dk/ 或者直接到这里下载： http://newrpms.sunsite.dk/apt/redhat/

ECHO 123
http://tieba.baidu.com/p/2002752880







清理页面缓存：
echo 1 > /proc/sys/vm/drop_caches

清理索引节点（inode）链接：
echo 2 > /proc/sys/vm/drop_caches

清理页面缓存＋索引节点链接：
echo 3 > /proc/sys/vm/drop_caches

PING WWW.BAIDU.COM
vim /etc/sysconfig/network-scripts/ifcfg-eth0
GATEWAY=
DNS= 

以及  

长链接和短链接的区别

SYSTEM 1


用户～～～～～
,

useradd命令  （adduser）
格式：useradd  [选项]...  用户名
常用命令选项
-u：指定 UID 标记号
-d：指定宿主目录，缺省为 /home/用户名
-e：指定帐号失效时间
-g：指定用户的基本组名（或UID号）（初始组）
-G：指定用户的附加组名（或GID号）
-M：不为用户建立并初始化宿主目录（家目录）
-s：指定用户的登录Shell
-m, --create-home 创建家目录
 -c, --comment COMMENT  用户注释信息
 
 
[root@teacher vnc]# useradd user1 -g GroupA 添加用户user1加入到指定的GroupA组
useradd: group 'GroupA' does not exist    因为GroupA组不存在

[root@teacher vnc]# groupadd GroupA  添加GroupA组
[root@teacher vnc]# useradd user1 -g GroupA

[root@teacher vnc]# id user1
uid=519(user1) gid=520(GroupA) groups=520(GroupA)

[root@teacher vnc]# id root
uid=0(root) gid=0(root) groups=0(root)

[root@teacher vnc]# useradd zhangwuji -c "mingjiao  zhangmen shuaige"  添加用户zhangwuji，并且添加注释信息
[root@teacher vnc]# tail -1 /etc/passwd
zhangwuji:x:520:521:mingjiao zhangmen shuaige:/home/zhangwuji:/bin/bash

/etc/skel/l
每个用户都有的配置文件，只对单独的用户有效
.bash_profile：用户每次登录时执行
.bashrc：每次进入新的Bash环境时执行
.bash_logout：用户每次退出登录时执行
.bash_history  保存上次用户注销前使用的命令

chmod 是用来修改权限
u  user
g  group
o  others
a  all
====
+  是增加权限
-  是去掉权限
=  直接等于某些权限
====
-R：递归修改指定目录下所有文件、子目录的权限




VIM 
===
命令模式
输入模式
末行模式
替换模式
可视模式

vim 作用：
	写脚本
	改配置文件
	新建文本文件
=====
windows  编辑工具
记事本  ---》文本文件  ---》纯字符（字母  特殊符合  ）
写字板
word
wps
=====
gedit    图形文本编辑工具
vim  	是字符界面的编辑工具
====
vi	过时了的
vim  主流的
==
[root@teacher lianxi]# which   vim  查看vim这个命令存在的路径
/usr/bin/vim
[root@teacher lianxi]#
[root@teacher lianxi]# alias  vi=vim  定义一个别名vi等于vim，使用vi的时候，其实就是在使用vim
alias 是定义别名的命令
===
修改主机名

[root@teacher ~]# hostname  station5.sxkeji.com 设置主机名（临时有效，重新启动无效）
[root@teacher ~]# hostname 查看主机名
teacher.sxkeji.com
[root@teacher ~]#
[root@teacher ~]# ifconfig eth0  查看ip地址
eth0      Link encap:Ethernet  HWaddr 00:30:67:F2:10:CF  
          inet addr:10.0.0.253  Bcast:10.0.255.255  Mask:255.255.0.0
==
[root@teacher ~]# vim  /etc/hosts  作用是将域名解析到一个ip地址，有的可以解析，没有不能解析
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
10.0.0.253   teacher.sxkeji.com  teacher  添加这行ip地址和主机名对应的记录
[root@teacher ~]# vim  /etc/sysconfig/network
NETWORKING=yes
HOSTNAME=teacher.sxkeji.com    修改为你的主机名
===
alias  vi=vim
[root@teacher wulin]# alias vi=/usr/bin/vim
都可以定义别名
===
[root@teacher lianxi]# vim  yaan.txt
vim编辑器后面接的文件，如果存在就是打开它，不存在就是新建
===
命令模式
输入模式
末行模式
替换模式
可视模式
====
桃花坞里桃花庵，
桃花庵里桃花仙。
桃花仙人种桃树，
又摘桃花换酒钱。
        唐伯虎
===
i 当前位置插入内容（insert）
a （append）
o 另起一行插入内容
===
末行模式
:q	如果未对文件做改动则退出
:q!	放弃保存并退出
:wq	保存当前文件并退出
:wq!	强制保存当前文件并退出
:x	保存当前文件并退出
:x!	强制保存当前文件并退出
==
在命令模式下使用
[root@teacher lianxi]# chmod 777 bohu.txt  设置权限为777，可以写
ZZ	保存当前文件并退出
===
[root@teacher lianxi]# chmod 444 bohu.txt
效果一样
：x！
：wq！ 强制退出并且保存
===
光标方向移动		上、下、左、右
翻页	Page Down或Ctrl+F	向下翻动一整页内容
Page Up或Ctrl+B  	向上翻动一整页内容
行内快速跳转	Home键或“^”脱字符、数字“0”	跳转至行首
End键或“$”键	跳转到行尾
行间快速跳转	1G或者gg	跳转到文件的首行 
G	跳转到文件的末尾行 （go）
#G	跳转到文件中的第#行   10G
===
:set nu  显示行号
:set number
:set nonu 取消行号
==
u是撤销（undo）
ctrl+r 恢复  recover
==
 删除	x或Del	删除光标处的单个字符
dd	删除当前光标所在行
#dd	删除从光标处开始的#行内容
d^	删除当前光标之前到行首的所有字符
d$	删除当前光标处到行尾的所有字符
复制	yy	复制当前行整行的内容到剪贴板
#yy	复制从光标处开始的#行内容
粘贴	p（小写）	将缓冲区中的内容粘贴到光标位置处之后
P(大写)	粘贴到光标位置处之前
==
===
可视或者可视块模式可以复制一部分单词
v 可视模式
V 可视行模式
ctrl+v 可视块模式
按y复制  x是删除
按p粘贴
另起一行，按o，再按esc，再p
===
===
练习：
	1.复制/etc/passwd文件到当前目录下
	2.显示一下行号
	3.复制第5到10行的内容，粘贴到末尾
	4.删除第9行和第10行
	5.将root改为gen
	6.删除部分bash字符串
	7.快速到达第3行，然后再跳到第1行，再跳到最后一行
	8.剪切第6-7行，粘贴到末尾
	9.退出并且保存
	10.复制/etc/hosts文件到当前目录下，将第1列的ip地址复制，然后粘贴到文件的末尾
====
将永中office卸载，然后安装的时候点“高级选项”，将pdf阅读器选上
==
卸载方式，点应用程序-->office--->yozo office tools--->remove
==
[root@teacher lianxi]# pwd
/lianxi
[root@teacher lianxi]# lftp 10.0.0.253
lftp 10.0.0.253:~> cd software/
lftp 10.0.0.253:/software> get Yozo_Office_6.1.0305.131ZH.tar.gz 
57414852 bytes transferred                     
lftp 10.0.0.253:/software> quit
[root@teacher lianxi]#
==
 tar xf Yozo_Office_6.1.0305.131ZH.tar.gz  解压
[root@teacher lianxi]# cd 6.1.0305.131ZH/  进入解压后的目录
[root@teacher 6.1.0305.131ZH]# ls
config.eni       instdata    setup
dispose.jar      Jre.zip     setup.png
InstallInfo.ini  Readme.txt  setup.sh
[root@teacher 6.1.0305.131ZH]#
[root@teacher 6.1.0305.131ZH]# ./setup 安装
点击高级选项--->勾选pdf阅读器---》开始安装
====
练习：
	1.第5章和第6章的课后习题
	2.阅读vim.pdf文件，深入了解vim编辑器的使用
	3.上网了解vim的经典使用方法
====

 















TAR UNZIP GZIP
tar 打包的时候不可以出现 ：  号
tar 打包的时候不可以出现 ：  号




czf   gz    
cjf    bz2    


gzip -->.gz
bzip  -->.bz2

unzip   

指定解压目录为/zhaowei
[root@teacher bak]# unzip passwd-shadow.zip -d /zhaowei
Archive:  passwd-shadow.zip
  inflating: /zhaowei/passwd         
  inflating: /zhaowei/shadow         
[root@teacher bak]# 


tar
常用命令选项
-c：创建 .tar 格式的包文件
       -c, --create
              create a new archive
-x：解开.tar格式的包文件
       -x, --extract, --get
              extract files from an archive
-v：输出详细信息
       -v, --verbose
              verbosely list files processed
-f：表示使用归档文件
       -f, --file=ARCHIVE
              use archive file or device ARCHIVE
-t：列表查看包内的文件
       -t, --list
              list the contents of an archive
-p：保持原文件的原来属性（权限）
       -p, --preserve-permissions
              extract  information  about  file per-
              missions (default for superuser)
-P：保持原文件的绝对路径
      -P, --absolute-names
              don’t strip  leading  ‘/’s  from  file
              names
-C：解包时指定的目标文件夹
-z：调用gzip程序进行压缩或解压
       -z, --gzip, --gunzip, --ungzip
              filter the archive through gzip
-j：调用bzip2程序进行压缩或解压
       -j, --bzip2
              filter the archive through bzip2

SYSTEM 2


RAID

http://wenku.baidu.com/link?url=v1d9Ed86XqO8hwmP-67aMx6A5fBnd0fmQJOXPQdskVuAvsxOwM0bwwVu5P7--355yFUNOOfttpHfF_ZXT2GaCpw-LWNECm6TOOp-_7kgHi3
====
千万不要在没有关闭RAID的情况下删除分区
正确关闭RAID的步骤
1.umount卸载RAID文件系统
2.mdadm -S停用RAID
3.清空/etc/mdadm.conf文件
4.清除/etc/fstab中RAID的挂载记录
5.清除每块磁盘上的元数据
6.删除/dev/下所对应的raid设备
====

raid 
磁盘阵列（Redundant Arrays of Inexpensive Disks，RAID），有“价格便宜具有冗余能力的磁盘阵列”之意。
其基本思想就是把多個相對便宜的硬碟組合起來，成為一個硬碟陣列組，使性能達到甚至超過一個價格昂貴、容量巨大的硬碟。
http://zh.wikipedia.org/wiki/RAID
http://baike.baidu.com/view/63423.htm?fromId=7102
====
software raid---》linux kernel---》mdadm
hardware raid---->常用---》性能好
====
raid0 -->条带卷
只需要2块以上的硬盘即可，成本低，可以提高整个磁盘的性能和吞吐量
读写速度块
===
raid1--》镜像卷
2块--》50%的空间利用率
有容错功能
===
raid5 
3块以上
(n-1)/n 利用率
有容错功能，最多可以坏一块磁盘
===
raid6 
4块以上
(n-2)/n 利用率
有容错功能，最多可以坏2块磁盘
===
raid10
4块磁盘
有容错功能，最多可以坏2块磁盘
-RAID10，RAID10什么意思？ 
所谓RAID10即高可靠性与高效磁盘结构，说白了就是带区结构外加一个镜像结构，RAID10准确的讲是RAID1+0，不是RAID10（十）。之所以采用RAID0+RAID1，是因为这两种结构各有优缺点，因此可以相互补充，达到既高效又高速还可以互为镜像的目的。大家可以结合两种结构的优点和缺点来理解这种新结构。这种新结构的价格高，可扩充性不好。主要用于容量不大，但要求速度和差错控制的数据库中
===
Currently, Linux supports  LINEAR  md  devices,  RAID0  (striping),
       RAID1  (mirroring), RAID4, RAID5, RAID6, RAID10
======
raid1--->安装系统
raid5、raid6---》数据
======
标准分区---》系统
lvm------》系统
raid----》数据
存储设备---》做raid
======





1。新建raid5卷，使用4块磁盘作raid5，1块磁盘作热备
 mdadm -C /dev/md1 -l5 -n4 -x1 /dev/sd[efghi]
2。格式化raid5设备
mkfs.ext4 /dev/md1
3.挂载使用
mkdir /music
mount /dev/md1  /music
4.自动挂载功能，修改/etc/fstab文件，添加
/dev/md1     /music     ext3   defaults  0 0

让其中的一块失效，然后看raid5是否能够继续使用
mdadm /dev/md1  -f /dev/sde
使用cat /proc/mdstat命令查看修复过程

删除有问题的磁盘，添加一个好的磁盘作热备，要求磁盘>容量一致
mdadm  /dev/md1 -r /dev/sde  -a /dev/sdk
=======
[root@localhost ~]# cat /proc/mdstat 查看raid的构建过程
Personalities : [raid6] [raid5] [raid4] 
md5 : active raid5 sde[5] sdf[4](S) sdd[2] sdc[1] sdb[0]
      3144192 blocks super 1.2 level 5, 512k chunk, algorithm 2 [4/3] [UUU_]
      [=============>.......]  recovery = 68.5% (719232/1048064) finish=0.0min speed=143846K/sec
      
unused devices: <none>
[root@localhost ~]# cat /proc/mdstat 
Personalities : [raid6] [raid5] [raid4] 
md5 : active raid5 sde[5] sdf[4](S) sdd[2] sdc[1] sdb[0]
      3144192 blocks super 1.2 level 5, 512k chunk, algorithm 2 [4/4] [UUUU]
      
unused devices: <none>
[root@localhost ~]# 
===
[root@localhost ~]# mdadm -D /dev/md5
/dev/md5:
        Version : 1.2
  Creation Time : Sun Jul 21 01:18:10 2013
     Raid Level : raid5
     Array Size : 3144192 (3.00 GiB 3.22 GB)
  Used Dev Size : 1048064 (1023.67 MiB 1073.22 MB)
   Raid Devices : 4
  Total Devices : 5
    Persistence : Superblock is persistent

    Update Time : Sun Jul 21 01:18:19 2013
          State : clean 
 Active Devices : 4
Working Devices : 5
 Failed Devices : 0
  Spare Devices : 1

         Layout : left-symmetric
     Chunk Size : 512K

           Name : localhost.localdomain:5  (local to host localhost.localdomain)
           UUID : cc4079cc:ade73c11:5639dbf4:dcefa596
         Events : 18

    Number   Major   Minor   RaidDevice State
       0       8       16        0      active sync   /dev/sdb
       1       8       32        1      active sync   /dev/sdc
       2       8       48        2      active sync   /dev/sdd
       5       8       64        3      active sync   /dev/sde

       4       8       80        -      spare   /dev/sdf
=====
[root@localhost ~]# mdadm -Ds
ARRAY /dev/md5 metadata=1.2 spares=1 name=localhost.localdomain:5 UUID=cc4079cc:ade73c11:5639dbf4:dcefa596
[root@localhost ~]# mdadm -Ds >>/etc/mdadm.conf
[root@localhost ~]#
====
[root@localhost ~]# mdadm -S /dev/md5  停止
mdadm: stopped /dev/md5
[root@localhost ~]# mdadm -Ds
[root@localhost ~]# mdadm -A /dev/md5  激活（需要有配置文件）
mdadm: /dev/md5 has been started with 4 drives and 1 spare.
[root@localhost ~]# 
==
[root@minimal-os ~]# mdadm -A /dev/md2
mdadm: /dev/md2 not identified in config file.
[root@minimal-os ~]# mdadm -A /dev/md2 /dev/sd[hijkl] 激活（没有配置文件）
mdadm: /dev/md2 has been started with 4 drives and 1 spare.
[root@minimal-os ~]# 
=======
    Number   Major   Minor   RaidDevice State
       0       8       16        0      active sync   /dev/sdb
       1       8       32        1      active sync   /dev/sdc
       4       8       80        2      active sync   /dev/sdf
       3       0        0        3      removed

       2       8       48        -      faulty spare   /dev/sdd
       5       8       64        -      faulty spare   /dev/sde
[root@localhost file]# mdadm /dev/md5 -r /dev/sd[de]
mdadm: hot removed /dev/sdd from /dev/md5
mdadm: hot removed /dev/sde from /dev/md5
[root@localhost file]# 
===
[root@localhost file]# mdadm /dev/md5 -a /dev/sd[gh]
mdadm: added /dev/sdg
mdadm: added /dev/sdh
==
[root@localhost file]# mdadm -D /dev/md5
/dev/md5:
        Version : 1.2
  Creation Time : Sun Jul 21 01:18:10 2013
     Raid Level : raid5
     Array Size : 3144192 (3.00 GiB 3.22 GB)
  Used Dev Size : 1048064 (1023.67 MiB 1073.22 MB)
   Raid Devices : 4
  Total Devices : 5
    Persistence : Superblock is persistent

    Update Time : Sun Jul 21 01:43:52 2013
          State : clean 
 Active Devices : 4
Working Devices : 5
 Failed Devices : 0
  Spare Devices : 1

         Layout : left-symmetric
     Chunk Size : 512K

           Name : localhost.localdomain:5  (local to host localhost.localdomain)
           UUID : cc4079cc:ade73c11:5639dbf4:dcefa596
         Events : 72

    Number   Major   Minor   RaidDevice State
       0       8       16        0      active sync   /dev/sdb
       1       8       32        1      active sync   /dev/sdc
       4       8       80        2      active sync   /dev/sdf
       6       8      112        3      active sync   /dev/sdh

       5       8       96        -      spare   /dev/sdg
[root@localhost file]# 
===
[root@localhost file]# mdadm /dev/md5 -f /dev/sdh
[root@localhost file]# mdadm -D /dev/md5
/dev/md5:
        Version : 1.2
  Creation Time : Sun Jul 21 01:18:10 2013
     Raid Level : raid5
     Array Size : 3144192 (3.00 GiB 3.22 GB)
  Used Dev Size : 1048064 (1023.67 MiB 1073.22 MB)
   Raid Devices : 4
  Total Devices : 5
    Persistence : Superblock is persistent

    Update Time : Sun Jul 21 01:46:33 2013
          State : clean, degraded, recovering 
 Active Devices : 3
Working Devices : 4
 Failed Devices : 1
  Spare Devices : 1

         Layout : left-symmetric
     Chunk Size : 512K

 Rebuild Status : 78% complete

           Name : localhost.localdomain:5  (local to host localhost.localdomain)
           UUID : cc4079cc:ade73c11:5639dbf4:dcefa596
         Events : 86

    Number   Major   Minor   RaidDevice State
       0       8       16        0      active sync   /dev/sdb
       1       8       32        1      active sync   /dev/sdc
       4       8       80        2      active sync   /dev/sdf
       5       8       96        3      spare rebuilding   /dev/sdg

       6       8      112        -      faulty spare   /dev/sdh

[root@localhost ~]# mdadm -E /dev/sdb 查看磁盘上的元数据
/dev/sdb:
          Magic : a92b4efc
        Version : 1.2
    Feature Map : 0x0
     Array UUID : cc4079cc:ade73c11:5639dbf4:dcefa596
           Name : localhost.localdomain:5  (local to host localhost.localdomain)
  Creation Time : Sun Jul 21 01:18:10 2013
     Raid Level : raid5
   Raid Devices : 4

 Avail Dev Size : 2096128 (1023.67 MiB 1073.22 MB)
     Array Size : 6288384 (3.00 GiB 3.22 GB)
    Data Offset : 1024 sectors
   Super Offset : 8 sectors
          State : clean
    Device UUID : 12ddb7bd:054725bd:5e953e20:12ed52f4

    Update Time : Sun Jul 21 01:51:13 2013
       Checksum : 576aec73 - correct
         Events : 121

         Layout : left-symmetric
     Chunk Size : 512K

   Device Role : Active device 0
   Array State : AA.. ('A' == active, '.' == missing)
[root@localhost ~]# 
=======
新建一个raid10，要求4块磁盘，1块做热备
[root@localhost ~]# mdadm  -C /dev/md10  -l10 -n4 -x1 /dev/sd[kjihd]
mdadm: Defaulting to version 1.2 metadata
mdadm: array /dev/md10 started.
[root@localhost ~]# mdadm -D /dev/md10
/dev/md10:
        Version : 1.2
  Creation Time : Sun Jul 21 02:06:18 2013
     Raid Level : raid10
     Array Size : 2096128 (2047.34 MiB 2146.44 MB)
  Used Dev Size : 1048064 (1023.67 MiB 1073.22 MB)
   Raid Devices : 4
  Total Devices : 5
    Persistence : Superblock is persistent

    Update Time : Sun Jul 21 02:06:29 2013
          State : clean 
 Active Devices : 4
Working Devices : 5
 Failed Devices : 0
  Spare Devices : 1

         Layout : near=2
     Chunk Size : 512K

           Name : localhost.localdomain:10  (local to host localhost.localdomain)
           UUID : 65ddb577:af1f718b:c5266cdd:89bb9cc7
         Events : 17

    Number   Major   Minor   RaidDevice State
       0       8       48        0      active sync   /dev/sdd
       1       8      112        1      active sync   /dev/sdh
       2       8      128        2      active sync   /dev/sdi
       3       8      144        3      active sync   /dev/sdj

       4       8      160        -      spare   /dev/sdk
[root@localhost ~]# 
======= 
练习：
	1.raid10和raid01的区别？
	2.在虚拟机里添加10块磁盘，创建raid1和raid5、raid6、raid10
	3.测试那些raid具有容错功能？
 raid -->raid 1 和raid 0  --->raid 5    ---> 
===
249025628--->双星IT就业群
http://www.63jiuye.com
===
服务器：
	lenovo
	dell
	华为
	IBM
	曙光
	HP
===
下面配置的服务器的价格？
配置：
	8个核
	32G
	2T
	raid功能
===
外观：塔式、机架式、刀片式
===
http://www.dell.com.cn/
===
1U=4.45cm
===


















高级课程


第一章 NGINX 与负载均衡
                            第1章 Nginx
一、什么是Nginx？
很多人对apache非常的熟悉，Nginx和Apache类似，都属于Web容器，同时也是一款高性能的
HTTP和反向代理软件，发音(engine x)

二、为什么要选择Nginx
Nginx和Apache最大的区别:
（1）Apache处理速度非常慢，而且占用很多内存资源，Nginx正好相反，
(2)在功能Apache的所有模块都是支持动静态编译，而Nginx都是静态编译
(3)Apache对FCGI的支持不好，而Nginx对FCGI支持非常的好.
(4)在处理链接上，Nginx支持epoll，而Apache却不支持
(5)从安装包看Nginx只有百K,Apache都按照M以算，非常的庞大.
           
                                                
三、Nginx的优势
（1）作为WEB服务器，Nginx处理静态文件，索引文件 自动搜索的效率非常之高

(2)作为代理服务器Nginx可以实现反向代理加速。提高网站的运行速度

(3)做负载均衡器,Nginx可以在内部直接支持Rails和PHP，可以支持HTTP代理服务器对外进行服务，同时还支持简单的容错利用算法进行负载

(4)在性能方面，Nginx专门为性能优化而开发的，支持最大并发链接数为5万.

(5)稳定方面 CPU占用资源非常低，官方表示Nginx保持1万个没有活动的链接，占用2.5M内存，官方声称在这种状态DDOS攻击是完全无效的.

(6)在高性能方面，Nginx支持热部署，启动速度特别迅速，因此可以不间断服务的情况下，对软件的版本配置或者升级，不影响现网业务，运行几个月也不需要启动，几乎可以做7*24小时不间断运行.

四、Nginx的模块工作原理
Nginx由内核与模块组成，内核的设计非常小巧和简洁，完成的工作也是非常的简单，通过配置文件
将客户端请求映射到一个location block当中，然后通过这个location中的配置每个指令调用不同模块，从而完成相应的工作.
    Nginx的模块从结构分:
    核心模块包含了:http模块，event模块，mail模块
    基础模块包含了:http Access模块 Http FastCGI模块 Http Proxy 模型和HTTP Rewrite模块.
    第三方模块:Http upstream request模块，Notice模块和Http Access key模块
    
    以上模块从功能分为3个大类:
    (1)Handerls(处理模块)此类模块直接请求，并且将输出内容和修改Haders信息操作,
    Handerls处理器模块只有一个
    (2)Filters（过滤模块) 主要针对其它的处理模块输出内容和进修修改，最后由Nginx输出.
    (3)Proxies(代理模块)，此模块Nginx的HTTP upstream之类的模块，这些模块实现了后端服务比如:FastCGI的信息交互,实现代理服务和负载均衡.
    
    
    HTTP发出请求
      |
      |
     \|/
    Nginx内核
      |
      |
 选择一个Handlers处理模块
      |
      |
    Handlers模块进行处理-----》交给Filters(过滤模块)-->响应HTTP请求
nginx 可以单个进程工作，也可以 master+ worker模式工作，所以当使用前者模式启动的时候，进程就是NGX_PROCESS_SINGLE ; 当使用后者的时候，那么父进程就是 NGX_PROCESS_MASTER,而子进程就是 NGX_PROCESS_WORKER。使用哪种模式可以在配置文件中设置，默认使用后者，如果配置文件中 masterprocess off 开启，那么就使用了前者。



#===============================================================
五、Nginx的安装与配置
(1)安装依赖库
# yum -y install gcc openssl-devel zlib-devel

安装pcre-delvel库pcre-8.01.tar.gz
# cd /soft/
# tar xf pcre-8.01.tar.gz -C tmp/
# cd tmp/pcre-8.01/
#./configure && make && make install

安装libmd5 libmd5-0.8.2b.tar.gz
# cd /soft/
#tar xf libmd5-0.8.2b.tar.gz -C tmp/

(2)安装Nginx 
# useradd user_00 -g users -s /sbin/nologin 
# cd /soft/
# tar -xvf nginx-0.8.55.tar.gz -C tmp/
# cd tmp/nginx-0.8.55/
./configure --user=user_00 --group=users --with-http_realip_module --with-http_stub_status_module --with-http_gzip_static_module --with-md5=/tmp/md5/ --with-sha1=auto/lib/sha1 --with-pcre=/tmp/pcre-8.01/ --without-select_module --without-poll_module --without-http_ssi_module --without-http_userid_module --without-http_geo_module --without-http_map_module --without-http_memcached_module --without-mail_pop3_module --without-mail_imap_module --without-mail_smtp_module --prefix=/usr/local/services/nginx-0.8.55
# make >/dev/null && make install >/dev/null
编译参数详解：
--with-http_realip_module 
此模块支持显示真实来源IP地址，主要用于NGINX做前端负载均衡服务器使用。

-with-http_stub_status_module 
这个模块可以取得一些nginx的运行状态， 

--with-http_gzip_static_module 
这个模块在一个预压缩文件传送到开启Gzip压缩的客户端之前检查是否已经存在以“.gz”结尾的压缩文件，这样可以防止文件被重复压缩。

--with-md5=/soft/md5/ 
设定md5库文件路径

--with-sha1=auto/lib/sha1 
设定sha1库文件路径
--with-pcre=/soft/pcre-8.01 
设定PCRE库路径

--without-select_module 
标准连接模式。默认情况下自动编译方式。您可以启用或禁用通过使用-select_module和不带- select_module配置参数这个模块

--without-poll_module 
不使用poll模块

--without-http_ssi_module 
不使用ngx_http_ssi_module模块，此模块处理服务器端包含文件(ssi)的处理.

--without-http_userid_module 
不使用ngx_http_userid_module模块

--without-http_geo_module 
这个模块基于客户端的IP地址创建一些ngx_http_geoip_module变量，并与MaxMindGeoIP文件进行匹配，该模块仅用于 0.7.63和0.8.6版本之后。但效果不太理想，对于城市的IP记录并不是特别准确，不过对于网站的来源访问区域的分析大致有一定参考性
。
--without-http_map_module 
不使用ngx_http_map_module模块

--without-http_memcached_module 
不使用ngx_http_memcached_module模块

--without-mail_pop3_module 
不允许ngx_mail_pop3_module模块

--without-mail_imap_module 
不允许ngx_mail_imap_module模块

--without-mail_smtp_module 
不允许ngx_mail_smtp_module模块






4.4、编辑主配置文件
配置文件位置:/usr/local/nginx/conf/nginx.conf 
1.	Nginx配置文件分为4个部分 
2.	main(全局设置）
3.	server(主机设置)
4.	upstream(负载均衡设置)
5.	localtion(URL匹配特定位置的设置)
这四个 server继承main  location继承server 
upstream即不会继承 其它设置也不会被继承.


#vim /usr/local/service/nginx/conf/nginx.conf 
#==================================一全局配置#========================
user  user_00 users;  #这个模块指令，指Nginx Worker 运用的用户和组，默认为nobody
worker_processes  3;  #指定了要开启的进程数，每进程占用10M~12M的内存，建议和CPU的核心数量一样多的进程就行了。


error_log  logs/error.log; #全局错误日志
#error_log  logs/error.log  notice; 
#error_log  logs/error.log  info;   
  
pid        logs/nginx.pid;  #:用来指定进程ID的存储位置.


#Specifies the value for maximum file descriptors that can be opened by this process.
#events 用来指定Nginx工作模式以及连接数上限
events {
    use epoll;  #使用epoll高效模式，适用于Linux,Unix使用kqueue
    worker_connections  100000; #定义Ningx没个进程最大的连接数。默认为1024，受到文件句柄的约束。
}
worker_rlimit_nofile 100000; #打开的文件句柄数量最高为10万

#==================================二、HTTP配置========================
http {
    include       mime.types;  #实现对配置文件所包含的文件设定
    default_type  application/octet-stream; #属于HTTP核心模块，默认设定为二进制流
    server_tokens off;   #禁止错误页面里显示nginx的版本号

	# 定义日志处理的格式
    #log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
    #                  '$status $body_bytes_sent "$http_referer" '
    #                  '"$http_user_agent" "$http_x_forwarded_for"';

	# 定义它的hash表为128K
    server_names_hash_bucket_size 128;
    client_header_buffer_size 32k; #客户端请求头部的缓冲区大小，一般一个请求头的大小不会超过1k
    large_client_header_buffers 4 32k; #客户请求头缓冲大小 nginx默认会用client_header_buffer_size这个buffer来读取header值
    client_max_body_size 8m; #设定通过nginx上传文件的大小

	#sendfile指令指定 nginx 是否调用sendfile 函数（zero copy 方式）来输出文件，
     #对于普通应用，必须设为on。
	 #如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络IO处理速度，降低系统uptime。
    sendfile          on;
    tcp_nopush        on; #此选项允许或禁止使用socke的TCP_CORK的选项，此选项仅在使用sendfile的时候使用
    tcp_nodelay       on;

    #keepalive_timeout  0;
    keepalive_timeout 60; #keepalive超时时间。连接保持活动时间超过这个，将被关闭掉

	#===================重要位置============
    fastcgi_connect_timeout 300; #指定连接到后端FastCGI的超时时间。
    fastcgi_send_timeout 300; #向FastCGI传送请求的超时时间，这个值是指已经完成两次握手后向FastCGI传送请求的超时时间。
    fastcgi_read_timeout 300; #接收FastCGI应答的超时时间，这个值是指已经完成两次握手后接收FastCGI应答的超时时间。
    fastcgi_buffer_size 254k; #指定读取FastCGI应答第一部分需要用多大的缓冲区
    fastcgi_buffers 16 256k; #指定本地需要用多少和多大的缓冲区来缓冲FastCGI的应答。
    fastcgi_busy_buffers_size 512k; #这个指令我也不知道是做什么用，只知道默认值是fastcgi_buffers的两倍。
    fastcgi_temp_file_write_size 512k; #在写入fastcgi_temp_path时将用多大的数据块，默认值是fastcgi_buffers的两倍。

    gzip              on; #该指令用于开启或关闭gzip模块(on/off)
    gzip_min_length   1k; #设置允许压缩的页面最小字节数，页面字节数从header头得content-length中进行获取
    gzip_buffers      4 16k; #设置系统获取几个单位的缓存用于存储gzip的压缩结果数据流
    gzip_http_version 1.0; #识别http的协议版本
    gzip_comp_level   2;   #gzip压缩比，1压缩比最小处理速度最快
	#匹配mime类型进行压缩，无论是否指定,”text/html”类型总是会被压缩的
    gzip_types        text/plain application/x-javascript text/css application/xml text/javascript;
    gzip_vary         on; #和http头有关系，加个vary头，给代理服务器用的

    charset      utf-8;  #字符集为utf-8

    access_log   off;    # 日常日志关闭
    log_not_found off;   # 日常日志关闭

        error_page  400 403 405 408  /40x.html;  # 错误返回页面
        error_page  500 502 503 504  /50x.html;  # 错误返回页面
	#===================Server虚拟机配置保持默认============
    server {
        listen       80 default;   #默认监听端口号为80
        server_name  _;
	return       444;
    }
    
 include vhost/vhost.www.fanhougame.com; 起到调用文件的作用

}   
    
    
    
    
    
# vim vhost.www.fanhougame.com;
#===================自定义虚拟机配置文件===========
主配虚拟Server配置文件如下:
    server {
        listen       80 ; #监听端口号
		#域名为
        server_name  10.0.0.201;
        # 指定网站的目录
		root         /data/www/oa.com/www.fanhougame.com ;

		# localtion模块指定网站首页名称
        location / {
            index index.php index.html index.htm;
            if (!-e $request_filename) {
                return 444;
            }
        }

		#:返回的错误信息
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   /usr/local/nginx/html;
        }

		#可以指定多个localtion进行不同的指令处理，这里是指定php的sock
        location ~ \.php$ {
            fastcgi_pass   unix:/tmp/php-cgi-5313-web.sock;
            fastcgi_index  index.php;
            include        fastcgi_params;
            fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
            fastcgi_param SERVER_NAME $http_host;
            fastcgi_ignore_client_abort on;
        }

		#指定对网页图片格式进行缓存max表示10年，也可以是30d(天)
        location ~ \.(swf|js|css|xml|gif|jpg|jpeg|png|bmp)$ {
            error_log    off;
            access_log   off;
			#expires      30d;
            expires      max;
        }
    }
    
 

4.5、启动与平滑重启
# cd /usr/local/services/nginx-0.8.55/sbin/
# ./nginx –t 检测配置文件是否有错误
# ./nginx 启动nginx
# ./nginx -s reload 平滑重启。

####################################################################################

六、	Nginx常用配置实例
6.1、负载均衡配置实例环境:
Master:10.0.0.201
Master Web 10.0.0.201:81
Slave1 Web 10.0.0.202:80
Slave2 Web 10.0.0.203:80



6.2、在201编辑主配置文件nginx.conf
# vim /usr/local/service/nginx/conf/nginx.conf

6.3、在201上面编辑虚拟主机配置文件vhost.aatest.com
# vim /usr/local/service/nginx/conf/vhost/vhost.aatest.com


6.4、在201上面编辑负载均很配置文件
# vim /usr/local/service/nginx/conf/vhost/vhost.fuzai
upstream www.aatest.com {
      server  10.0.0.201:81 weight=1 max_fails=3 fail_timeout=20s;
      server  10.0.0.202:80 weight=1 max_fails=3 fail_timeout=20s;
      server  10.0.0.203:80 weight=1 max_fails=3 fail_timeout=20s;
}

server{
    listen 80;
    server_name www.aatest.com;
    location / {
        proxy_pass         http://www.aatest.com;
        proxy_set_header   Host             $host;
        proxy_set_header   X-Real-IP        $remote_addr;
        proxy_set_header   X-Forwarded-For  $proxy_add_x_forwarded_for;
    }
}

6.5、在202和203编辑如下主配置文件

# vim /usr/local/service/nginx/conf/nginx.conf



6.5、在202和203编辑如下虚拟主机配置文件
# vim /usr/local/service/nginx/conf/www.aatestX.com
    server {
        listen       80 ; #监听端口号
        #域名为
        server_name  www.aatestX.com;
         server_name  www.aatest.com;
        # 指定网站的目录
                root         /opt/zeng ;

                # localtion模块指定网站首页名称
        location / {
            index index.php index.html index.htm;
            if (!-e $request_filename) {
                return 444;
            }
        }

                #:返回的错误信息
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   /usr/local/nginx/html;
        }

                #可以指定多个localtion进行不同的指令处理，这里是指定php的sock
        location ~ \.php$ {
            fastcgi_pass   unix:/tmp/php-cgi-5313-web.sock;
            fastcgi_index  index.php;
            include        fastcgi_params;
            fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
            fastcgi_param SERVER_NAME $http_host;
            fastcgi_ignore_client_abort on;
        }

                #指定对网页图片格式进行缓存max表示10年，也可以是30d(天)
        location ~ \.(swf|js|css|xml|gif|jpg|jpeg|png|bmp)$ {
            error_log    off;
            access_log   off;
                        #expires      30d;
            expires      max;
        }
    }


                      
总结如下：
单机WEB配置
1、安装库
2、安装Nginx
3、编辑Nginx.conf主文件(注意编辑完虚拟配置文件之后。要主文件相关连(include file>
4、编辑虚拟机的配置文件
5、启动服务
6、建立网站对应的目录，编写一些静态的html页面.echo "test" >index.html
                     

负载均衡的配置
环境:
10.0.0.201 负载均衡服务器:对外80
10.0.0.201 虚拟主机(WEB)81

10.0.32.111 端口号:80
10.0.0.131 端口号：80


步骤一、在201 32.111 131服务器上面都编辑Nginx.conf


步骤二、在201 111 131 编辑一个虚拟机配置文件


步骤三、在201上面编辑负载均衡的配置文件

步骤四、启动服务


访问的主机上 
vim /etc/hosts



/etc/resolv.conf

练习题目如下：
企业需要建立3个网站
www.gongda1.com 
www.gongda2.com
www.gongda3.com
要求安装Nginx，开3个虚拟主机
要求在浏览器里面输入：
http://www.gongda1.com 
返回内容为:this gongda1

http://www.gongda2.com 
返回内容为:this gongda2

http://www.gongda3.com 
返回内容为:this gongda3
 www.gongda.com 
 F5   
 1 gongda1
 2  gongda2
 3  gongda3

要求负载均衡。
http://www.gongda1.com server1 在负载均衡服务器上。

http://www.gongda2.com servee2 单独的

http://www.gongda3.com server3 单独的

                   
                      
                      
                      
                         
                         
                            


解析NGINX 负载均衡
解析nginx复杂均衡
http://baidutech.blog.51cto.com/4114344/1033718/

 


首先介绍下关键的测试指标：
均衡性：是否能够将请求均匀的发送给后端
一致性：同一个key的请求，是否能落到同一台机器
容灾性：当部分后端机器挂掉时，是否能够正常工作
以上述指标为指导，我们针对如下四个测试场景分别用easyABC和polygraph进行测试：
场景1      server_*均正常提供服务；
场景2      server_4挂掉，其他正常；
场景3      server_3、server_4挂掉，其他正常；
场景4      server_*均恢复正常服务。
上述四个场景将按照时间顺序进行，每个场景将建立在上一个场景基础上，被测试对象无需做任何操作，以最大程度模拟实际情况。另外，考虑到测试工具自 身的特点，在easyabc上的测试压力在17000左右，polygraph上的测试压力在4000左右。以上测试均保证被测试对象可以正常工作，且无 任何notice级别以上（alert/error/warn）的日志出现，在每个场景中记录下server_*的qps用于最后的策略分析。

 
 【精】Nginx 反向代理、负载均衡、页面缓存、URL重写及读写分离详解
http://freeloda.blog.51cto.com/2033581/1288553

正反向代理 的概念和区别
5.简单说一下，正向代理与反向代理

(1).正向代理的概念        
 正向代理，也就是传说中的代理,他的工作原理就像一个跳板，简单的说，我是一个用户，我访问不了某网站，但是我能访问一个代理服务器，这个代理服务器 呢，他能访问那个我不能访问的网站，于是我先连上代理服务器，告诉他我需要那个无法访问网站的内容，代理服务器去取回来，然后返回给我。从网站的角度，只 在代理服务器来取内容的时候有一次记录，有时候并不知道是用户的请求，也隐藏了用户的资料，这取决于代理告不告诉网站。        结论就是，正向代理 是一个位于客户端和原始服务器(origin  server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内 容返回给客户端。客户端必须要进行一些特别的设置才能使用正向代理。
 
 
(2).反向代理的概念
继续举例:    
        例用户访问 http://www.test.com/readme，但www.test.com上并不存在readme页面，他是偷偷从另外一台服务器上取回来，然后作为自己的内容返回用户，但用户并不知情。这里所提到的 www.test.com 这个域名对应的服务器就设置了反向代理功能。
         结论就是，反向代理正好相反，对于客户端而言它就像是原始服务器，并且客户端不需要进行任何特别的设置。客户端向反向代理的命名空间(name- space)中的内容发送普通请求，接着反向代理将判断向何处(原始服务器)转交请求，并将获得的内容返回给客户端，就像这些内容原本就是它自己的一样。
(

3).两者区别从用途上来讲：
         正向代理的典型用途是为在防火墙内的局域网客户端提供访问Internet的途径。正向代理还可以使用缓冲特性减少网络使用率。反向代理的典型用途是将 防火墙后面的服务器提供给Internet用户访问。反向代理还可以为后端的多台服务器提供负载平衡，或为后端较慢的服务器提供缓冲服务。另外，反向代理 还可以启用高级URL策略和管理技术，从而使处于不同web服务器系统的web页面同时存在于同一个URL空间下。
从安全性来讲：
       正向代理允许客户端通过它访问任意网站并且隐藏客户端自身，因此你必须采取安全措施以确保仅为经过授权的客户端提供服务。反向代理对外都是透明的，访问者并不知道自己访问的是一个代理。


第二章 FASTCGI PHP
一、什么是FastCGI
FastCGI是一个可伸缩、高速的，在HTTP server和动态脚本语言之间的一个通信接口.大多数的HTTP server都支持FastCGI，比如：Nginx Aapache lighttpd等..FastCGI被很多语言所支持。其中就有PHP.


二、Nginx+FastCGI运行原理
(1)Nginx不支持对外程序的直接调用或者解析，所有的外部程序(包括PHP)都必须通过FastCGI来调用
(2)FastCGI接口在Linux下面可以(socket文件的方式存在，也可以IP形式存在)，
(3)为了调用CGI程序，还需要一个FastCGI的wrapper，当Nginx发送CGI的请求给这个socket的时候。通过FastCGI接口wrapper接受到的请求，然后派生出一个新的线程，这个线程调用外部程序或者脚本读却返回数据.
   最后wrapper在将返回的数据通过FastCGI接口，沿着固定的socket传递给Nginx，最后返回给数据发送的客户端.
   
   
Ningx发送CGI请求-->socket文件-->FastCGI_wrapper接受到请求-->派生出一个新的线程-->调用外部程序或者脚本进行处理
--->处理后数据wrapper将这个数据通过固定Socket传送给Ningx-->最后Nginx把数据返回给客户端
    
 三、PHP与PHP-FPM的安装与优化
   PHP-FPM也是第三方的FastCGI的进程管理，它作为PHP补丁一起开发，编写的时候跟着一起编译到PHP内核当中，PHP-FPM在处理高并发的方面非常的优秀.它的一个优点呢：就是把动态语言和HTTP server分离开来(动静分离)，Http server主要处理静态请求，PHP-FPM处理动态请求。
   所有呢 PHP/PHP-FPM 和Nginx经常组合到一块安装到一台机器上，以满足业务需求.
   
   
   apache 和apache 区别  优缺点
     
   什么是长链接和短链接   
   
   apache 怎样出动态和静态请求

安装～～～

四、首先安装Mysql
(1)首先安装Mysql数据库，PHP在编译的时候需要mysql的一个配置
这样PHP远程链接Mysql才有用
# cd /data/soft/
# tar xf mysql-5.1.49.tar.gz -C tmp/
# cd tmp/mysql-5.1.49/
#CONFOPTS=" \
--with-charset=utf8 \
--with-plugins=partition,federated,innobase,myisam \
--enable-static \
--enable-assembler \
--enable-thread-safe-client \
--with-client-ldflags=-all-static-ltinfo \
--with-mysqld-ldflags=-all-static-ltinfo \
--with-big-tables \
--with-mysqld-user=mysql \
--without-debug \
--without-ndb-debug \
--localstatedir=/usr/local/services/mysql-5.1.49/var \
--prefix=/usr/local/services/mysql-5.1.49 \
"
#./configure $CONFOPTS >/dev/null
# make >/dev/null && make install >/dev/null

 
五、安装PHP的依赖库
①libxml2-2.7.7.tar.gz
# cd /data/soft/
#tar xf libxml2-2.7.7.tar.gz –C tmp/
# cd tmp/libxml2-2.7.7/
#./configure --prefix=/usr/local/services >/dev/null
#make >/dev/null && make install >/dev/null



②curl-7.21.4.tar.gz
# cd /data/soft/
# tar xf curl-7.21.4.tar.gz -C tmp/
# cd tmp/curl-7.21.4/
#./configure --prefix=/usr/local/services >/dev/null
#make >/dev/null && make install >/dev/null



③jpegsrc.v8b.tar.gz
# cd /data/soft/
#tar xf jpegsrc.v8b.tar.gz –C tmp/
#cd tmp/jpeg-8b/
#./configure --prefix=/usr/local/services >/dev/null
#make >/dev/null && make install >/dev/null



④libpng-1.4.3.tar.gz
# cd /data/soft/
# tar xf libpng-1.4.3.tar.gz -C tmp/
# cd tmp/libpng-1.4.3/
#./configure --prefix=/usr/local/services >/dev/null
#make >/dev/null && make install >/dev/null



⑤freetype-2.4.1.tar.gz
# cd /data/soft/
# tar xf freetype-2.4.1.tar.gz -C tmp/
# cd tmp/freetype-2.4.1/
#./configure --prefix=/usr/local/services >/dev/null
#make >/dev/null && make install >/dev/null





⑥libevent-2.0.10-stable.tar.gz
# cd /data/soft/
# tar xf libevent-2.0.10-stable.tar.gz –C tmp/
# cd tmp/libevent-2.0.10-stable/
#./configure --prefix=/usr/local/services --disable-debug-mode >/dev/null
#make >/dev/null && make install >/dev/null




⑦re2c-0.13.5.tar.gz
# cd /data/soft/
# tar xf re2c-0.13.5.tar.gz -C tmp/
# cd tmp/re2c-0.13.5/
#./configure --prefix=/usr/local/services >/dev/null
#make >/dev/null && make install >/dev/null



⑧libmcrypt-2.5.8.tar.gz
# cd /data/soft/
# tar xf libmcrypt-2.5.8.tar.bz2 -C tmp/
# cd tmp/libmcrypt-2.5.8/
#./configure --prefix=/usr/local/services >/dev/null
#make >/dev/null && make install >/dev/null
# cd libltdl/
# ./configure --prefix=/usr/local/services --enable-ltdl-install >/dev/null
#make >/dev/null && make install >/dev/null



六、安装PHP
wget http://php.net/distributions/php-5.3.13.tar.gz
php-5.3.13.tar.gz
# cd /data/soft/
# tar xf php-5.3.13.tar.gz -C tmp/
#cd tmp/php-5.3.13/
#CONFOPTS="
--enable-zend-multibyte \
--enable-mbstring \
--enable-sockets \
--enable-pdo \
--enable-zip \
--enable-fpm \
--with-gd \
--with-fpm-user=user_00 \
--with-fpm-group=user_00 \
--with-zlib \
--with-config-file-path=/usr/local/services/php-5.3.13/etc \
--with-libxml-dir=/usr/local/services \
--with-curl=/usr/local/services \
--with-png-dir=/usr/local/services \
--with-jpeg-dir=/usr/local/services \
--with-freetype-dir=/usr/local/services \
--with-mysql=/usr/local/services/mysql-5.1.49/ \
--with-pdo-mysql=/usr/local/services/mysql-5.1.49/ \
--with-mysqli=//usr/local/services/mysql-5.1.49/bin/mysql_config \
--prefix=/usr/local/services/php-5.3.13 \
"
# ./configure $CONFOPTS
# make >/dev/null && make install >/dev/null
编译错误解决：
/var/lib/mysql/mysql.sock
configure: error: Cannot find libmysqlclient under /usr.
Note that the MySQL client library is not bundled anymore!
解决方法：
cp -rp /usr/lib64/mysql/libmysqlclient.so.16.0.0 /usr/lib/libmysqlclient.so





七、安装PHP的扩展模块
①eaccelerator-0.9.6.1.tar.bz2
# cd /data/soft/
#tar xf eaccelerator-0.9.6.1.tar.bz2 -C tmp/
#cd tmp/eaccelerator-0.9.6.1/
#/usr/local/services/php-5.3.13/bin/phpize 
#./configure --prefix=/usr/local/services/eaccelerator-0.9.6.1 --enable-eaccelerator --with-php-config=/usr/local/services/php-5.3.13/bin/php-config > /dev/null
#make >/dev/null && make install >/dev/null
#mkdir /tmp/eaccelerator
#chmod 777 /tmp/eaccelerator

②memcached-1.4.13.tar.gz
(服务器端要前安装，下面的编译扩展模块要用到)
# cd /data/soft/
#tar xf memcached-1.4.13.tar.gz -C tmp/
# cd tmp/memcached-1.4.13/
#./configure --enable-64bit --with-libevent=/usr/local/services --prefix=/usr/local/services/memcached-1.4.13 >/dev/null
# make >/dev/null && make install >/dev/null

③libmemcached-0.48.tar.gz
# cd /data/soft/
#tar xf libmemcached-0.48.tar.gz -C tmp/
#cd tmp/libmemcached-0.48/
#CONFOPTS="
--disable-libinnodb 
--without-libinnodb-prefix 
--with-libevent-prefix=/usr/local/services 
--with-memcached=/usr/local/services/memcached-1.4.13/bin/memcached 
--prefix=/usr/local/services 
"
#./configure $CONFOPTS >/dev/null
#make >/dev/null && make install >/dev/null

④igbinary-1.0.2.tgz
# cd /data/soft/
# tar xf igbinary-1.0.2.tar.gz -C tmp/
#cd tmp/igbinary-1.0.2/
#/usr/local/services/php-5.3.13/bin/phpize
#./configure --enable-igbinary --with-php-config=/usr/local/services/php-5.3.13/bin/php-config >/dev/null
#make >/dev/null && make install >/dev/null

⑤memcache-3.0.5.tgz 
# cd /data/soft/
# tar xf memcache-3.0.5.tgz -C tmp/
#cd tmp/memcache-3.0.5/
#/usr/local/services/php-5.3.13/bin/phpize
#CONFOPTS=" \
--enable-memcache \
--with-php-config=/usr/local/services/php-5.3.13/bin/php-config \
"
#./configure $CONFOPTS >/dev/null
#make >/dev/null && make install >/dev/null

⑥memcached-1.0.2.tgz(注意安装的顺序，igbinary-1.1.1.tgz是依赖库)
# cd /data/soft/
# tar xf memcached-1.0.2.tgz -C tmp/
# cd  tmp/memcached-1.0.2/
#/usr/local/services/php-5.3.13/bin/phpize
#CONFOPTS=" \
--enable-memcached \
--enable-memcached-igbinary \
--enable-memcached-json \
--with-libmemcached-dir=/usr/local/services \
--with-php-config=/usr/local/services/php-5.3.13/bin/php-config \
--prefix=/usr/local/services \
"
#./configure $CONFOPTS >/dev/null
#make >/dev/null && make install >/dev/null

⑦owlient-phpredis-2.1.1-1-g90ecd17.tar.gz
# cd /data/soft/
#tar xf owlient-phpredis-2.1.1-1-g90ecd17.tar.gz -C tmp/
# cd tmp/owlient-phpredis-90ecd17/
#/usr/local/services/php-5.3.13/bin/phpize 
#./configure --with-php-config=/usr/local/services/php-5.3.13/bin/php-config >/dev/null
#make >/dev/null && make install >/dev/null



配置
九、拷贝配置文件：
# cd /usr/local/services/php-5.3.13/etc
# cp php-fpm.conf.default php-fpm.conf
# cp /soft/php/php-5.3.13/php.ini-production php.ini

7.8、PHP配置文件优化与调整
1.在php-fpm.conf 里面调整.
;listen = 127.0.0.1:9000
listen = /tmp/php-cgi.tuge.sock   #以socke的方式访问.注视掉.ip端口的方式.




; Default Value: log/php-fpm.log
error_log = /data/php_log/tuge.php.error  #根据不同的项目名.定义不同的.sock 和日志.

# 调整进程数量
pm.max_children：静态方式下开启的php-fpm进程数量。
pm.start_servers：动态方式下的起始php-fpm进程数量。
pm.min_spare_servers：动态方式下的最小php-fpm进程数量。
pm.max_spare_servers：动态方式下的最大php-fpm进程数量。


2.在php.ini 加入扩展模块.
在尾部添加:
[eaccelerator]
zend_extension="/usr/local/services/php-5.3.13/lib/php/extensions/eaccelerator.so"
eaccelerator.shm_size="16"
eaccelerator.cache_dir="/tmp/eaccelerator"
eaccelerator.enable="1"
eaccelerator.optimizer="1"
eaccelerator.check_mtime="1"
eaccelerator.debug="0"
eaccelerator.filter=""
eaccelerator.shm_max="0"
eaccelerator.shm_ttl="0"
eaccelerator.shm_prune_period="0"
eaccelerator.shm_only="0"
eaccelerator.compress="1"
eaccelerator.compress_level="9"

扩展模块增加
extension_dir = "/usr/local/services/php-5.3.13/lib/php/extensions"
extension = memcached.so
extension = redis.so
extension = memcache.so
extension = igbinary.so


3、移动扩展模块位置
# cd  /usr/local/services/php-5.3.13/lib/php/extensions/no-debug-non-zts-20090626/
# mv /usr/local/services/php-5.3.13/lib/php/extensions/no-debug-non-zts-20090626/*  /usr/local/services/php-5.3.13/lib/php/extensions

十步：启动PHP-FPM
关闭防火墙

修改Nginx的虚拟主机的sock位置
fastcgi_pass   unix:/tmp/php-cgi.tuge.sock;


启动PHP
# cd /usr/local/services/php-5.3.13/sbin
# ./php-fpm



1、什么是Nginx，为什么要选择它，优势在哪里？
2、Nginx+PHP为什么要选择这种组合？优势在哪里？
3、Nginx+PHP如何处理动态和静态请求。                          
                          
                         


第四章 MEMCACHED
第4章 Memcached




一、什么是Memcached 
(1)Memcached概述
 Memcached是一个免费的开源的、高性能的、具有又分布式内存对象的缓存系统，它通过减轻数据库负载加速动态WEB应用，
 
 4.1.1、Memcached和数据库交互流程
(1)、检查客户端请求的数据是在Memcached中存在，如果存在，直接把请求的数据返回，不再对数据进行任何操作。
(2)、如果请求的数据不再Memcache中，就去查询数据库，把从数据库中获取的数据返回给客户端，同时把数据缓存一份到Memcahe中
(3)、每次更新数据库(如果更新、删除数据库的数据)的同时更新Memcache中的数据，保证Memcache中的数据数据库中的数据一致。
(4)、当分配的Memcache内存空间用完之后，会使用LRU(Least Recetnly Used 最近最少使用
)策略加到期失效策略，失效的数据首先被替换掉，然后再替换掉最近使用的数据.

4.2.1、Memached特征如下:
  Memcached作为高性能的缓存服务器，具有如下特征:
  (1)、协议简单
   Memcahed的协议实现比较简单，使用的是基于文本的协议，能直接通过telnet在服务器上存取数据.

  (2)、基于libevent的时间处理
Libevent使一套利用C开发的程序库，它将BSD系统kqueue Linux系统的epoll等事件处理功能封装成一个接口，确保即使服务端的链接数增加也能发挥很好的性能.Memcached利用这个库进行异步事件处理。

ibevent是一个事件触发的网络库，适用于windows、linux、bsd等多种平台，内部使用select、epoll、kqueue等系统调用管理事件机制。著名分布式缓存软件memcached也是libevent based，而且libevent在使用上可以做到跨平台，而且根据libevent官方网站上公布的数据统计，似乎也有着非凡的性能。

libevent包括事件管理、缓存管理、DNS、HTTP、缓存事件几大部分。事件管理包括各种IO（socket）、定时器、信号等事件；缓存管理是指evbuffer功能；DNS是libevent提供的一个异步DNS查询功能；HTTP是libevent的一个轻量级http实现，包括服务器和客户端。libevent也支持ssl，这对于有安全需求的网络程序非常的重要，但是其支持不是很完善，比如http server的实现就不支持ssl。

 (3)、内置的内存管理方式
   当内存但终得数据空间沾满时，使用LRU算法自动删除不使用的缓存，即重用过期数据的内存空间，Memcahed的为缓存系统设计的.没有考虑数据的容灾问题，和机器的内存一样，重启机器数据将会丢失

  (4)、互不通信的Memcached之间有分布特征。
各个Memcahed服务器之间相互不通信，都是独立的存取数据，不共享任何信息，通过对客户端的设计，让Memcahed具有分布式，能支持海量缓存的大规模一个应用.

配置与安装
4.2、Memcahed的安装
4.2.1、安装libevnet
Memcache用到了libevent这个库用于Socket的处理，所以还需要安装libevent。（如果你的系统已经安装了libevent，可以不用安装
#wget http://cloud.github.com/downloads/libevent/libevent/libevent-2.0.21-stable.tar.gz
# ls /usr/lib | grep libevent
# mkdir /opt/tmp && cd /opt/tmp
# mv /libevent-2.0.21-stable.tar.gz /opt/tmp
# tar -xvf libevent-2.0.21-stable.tar.gz
# cd libevent-2.0.21-stable
# ./configure --prefix=/usr && make && make install



4.2.2、安装memcached
# wget http://www.danga.com/memcached/dist/memcached-1.4.0.tar.gz
# tar -xvf memcached-1.4.0.tar.gz && cd memcached-1.4.0
# ./configure --with-libevent=/usr && make && make install
# ls -al /usr/local/bin/memcached 检测是否安装成功





4.2.2、启动memcached memcahed 默认端口11211
/usr/local/bin/memcached -d -m 10 -u root -l 127.0.0.1 -p 12000 -c 512 -P /tmp/memcached.pid
-d选项是启动一个守护进程，
-m是分配给Memcache使用的内存数量，单位是MB，我这里是10MB，正常来说都分1024或者根据业务来分
-u是运行Memcache的用户，我这里是root，
-l是监听的服务器IP地址，如果有多个地址的话，我这里指定了服务器的IP地址192.168.0.200，
-p是设置Memcache监听的端口，我这里设置了12000，最好是1024以上的端口，
-c选项是最大运行的并发连接数，默认是1024，我这里设置了256，按照你服务器的负载量来设定，
-P是设置保存Memcache的pid文件，我这里是保存在 /tmp/memcached.pid





4.3、Memcahed测试
4.3.1、常见出错
这说明没有找到文件：libevent-1.2.so.1解决办法如下：
/usr/local/bin/memcached: error while loading shared libraries: libevent-2.0.so.5: cannot open shared object file: No such file or directory
# ln -s /usr/lib/libevent-2.0.so.5 /usr/lib64/libevent-2.0.so.5

4.3.2、基本测试
# telete 127.0.0.1 12000
# telnet 127.0.0.1 12000
set test 0 0 6  向test当中存储数据
123456     输入的key为test存入数据
STORED       返回set结果
get test        获取数据
VALUE test 0 6
123   取得key为test中的数据
incr test 1   数据 增加1
124
decr test 2  数据减少2  
122
quit

4.3.5、参数说明
>stats
pid               Process id of this server process （memcache服务器的进程ID）
uptime            Number of seconds this server has been running （服务器已经运行的秒数）
time              Current UNIX time according to the server （服务器当前的UNIX时间）
version           Version string of this server （memcache版本）
pointer_size      Current system pointer 当前操作系统的指针大小（32位系统一般是32bit）
rusage_user       Accumulated user time for this process （该进程累计的用户时间(秒:微妙)）
rusage_system     Accumulated system time for this process （该进程累计的系统时间(秒:微妙)）
curr_items        Current number of items stored by the server （服务器当前存储的内容数量）
total_items       Total number of items stored by this server ever since it started （服务器启动以来存储过的内容总数）
bytes             Current number of bytes used by this server to store items （服务器当前存储内容所占用的字节数）
curr_connections  Number of open connections （当前打开着的连接数量）
total_connections Total number of connections opened since the server started running （服务器运行以来接受的连接总数）
connection_structures Number of connection structures allocated by the server （服务器分配的连接结构的数量）
cmd_get             Cumulative number of retrieval requests （get命令（获取）总请求次数）
cmd_set             Cumulative number of storage requests （set命令（保存）总请求次数）
get_hits            Number of keys that have been requested and found present （请求成功的总次数）
get_misses          Number of items that have been requested and not found （请求失败的总次数）
threads             Current number of thread （当前线程数）
bytes_read          Total number of bytes read by this server from network （服务器从网络读取到的总字节数）
bytes_written       Total number of bytes sent by this server to network （服务器向网络发送的总字节数）
limit_maxbytes      Number of bytes this server is allowed to use for storage. （服务器在存储时被允许使用的字节总数）
evictions           Number of valid items removed from cache to free memory for new items （为获取空闲内存而删除的items数（分配给memcache的空间用满后需要删除旧的items来得到空间分配给新的items））
其中，最关注最多的几个参数：
uptime：是memcached运行的秒数。
cmd_get：是查询缓存的次数。
cmd_get/uptime 结果是平均每秒请求缓存的次数——结果值越大，说明Memcached的利用率越高，站点的访问量大，如果太低，用文件系统缓存就可以了，根本不会体现出使用memcached的强大性能。
cmd_set：是设置key=>value的次数。整个memcached是个大hash，用cmd_get没有找到的内容，就会调用一下cmd_set写进缓存里。
get_hits：是缓存命中的次数。所谓的命中率 = get_hits/cmd_get * 100%。
get_misses：是缓存未命中的次数。get_misses加上get_hits就等于cmd_get。
stats：显示服务器信息、统计数据等
stats reset：清空统计数据
stats slabs：显示各个slab的信息，包括chunk的大小、数目、使用情况等
stats items：显示各个slab中item的数目和存储时长(最后一次访问距离现在的秒数)
quit：退出


4.3.4、重启
# kill `cat /tmp/memcached.pid`


第六章 NGINX + TOMCAT 负载均衡
                              第6章 Nginx+Tomcat(实现负载均衡，实现动静分离)
                              
                              
一、Tomcathttp://os.51cto.com/art/201408/447781.htm
1.1、Tomcat的概述
Tomcat是Apache 软件基金会(Apache Software Fundation)的Jakarta项目中的一个核心项目，由Apache、Sun和其他一些公司以及个人共同开发，由于由Sun的参与支持，最新的Servlet和JSP规范总是能在Tomcat中得到体现，Tomcat5支持最新的Servelet 2.4和JSP2.0规范，因为Tomcat技术先进、性能稳定，而且最大的优点：免费，所有深受JAVA爱好者的喜爱并得到了部分软件开发商的认可，成为目前比较流行的WEB应用服务器(俗称:WEB容器)，目前的最新本版是8.0

常用的WEB容器：
IIS
Apache
Nginx
lighthttp
Tomcat
Jetty


1.2、业务概述
(1）、如果你们公司规模比较小，WEB层的server低于15台，而且你们公司WEB程序用java开发的所谓的jsp，
这个时候，直接用Nginx最负载均衡(反向代理)，这里的Nginx和Tomcat是分开的
比如说：
Nginx server1:10.0.0.201 动静分离在这个机器实现。
Tomcat WEB1:10.0.0.202
Tomcat WEB1:10.0.0.203
Tomcat WEB1:10.0.0.204
Tomcat WEB1:10.0.0.205

(2)、如果你们公司的规模比较大，WEB层的Server大于15台以上，你们公司用的JAVA（jsp）的WEB程序，这个时候
用lvs做负载均衡，然后+Nginx+Tomcat实现动静分离，这里的Nginx和Tomcat是结合在一起，每台WEB server都需要安装一个Nginx和Tomcat。
Lvs server 10.0.0.201 
Ningx+Tomcat WEB1:10.0.0.202
Ningx+Tomcat WEB1:10.0.0.203
Ningx+Tomcat WEB1:10.0.0.204
Ningx+Tomcat WEB1:10.0.0.205


1.3、安装jdk
http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html
# tar -xvf jdk-8u5-linux-x64.tar.gz
# mv jdk1.8.0_05/ /usr/local/java
# vim /etc/profile
JAVA_HOME=/usr/local/java

JRE_HOME=/usr/local/java/jre

PATH=$JAVA_HOME/bin:$PATH:$JRE_HOME/bin

CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib

export JAVA_HOME JRE_HOME PATH CLASSPATH

# source /etc/profile
# java -version


1.4、安装tomcat
http://apache.fayea.com/apache-mirror/tomcat/tomcat-7/v7.0.54/bin/apache-tomcat-7.0.54.tar.gz
# tar -xvf apache-tomcat-7.0.54.tar.gz
# mv apache-tomcat-7.0.54 /usr/local/tomcat


1.5、配置Tomcat
# vim /usr/local/tomcat/conf/server.xml
    <Connector port="8080" protocol="HTTP/1.1"  索搜此项修改默认WEB端口
               connectionTimeout="20000"
               redirectPort="8443" />
<Host name="localhost"  appBase="zeng"  可以修改域名或者IP，但作代理请保持localhost
            unpackWARs="true" autoDeploy="true">
          <Context path="" docBase="/opt/zeng"></Context> 新增此项 修改WEB的家目录


1.6、启动tomcat
[root@slave bin]# ./startup.sh start
Using CATALINA_BASE:   /usr/local/tomcat
Using CATALINA_HOME:   /usr/local/tomcat
Using CATALINA_TMPDIR: /usr/local/tomcat/temp
Using JRE_HOME:        /usr/local/java/jre
Using CLASSPATH:       /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jar
Tomcat started.

关闭Tomcat:
[root@slave bin]#./shutdown.sh



二、Nginx配置
(1)、编辑Nginx.conf
在配置文件的尾部增加:
include vhost.www.daili.com;


(2)、编辑虚拟配置文件
#vim /usr/local/services/nginx-0.8.55/conf/vhost.www.daili.com
upstream webcount {
      server  10.0.0.202:8080 weight=1 max_fails=3 fail_timeout=20s;
}
server {
        listen       80;
        server_name  www.aatest.com;
        charset utf-8;
            location ~ (\.jsp)|(\.do)$ {
            index  index.html index.htm index.jsp index.do;
            proxy_pass        http://webcount;
            proxy_set_header  X-Real-IP  $remote_addr;
            client_max_body_size  100m;
            }
            
         location ~ .*\.(gif|jpg|jpeg|png|bmp|swf|html|htm)$
    {
        root   /opt/alvin;  #本地的静态网页文件或者图片可以存放在此目录下
    expires      30d;
    }
}




为了使Tomcat能够运行CGI，必须做的几件事：1. 把servlets-cgi.renametojar （在CATALINA_HOME/server/lib/目录下）改名为servlets-cgi.jar。处理CGI的servlet应该位于Tomcat的CLASSPATH下。2. 在Tomcat的CATALINA_BASE/conf/web.xml 文件中，把关于<servlet-name> CGI的那段的注释去掉（默认情况下，该段位于第241行）。3. 同样，在Tomcat的CATALINA_BASE/conf/web.xml文件中，把关于对CGI进行映射的那段的注释去掉（默认情况下，该段位于第299行）。注意，这段内容指定了HTML链接到CGI脚本的访问方式。4. 可以把CGI脚本放置在WEB-INF/cgi 目录下（注意，WEB-INF是一个安全的地方，你可以把一些不想被用户看见或基于安全考虑不想暴露的文件放在此处），或者也可以把CGI脚本放置在 context下的其他目录下，并为CGI Servlet调整cgiPathPrefix初始化参数。这就指定的CGI Servlet的实际位置，且不能与上一步指定的URL重名。5. 重新启动Tomcat，你的CGI就可以运行了



















第五章 REDIS
                             第5章 Redis
              
一、Redis概述
1.1、什么是Redis
Redis是一种高级key-value数据库。它跟memcached类似，不过数据可以持久化，而且支持的数据类型很丰富。有字符串，链表，集 合和有序集合。支持在服务器端计算集合的并，交和补集(difference)等，还支持多种排序功能。所以Redis也可以被看成是一个数据结构服务 器。
Redis的所有数据都是保存在内存中，然后不定期的通过异步方式保存到磁盘上(这称为“半持久化模式”)；也可以把每一次数据变化都写入到一个append only file(aof)里面(这称为“全持久化模式”)。
1.2、Redis数据持久化(俗称“数据落地”)

第一种方法filesnapshotting：默认redis是会以快照的形式将数据持久化到磁盘的（一个二进制文 件，dump.rdb，这个文件名字可以指定），在配置文件中的格式是：save N M表示在N秒之内，redis至少发生M次修改则redis抓快照到磁盘。当然我们也可以手动执行save或者bgsave（异步）做快照。

工作原理简单介绍一下：当redis需要做持久化时，redis会fork（派生）一个子进程；子进程将数据写到磁盘上一个临时RDB文件中；当子进程完成写临时文件后，将原来的RDB替换掉，这样的好处就是可以copy-on-write

还有一种持久化方法是Append-only：filesnapshotting方法在redis异常死掉时， 最近的数据会丢失（丢失数据的多少视你save策略的配置），所以这是它最大的缺点，当业务量很大时，丢失的数据是很多的。Append-only方法可 以做到全部数据不丢失，但redis的性能就要差些。AOF就可以做到全程持久化，只需要在配置文件中开启（默认是no），appendonly yes开启AOF之后，redis每执行一个修改数据的命令，都会把它添加到aof文件中，当redis重启时，将会读取AOF文件进行“重放”以恢复到 redis关闭前的最后时刻.

LOG Rewriting随着修改数据的执行AOF文件会越来越大，其中很多内容记录某一个key的变化情况。因此redis有了一种比较有意思的特性：在后台重建AOF文件，而不会影响client端操作。在任何时候执行BGREWRITEAOF命令，都会把当前内存中最短序列的命令写到磁盘，这些命令可以完全构建当前的数据情况，而不会存在多余的变化情况（比如状态变化，计数器变化等），缩小的AOF文件的大小。所以当使用AOF时，redis推荐同时使用BGREWRITEAOF.






二、Redis安装
2.1、redis安装
# cd /data/soft/
# tar xf redis-2.4.15.tar.gz -C tmp/
# cd tmp/redis-2.4.15/
#make PREFIX=/usr/local/services/redis-2.4.15 >/dev/null
#make PREFIX=/usr/local/services/redis-2.4.15  install >/dev/null

会在当前目录下生成本个可执行文件，分别是redis-server、redis-cli、redis-benchmark、redis-stat，它们的作用如下：
•	redis-server：Redis服务器的daemon启动程序
•	redis-cli：Redis命令行操作工具。当然，你也可以用telnet根据其纯文本协议来操作
•	redis-benchmark：Redis性能测试工具，测试Redis在你的系统及你的配置下的读写性能
•	redis-stat：Redis状态检测工具，可以检测Redis当前状态参数及延迟状况 

2.2、调整overcommit_memory参数
如果内存情况比较紧张的话，需要设定内核参数overcommit_memory，指定内核针对内存分配的策略，其值可以是0、1、2。
0，表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存申请失败，并把错误返回给应用进程。
1，表示内核允许分配所有的物理内存，而不管当前的内存状态如何。
2，表示内核允许分配超过所有物理内存和交换空间总和的内存
Redis在dump数据的时候，会fork出一个子进程，理论上child进程所占用的内存和parent是一样的，比如parent占用的内存为 8G，这个时候也要同样分配8G的内存给child, 如果内存无法负担，往往会造成redis服务器的down机或者IO负载过高，效率下降。所以这里比较优化的内存分配策略应该设置为 0
设置方式有两种，需确定当前用户的权限活使用root用户修改： 


1：重设文件 # echo 1 > /proc/sys/vm/overcommit_memory(默认为0) 
2： # echo "vm.overcommit_memory=1" >> /etc/sysctl.conf 
# /sbin/sysctl -p 



2.3、拷贝配置文件
#mkdir /usr/local/services/redis-2.4.15/etc
# cd /soft/redis/redis-2.4.15
# cp redis.conf /usr/local/services/redis-2.4.15/etc/


2.4、redis配置文件
# mkdir -p /data/redis/redis_db
#mkdir -p /data/redis/redis_dump

# vim /usr/local/service/redis-2.4.15/etc/
daemonize yes
pidfile /data/redis/redis_db/redis.pid
port 6379
timeout 300
loglevel debug
logfile stdout
databases 16
save 900 1
save 300 10
save 60 10000
rdbcompression yes
dbfilename dump.rdb
dir /data/redis/redis_dump
slave-serve-stale-data yes
appendonly no
appendfsync everysec
no-appendfsync-on-rewrite no
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
slowlog-log-slower-than 10000
slowlog-max-len 128
vm-enabled no
vm-swap-file /data/redis/redis_db/redis.swap
vm-max-memory 0
vm-page-size 32
vm-pages 134217728
vm-max-threads 4
hash-max-zipmap-entries 512
hash-max-zipmap-value 64
list-max-ziplist-entries 512
list-max-ziplist-value 64
set-max-intset-entries 512
zset-max-ziplist-entries 128
zset-max-ziplist-value 64
activerehashing yes
bind 127.0.0.1


配置文件说明
daemonize yes # Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程
pidfile /data/redis/redis_db/redis.pid #当Redis以守护进程方式运行时，Redis默认会把pid写入/var/run/redis.pid文件，可以通过pidfile指定

port 6379 #指定Redis监听端口，默认端口为6379，作者在自己的一篇博文中解释了为什么选用6379作为默认端口，因为6379在手机按键上MERZ对应的号码，而MERZ取自意大利歌女Alessia Merz的名字

timeout 300  #当客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能

loglevel debug #指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verbose

logfile stdout  #日志记录方式，默认为标准输出，如果配置Redis为守护进程方式运行，而这里又配置为日志记录方式为标准输出，则日志将会发送给/dev/null

databases 16 #设置数据库的数量，默认数据库为0，可以使用SELECT <dbid>命令在连接上指定数据库id

#指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合
Redis默认配置文件中提供了三个条件
save 900 1 
save 300 10
save 60 10000

#指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大
rdbcompression yes

#指定本地数据库文件名，默认值为dump.rdb
dbfilename dump.rdb
#指定本地数据库存放目录
dir /data/redis/redis_dump

设置当本机为slav服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步
slave-serve-stale-data yes

. 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为 redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为no
appendonly no

指定更新日志条件，共有3个可选值： 
no：表示等操作系统进行数据缓存同步到磁盘（快） 
always：表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全）
everysec：表示每秒同步一次（折衷，默认值）
appendfsync everysec

当AOF文件增长到一定大小的时候Redis能够调用 BGREWRITEAOF 对日志文件进行重写
no-appendfsync-on-rewrite no
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb

注意制定一个负数将关闭慢日志，而设置为0将强制每个命令都会记录
slowlog-log-slower-than 10000
slowlog-max-len 128

指定是否启用虚拟内存机制，默认值为no，简单的介绍一下，VM机制将数据分页存放，由Redis将访问量较少的页即冷数据swap到磁盘上，访问多的页面由磁盘自动换出到内存中（在后面的文章我会仔细分析Redis的VM机制）
vm-enabled no

虚拟内存文件路径，默认值为/tmp/redis.swap，不可多个Redis实例共享
vm-swap-file /data/redis/redis_db/redis.swap #交换文件

将所有大于vm-max-memory的数据存入虚拟内存,无论vm-max-memory设置多小,所有索引数据都是内存存储的(Redis的索引数据 就是keys),也就是说,当vm-max-memory设置为0的时候,其实是所有value都存在于磁盘。默认值为0
vm-max-memory 0

Redis swap文件分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，vm-page-size是要根据存储的 数据大小来设定的，作者建议如果存储很多小对象，page大小最好设置为32或者64bytes；如果存储很大大对象，则可以使用更大的page，如果不 确定，就使用默认值
vm-page-size 32

设置swap文件中的page数量，由于页表（一种表示页面空闲或使用的bitmap）是在放在内存中的，，在磁盘上每8个pages将消耗1byte的内存
vm-pages 134217728


设置访问swap文件的线程数,最好不要超过机器的核数,如果设置为0,那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟。默认值为4
vm-max-threads 4

指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法
hash-max-zipmap-entries 512
hash-max-zipmap-value 64

list数据类型节点值大小小于多少字节会采用紧凑存储格式。
list-max-ziplist-entries 512
list-max-ziplist-value 64

set数据类型内部数据如果全部是数值型，且包含多少节点以下会采用紧凑格式存储。
set-max-intset-entries 512

zsort数据类型节点值大小小于多少字节会采用紧凑存储格式。
zset-max-ziplist-entries 128
zset-max-ziplist-value 64

指定是否激活重置哈希，默认为开启
activerehashing yes

绑定的主机地址
bind 127.0.0.1



2.5、启动Redis服务
# redis-server conf/redis.conf
# redis-cli shutdown  停止Redis  关闭服务 
# redis-cli -p 6380 shutdown  如果非默认端口，可指定端口: 






2.6、测试Redis
# ls /data/redis/redis_dump/  看看是否有文件。没有？正常。我们写入数据进去
# telnet localhost  6379    
Trying ::1...
telnet: connect to address ::1: Connection refused
Trying 127.0.0.1...
Connected to localhost.
Escape character is '^]'.
get mykey
$-1
set foo 3
+OK
get foo
$1
3
save
+OK
quit
+OK
Connection closed by foreign host.

# ls /data/redis/redis_dump/  在此尝试看看。。
                            
                             
                             


第三章  VARNISH 
一、Varnish概述
2.1.1 Varnish的结构与特点
 Varnish是一个轻量级别的Cache和反向代理软件，先进的设计理念和成熟的设计框架是Varnish的主要特点：
	基于内存进行缓存，重启后数据将消失
	利用虚拟内存方式，I/O性能好.
	支持设置0~60秒的精确缓存时间
	VCL配置管理比较灵活
	32位机器上缓存文件大小为最大2GB
	具有强大的管理功能，例如：top stat admin list等
	状态设计巧妙，结构清晰
	利用二叉堆管理缓存文件，达到可以积极删除目的。


2.1.2 Varnish与Squid的对比
  说到Varnish，就不能不提Squid，Squid是一个高性能的代理缓存服务器，它和Varnish的相比较有诸多的异同点，下面进行分析：
        相同点：
	都是一个反向代理服务器
	都是开源软件
     
        异同点，也是Varnish的优点:
	Varnish的稳定性很高，两者在完成相同的负荷的工作时，Squid发生的故障几率要高于Varnish，因为Squid需经常重启.
	Varnish访问速度更快，Varnish采用用了”Visual Page Cache”技术，所有缓存的数据都直接从内存读取，而且Squid是从硬盘读取缓存数据，因此Varnish访问速度更快
	Varnish可以支持更多的并发连接，因为Varnish的TCP连接要比Squid释放快，所以在高并发连接情况可以支持更多地TCP连接。
	Varnish可以通过管理端口，使用正则表达式清除部分缓存，而Squid做不到。
     Varnish缺点如下：
	在高并发状态下CPU,I/O和内存等资源开销都要高于Squid。
	Varnish进程一旦挂起，崩溃或者重启，缓存数据都会从内存当中完全释放，此时所有的请求会发送后端的WEB服务器，在高并发的情况下，这会给后端的服务器造成很大压力。

  Internet外网
      |
  ---FW-->防火墙
      |
      |
      |
      |
--Varnish1  --Varnish2  --Varnish3
   |            |            |
   |            |            |
   |            |            |
   |            |            | 
 WEB1          WEB2         WEB3

配置与安装
二、Varnish安装
2.1、环境：
Varnish-server:10.0.0.202
Nginx-Server:10.0.0.201

2.2.2、创建Varnish用户缓存目录和日志
# useradd varnish -s /sbin/nologin   创建varnish用户
# mkdir /varnish/cache –p         创建varnish缓存目录
# mkdir /varnish/log              创建varnish日志 
# chown -R varnish:varnish /varnish/  修改赋权组


2.2.3、安装PCRE 
为了兼容正则表达式，编译 2.0以上版本时否则会报错pcre找不到。
# yum install gcc 
# yum install gcc-c++ libstdc++-devel
# yum install -y httpd-devel pcre perl pcre-devel zlib zlib-devel GeoIP GeoIP-devel
# wget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.34.tar.bz2
# tar -xvf pcre-8.34.tar.bz2
# cd pcre-8.34/
# ./configure --prefix=/usr/local/prce/
# make && make install

2.2.4、安装Varnish
# wget http://repo.varnish-cache.org/source/varnish-3.0.0.tar.gz
# tar -xzvf varnish-3.0.0.tar.gz
# cd varnish-3.0.0
#./configure --prefix=/usr/local/varnish PKG_CONFIG_PATH=/usr/lib/pkgconfig
# make && make install
# cd /usr/local/varnish/sbin
./varnishd -V




2.3.1、VCL使用说明
VCL，即Varnish Configaution Language 用来定义Varnish的存储策略
VCL内置函数
   (1)、vcl_recv函数
用于接收和处理请求，当请求到达并成功接收后被调用.
    函数一般以如下几个关键字结束
pass表示进入pass模式，把请求控制权交给vcl_pass函数
pige 表示进入pige模式，把请求控制权交给vcl_pipe函数
error code[reason] 表示返回”code”给客户，并放弃处理该请求，”code”是错误的标识
，例如：200和405等，”reason”是错误信息

(2)、vcl_pipe函数
   此函数在进入pipe模式时被调用，用于请求直接传至后端主机，在请求和返回内容没有改变的情况下，将不变的内容返回给客户端，直到这个连接被关闭。
   此函数一般以如下几个关键字结束：
     error code[reason]
     pipe
(3)、vcl_pass函数
   此函数在进入pass模式时被调用，用于请求直接传至后端主机，后端主机但应数据，将答应的数据传至客户端，但不进行任何缓存，当前连接下每次都返回最新的内容。
此函数一般以如下几个关键字结束：
error code[reason]
     pass

(4)、lookup函数
   表示在缓存中查找被请求的对象，并且根据查找的结果把控制权交给vcl_hit或者函数vcl_miss

(5)、vcl_hit函数
在执行lookup指令后，在缓存中找到请求的内容后将自动调用该函数
此函数一般以如下几个关键字结束：
fetch 表示从后端获取请求的内容，并且把控制权交给vcl_fetch函数
  deliver  表示将找到的内容发送给客户，并且把控制权交给函数vcl_deliver
error code[reason]
pass

(6)、vcl_miss函数
   在执行lookup指令后，在缓存中没有找到请求的内容时自动调用该方法，此函数可以于判断是否需要从后端服务器获取内容
  此函数一般以如下几个关键字结束：
fetch：表示从后端获取请求内容，并且把控制权交给vcl_fetch函数
error code[reason]
pass

(7)、vcl_miss函数
在后端主机更新缓存并且获取内容后调用该方法，接着，通过判断获取的内容来决定是将内容放入缓存，还是直接返回给客户端，
   此函数一般以如下几个关键字结束：
 error code[reason]
pass
deliver 

(8)、vcl_deliver函数
  将在缓存中找到请求的内容发送给客户端调用此方法。
此函数一般以如下几个关键字结束：
error code[reason]
deliver 

(9)、vcl_timeout函数
 在缓存内容到期前调用此函数.
此函数一般以如下几个关键字结束：
 discard：表示从缓存中清除内容
 fetch

(10)、vcl_discard函数
  在缓存内容到期后或者缓存空间不足时，自动调用该函数.
此函数一般以如下几个关键字结束：
  keep:表示将内容继续保留在缓存当中
discard 





三、Varnish配置
2.3.2、配置Varnish配置实战
由于本版不同，Varnish配置文件的写法也存在一定的差异，Varnish3.x版本不但在配置写法上和2.x版本不同，修复了很多不应用BUG，本文以3.x版本为基准
   Varnish安装完成后，默认的配置文件/usr/local/varnish/etc/varnish/default.vcl
 此配置文件默认是全部注释掉的.配置文件如下：
先编辑配置文件
# vi /usr/local/varnish/etc/varnish/default.vcl
# This is a basic VCL configuration file for varnish.  See the vcl(7)
# man page for details on VCL syntax and semantics.
# 
# Default backend definition.  Set this to point to your content
# server.
# 

# This is a basic VCL configuration file for varnish.  See the vcl(7)
# man page for details on VCL syntax and semantics.
#
# Default backend definition.  Set this to point to your content
# server.
#
#设置后端WEB服务-关注点
backend webtest1 {
    .host = "10.0.0.201";    # web端地址～
     .port = "80";
    .connect_timeout = 1s;
    .first_byte_timeout = 5s;
    .between_bytes_timeout = 2s;
}

#可以定义多台WEB-关注点
#backend webtest2 {
#    .host = "192.168.100.6";
#    .port = "80";
#    .connect_timeout = 1s;
#    .first_byte_timeout = 5s;
#    .between_bytes_timeout = 2s;
#}
#多台WEB可以定义负载均衡-关注点lb_test，
#director lb_test random {
#    {
#      .backend = webtest1;
#      .weight = 5;
    # }
    # {
    #   .backend = webtest2;
    #   .weight = 5;
    # }
#}
#定义那些IP或者IP段具有访问权-关注点
acl purge {
    "localhost";
    "127.0.0.1";
    "192.168.1.0"/24;
    "10.0.0.0"/16;
}


sub vcl_recv {
#开启压缩模式，图片格式取消压缩
if (req.http.Accept-Encoding) {
    if (req.url ~ "\.(jpg|png|gif|jpeg|flv)" ) {
        remove req.http.Accept-Encoding;
        remove req.http.Cookie;
    } else if (req.http.Accept-Encoding ~ "gzip") {
        set req.http.Accept-Encoding = "gzip";
    } else if (req.http.Accept-Encoding ~ "deflate") {
        set req.http.Accept-Encoding = "deflate";
    } else {
        remove req.http.Accept-Encoding;
    }
}
#根据host设置后端服务器-关注点
  if (req.http.Host ~ "(?i)(www.test1.com|www.test2.com|10.0.0.202)") {    #(为varnish本机IP地址)
     #set req.backend = lb_test; #如果开启负载用此项，上面的负载均衡的POOL的名叫注意：lb_test
     set req.backend = webtest1;
       }else
  if (req.http.Host ~ "(?i)image.wdj.com"){
     set req.backend = webtest1;
  }else
  {
    error 408 "Hostname not found";
  }
#如果为purge请求，客户端ip不在访问列表中，返回405拒绝-关注点 
  if (req.request == "PURGE") {
     if (!client.ip ~purge) {
       error 405 "Not Allowed";
   }
#本地缓存查找
   return(lookup);
  }
#如果为GET请求，url后缀为jpg,png,gif等 取出cookie
  if (req.request == "GET"&&req.url ~ "(?i)\.(jpg|png|gif|swf|jpeg|ico)$") {
        unset req.http.cookie;
  }
#如果GET请求，url为php，则穿过cache，不缓存
  if (req.request =="GET"&&req.url ~ "(?i)\.php($|\?)"){
        return (pass);
  }
#简单防盗链--关注点
if (req.http.referer ~ "http://.*") {
  if ( !(req.http.referer ~ "http://.*test1\.com"
     || req.http.referer ~ "http://.*test2\.com"
     || req.http.referer ~ "http://.*wdj\.com"
     || req.http.referer ~ "http://.*google\.com"
     || req.http.referer ~ "http://.*baidu\.com"
     || req.http.referer ~ "http://.*yahoo\.cn"
  )) {
      error 404 "Not Found!";
 }
}
#获取客户端ip
#     if (req.restarts == 0) {
        if (req.http.x-forwarded-for) {
            set req.http.X-Forwarded-For =
                req.http.X-Forwarded-For + ", " + client.ip;
        } else {
            set req.http.X-Forwarded-For = client.ip;
        }
#   }
#不是以下请求进入pipe模块
    if (req.request != "GET" &&
      req.request != "HEAD" &&
      req.request != "PUT" &&
      req.request != "POST" &&
      req.request != "TRACE" &&
      req.request != "OPTIONS" &&
      req.request != "DELETE") {
        /* Non-RFC2616 or CONNECT which is weird. */
        return (pipe);
    }
#不是GET 和HEAD请求不缓存
    if (req.request != "GET" && req.request != "HEAD") {
        /* We only deal with GET and HEAD by default */
        return (pass);
    }
    if (req.http.Authorization) {
        /* Not cacheable by default */
        return (pass);
    }
    return (lookup);
}
#
 sub vcl_pipe {
     return (pipe);
 }
#
sub vcl_pass {
    return (pass);
}
#使用url+host hash算法查找数据
sub vcl_hash {
    hash_data(req.url);
    if (req.http.host) {
        hash_data(req.http.host);
    } else {
        hash_data(server.ip);
    }
    return (hash);
}
# 如果请求为purge 将清除缓存
sub vcl_hit {
   if (req.request == "PURGE") {
       set obj.ttl = 0s;
       error 200 "Purged";
    }
    return (deliver);
}

sub vcl_miss {
    return (fetch);
}
#
sub vcl_fetch {
    if (beresp.ttl <= 0s ||
        beresp.http.Set-Cookie ||
        beresp.http.Vary == "*") {
                /*
                 * Mark as "Hit-For-Pass" for the next 2 minutes
                 */
                set beresp.ttl = 0 s;
                return (hit_for_pass);
    }
    if (beresp.http.Pragma ~"no-cache" ||
    beresp.http.Cache-Control ~"no-cache" ||
    beresp.http.Cache-Control ~"private") {
      return (deliver);
   }
#为特定格式文件设置缓存时间，有多种格式可以直接在后面加-关注点
    if (req.request == "GET"&&req.url ~ "(?i)\.(js|css|mp3|jpg|png|gif|swf|jpeg|ico)$") {
    set beresp.ttl = 30d;
  }
   if (req.request == "GET"&&req.url ~ "(?i)\.(html|htm)$") {
    set beresp.ttl = 1d;
  }
    return (deliver);
}
# 设置返回状态
 sub vcl_deliver {
     set resp.http.x-hits = obj.hits;
     if (obj.hits > 0) {
      set resp.http.X-Cache = "Hit test.com";
   }else {
       set resp.http.X-Cache = "Miss test.com";
   }
     set resp.http.Server = "BWM";
     return (deliver);
 }
# 定义错误
sub vcl_error {
    set obj.http.Content-Type = "text/html; charset=utf-8";
    set obj.http.Retry-After = "5";
    synthetic {"
<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
  <head>
    <title>"} + obj.status + " " + obj.response + {"</title>
  </head>
  <body>
    <h1>Error "} + obj.status + " " + obj.response + {"</h1>
    <p>"} + obj.response + {"</p>
    <h3>Guru Meditation:</h3>
    <p>XID: "} + req.xid + {"</p>
    <hr>
    <p>Varnish cache server</p>
  </body>
</html>
"};
    return (deliver);
}

sub vcl_init {
        return (ok);
}

sub vcl_fini {
        return (ok);
}

四、Varnish运行
-u 以什么用户运行
-g 以什么组运行
-f varnish配置文件
-a 绑定IP和端口
-s varnish缓存文件位置与大小
-w 最小，最大线程和超时时间
-t 缓存时间s
-T varnish管理端口，主要用来清除缓存
-p client_http11=on 支持http1.1协议
-P(大P) /usr/local/varnish/var/varnish.pid 指定其进程码文件的位置，实现管理
停止varnish



varnish两种缓存方式：
(1)基于malloc内存+swap交换模式
/usr/local/varnish/sbin/varnishd -f /usr/local/varnish/etc/varnish/default.vcl -s malloc,200M -a 10.0.0.202:80 -w 1024,512000,10 -t 10.0.0.202:300

(2)基于file是mmap的文件内存映射的机制.
/usr/local/varnish/sbin/varnishd -u varnish -g varnish -f /usr/local/varnish/etc/varnish/default.vcl -a 10.0.0.202:80 -s file,/varnish/cache/varnish_cache.data,1G -w 1024,51200,10 -t 3600 -T 10.0.0.202:3000                  
企业里里面开启为100G






2.4.2、启动日志
# /usr/local/varnish/bin/varnishncsa -w  /varnish/log/varnish.log &

日志加入开机启动:
 echo "/usr/local/varnish/bin/varnishncsa -w /data/varnish/logs/varnish.log &" >> /etc/rc.local
参数: -w 指定varnish访问日志要写入的目录与文件








LVS 负载均衡
8章-LVS负载均衡


http://os.51cto.com/art/201105/264303.htm


http://os.51cto.com/art/201105/262536.htm


一、为什么要使用这个负载均衡技术？
考虑一个问题：
  比如某公司有一台服务器目前支撑了2000左右的用户，但是随着用户的业务扩展，用户量爆增到5000.或者一万，
  这个时候。怎么处理?
     两种处理方法：
     (1)向上扩展，提高当前服务器的硬件性能，硬件的提升并不能完全解决问题，
     (2)向外扩展  也称为横向扩展，增加服务器数量，通过负载均衡均匀的分配用户
    负载均衡技术(Load Balancing:LB).
    (1)系统的高可用性
    (2)系统扩展性
    (3)负载均衡能力.
LVS+Keepalived很好的实现了以上的需求，LVS提供均衡能力，Keepalived提供健康检查故障转移，提供高系统的可用性。
  采用这样的架构以后，很容易对现有的系统进行扩展，只要后端增加或者减少(realServer)，只要更改lvs的配置文件，就可是实现
  无缝配置变更.

二、LVS工作模式介绍
 (1)LVS是一个开源的软件，可以实现Linux平台的负载均衡，LVS是Linux Virtual Server的缩写，意思就是Linux虚拟服务器。
 LVS目前有三种IP负载技术(VS/NAT, VS/TUN, VS/DR)。八种调度算法(rr,wrr,lc,wlc,lblc,lblcr,dh,sh)
 
 
 
 LVS负载均衡的八种调度算法
RR算法
LVS负载均衡算法1.轮循调度(Round-RobinScheduling)  

WRR算法
LVS负载均衡算法2.加权轮循调度(WeightedRound-RobinScheduling)

LC算法
LVS负载均衡算法3.最小连接调度(Least-ConnectionScheduling)

WLC算法:
LVS负载均衡算法4.加权最小连接调度(WeightedLeast-ConnectionScheduling)

LBLC算法
LVS负载均衡算法5.基于局部性的最少链接(Locality-BasedLeastConnectionsScheduling)

LBLCR算法
LVS负载均衡算法6.带复制的基于局部性最少链接(Locality-BasedLeastConnectionswithReplicationScheduling)

DH算法
LVS负载均衡算法7.目标地址散列调度(DestinationHashingScheduling)

SH算法
LVS负载均衡算法8.源地址散列调度(SourceHashingScheduling)

	(2)、keepalived
	Keepalived 是运行在lvs 之上，它的主要功能是实现真实机的故障隔离及负载均衡器间的失败 切换，提高系统的可用性


    
     
三、LVS的安装
环境描述：
LVS server1 (Master):10.0.2.34-虚拟IP为:10.0.2.234
LVS server2 ( Slave ) :10.0.2.205虚拟IP为:10.0.2.234
WEB server1: 10.0.2.53  网关为:10.0.0.254
WEB server2; 10.0.2.41  网关为:10.0.0.254

WEB 端开启nginx 同时注意端口号的问题

注意：所有集群服务器时间要一致

2.2、安装LVS
注意此动作。否则MAKE直接报错。
# ln -s /usr/src/kernels/2.6.32-279.el6.x86_64/ /usr/src/linux
# tar -xvf ipvsadm-1.24.tar.gz 
# cd ipvsadm-1.24
# make && make install
# ipvsadm -L
如果/usr/src/kernels为空，没有文件?
解决方法如下：
#yum -y install kernel-devel-2.6.32-279.el6.x86_64

配置文件说明：
! Configuration File for keepalived
global_defs {  #全局定义
   notification_email { #定义邮件
      alvin@126.com  #定义邮件地址
   }
   notification_email_from alvin@126.com #定义邮件地址
   smtp_server mail.126.com #邮件服务器
   smtp_connect_timeout 30 #邮件超时时间
   router_id LVS_DEVEL #route_id标识 
}

vrrp_instance VI_1 { #定义VRR组，
    state MASTER  #定义为MASTER主
    interface eth1 #对外访问的网络接口
    virtual_router_id 100 #虚拟路由标识。注意主从要一致
    priority 100 #主从优先级，主的优先级要高于从。注意
    advert_int 1 #:广播周期秒数
    authentication {
        auth_type PASS
        auth_pass 2209
    }
    virtual_ipaddress {
        10.0.0.210 #:虚拟VIP地址，真实环境这里应该是公网IP
 }

}
virtual_server 10.0.0.210 80 { #:虚拟VIP地址 与 端口，DR架构WEB端口要和虚拟端口监听一致。否则将无法访问
    delay_loop 6 #健康检查时间间隔，单位是秒
    lb_algo rr   #调用算法为RR
    lb_kind DR   #调用架构模式为DR
    persistence_timeout 0 #:同一IP 50秒内的请求都发到同个real server
    protocol TCP  #使用TCP协议
   
    real_server 10.0.0.201 80 {#:真实WEB服务器地址与端口
        weight 1 #：转发伐值，越高调用的越多
        TCP_CHECK {
        connect_timeout 10   #：连接超时为10秒
        nb_get_retry 3
        delay_before_retry 3
        connect_port 80  #连接端口为80，要和上面的保持一致
} 
    }
    real_server 10.0.0.204 80 {
        weight 1
        TCP_CHECK {
        connect_timeout 10
        nb_get_retry 3
        delay_before_retry 3
        connect_port 80
        }
     }
}


2.3、安装Keepalived
# tar  -xvf keepalived-1.1.20.tar.gz
# cd keepalived-1.1.20
#./configure  --prefix=/usr/local/keepalived
 yum install -y popt-devel
# make && make install
# cp /usr/local/keepalived/etc/rc.d/init.d/keepalived  /etc/rc.d/init.d/
# cp /usr/local/keepalived/etc/sysconfig/keepalived  /etc/sysconfig/
# mkdir /etc/keepalived
# cp usr/local/keepalived/etc/keepalived/keepalived.conf  /etc/keepalived/
# cp /usr/local/keepalived/sbin/keepalived /usr/sbin/

Master 端和slave 端的配置一样 区别在于 master state :MASTER  slave state:BACKUP


Master配置
# vim /etc/keepalived/keepalvied.conf
! Configuration File for keepalived

global_defs {
   notification_email {
     acassen@firewall.loc
     failover@firewall.loc
     sysadmin@firewall.loc
   }
   notification_email_from Alexandre.Cassen@firewall.loc
   smtp_server 192.168.200.1
   smtp_connect_timeout 30
   router_id LVS_DEVEL
}

vrrp_instance VI_1 {
    state MASTER
    interface eth1
    virtual_router_id 51
    priority 100
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    virtual_ipaddress {
        10.0.0.210
    }
}

virtual_server 10.0.2.234 8080 {
    delay_loop 6
    lb_algo rr
    lb_kind DR
    nat_mask 255.255.255.0
    persistence_timeout 15
    protocol TCP

  real_server 10.0.2.53 8080 {
        weight 1
        TCP_CHECK {
        connect_timeout 10
        nb_get_retry 3
        delay_before_retry 3
        connect_port 8080
        }
     }

  real_server 10.0.2.41 8080 {
        weight 1
        TCP_CHECK {
        connect_timeout 10
        nb_get_retry 3
        delay_before_retry 3
        connect_port 8080
        }
     }

 }



2.3、LVS从的配置：
#vim/etc/keepalvied 
! Configuration File for keepalived

global_defs {
   notification_email {
     acassen@firewall.loc
     failover@firewall.loc
     sysadmin@firewall.loc
   }
   notification_email_from Alexandre.Cassen@firewall.loc
   smtp_server 192.168.200.1
   smtp_connect_timeout 30
     protocol TCP

  real_server 10.0.0.202 80 {
        weight 1
        TCP_CHECK {
        connect_timeout 10
        nb_get_retry 3
        delay_before_retry 3
        connect_port 80
        }
     }

  real_server 10.0.0.223 80 {
        weight 1
        TCP_CHECK {
        connect_timeout 10
        nb_get_retry 3
        delay_before_retry 3
        connect_port 80
        }
     }

 }
  router_id LVS_DEVEL
}

  vrrp_instance VI_1 {
    state BACKUP
    interface eth1
    virtual_router_id 51
    priority 99
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    virtual_ipaddress {
        10.0.0.210
    }
}

virtual_server 10.0.0.210 80 {
    delay_loop 6
    lb_algo rr
    lb_kind DR
    nat_mask 255.255.0.0
    persistence_timeout 15

#/etc/init.d/keepalived restart



NAT模式 


NAT负载模式:
  NAT本来是因IPV4的公网地址不足，把内部的私有地址映射成公网地址实现，内部机器可以访问互联网.
  
  
   用户 
   |
   |
---LVS-----
|        |
|        |
WEB      WEB
   

(1)用户向LVS发起数据访问，
(2)LVS把这个数据访问定向到内部WEB服务器
(3)WEB服务器最后把数据返回给LVS
(4)再由LVS把数据返回给用户.
不管是出去还是进来的流量都需要经过LVS。这样的LVS负载压力非常之大。

NAT模式：
集群节点跟Direcator必须在同一个IP网络中。
RIP(真实IP)通常是私有地址，仅仅用于个集群之间通信。
director位于Client和real server之间，并负责处理进出的所有通信。
realservet必须将网关指向DIP。同时也支持端口影射
Realserver可以使用任意OS
在较大应用规模当中，单个Director会出现瓶颈
大概可以带10个左右的SERVER就会出现瓶颈。






DR模式


LVS负载均衡模式 直接路由模式（DR）
直接路由模式比较特别,很难说和什么方面相似,前NAT基本上都是工作在网络层上(三层),而直接路由模式则应该是工作在数据链路层上(二层)｡其原理 为,DR和REALSERVER都使用同一个IP对外服务｡但只有DR对ARP请求进行响应,所有REALSERVER对本身这个IP的ARP请求保持静 默｡也就是说,网关会把对这个服务IP的请求全部定向给DR,而DR收到数据包后根据调度算法,找出对应的REALSERVER,把目的MAC地址改为 REALSERVER的MAC并发给这台REALSERVER｡这时REALSERVER收到这个数据包,则等于直接从客户端收到这个数据包无异,处理后 直接返回给客户端｡由于DR要对二层包头进行改换,所以DR和REALSERVER之间必须在一个广播域,也可以简单的理解为在同一台交换机上｡


 DR模式：
   个集群节点跟dr必须在同一个物理网络(局域网)当中(dr和web不能隔了有路由器)
   VIP可以使用公网地址，实现远程管理和监控
   director只负责处理进站请求，响应的请求封装后直接由Relserver发给客户端。
   Realserver不能将Direc当成网关。只能选择前当网关。
   Direc不能支持端口映射。VIP的端口必须和WEB服务端口一致
   大多数的操作系统都可以应用在relserver上。
   Direc性能比NAT要好很多。处理速度提高N倍

















TUN模式








RSYNC+INTOTIFY实现数据同步
                                   
                                    rsync+inotify实现数据同步


一、rsync概述

rsync与传统的cp、tar备份方式相比，rsync具有安全性高、备份迅速、支持增量备份等优点，通过rsync可以解决对实时性要求不高的数据备份需求，例如定期的备份文件服务器数据到远端服务器，对本地磁盘定期做数据镜像等。
    随着应用系统规模的不断扩大，对数据的安全性和可靠性也提出的更好的要求，rsync在高端业务系统中也逐渐暴露出了很多不足，首先，rsync同步数 据时，需要扫描所有文件后进行比对，进行差量传输。如果文件数量达到了百万甚至千万量级，扫描所有文件将是非常耗时的。而且正在发生变化的往往是其中很少 的一部分，这是非常低效的方式。其次，rsync不能实时的去监测、同步数据，虽然它可以通过linux守护进程的方式进行触发同步，但是两次触发动作一 定会有时间差，这样就导致了服务端和客户端数据可能出现不一致，无法在应用故障时完全的恢复数据。基于以上原因，rsync+inotify组合出现了。


二、	inotify 概述

2.1、初识inotify
Inotify 是一种强大的、细粒度的、异步的文件系统事件监控机制，linux内核从2.6.13起，加入了Inotify支持，通过Inotify可以监控文件系统 中添加、删除，修改、移动等各种细微事件，利用这个内核接口，第三方软件就可以监控文件系统下文件的各种变化情况，而inotify-tools就是这样 的一个第三方软件。
   在上面章节中，我们讲到，rsync可以实现触发式的文件同步，但是通过crontab守护进程方式进行触发，同步的数据和实际数据会有差异，而inotify可以监控文件系统的各种变化，当文件有任何变动时，就触发rsync同步，这样刚好解决了同步数据的实时性问题。
   
   
在WEB内容发布服务器安装inotify.  
 2.2、inotify安装
# tar –xvf inotify-tools-3.14.tar.gz
# ./configure
# make && make install


# ll /usr/local/bin/inotifywa*
-rwxr-xr-x 1 root root 44319 4月   6 18:51 /usr/local/bin/inotifywait
-rwxr-xr-x 1 root root 41409 4月   6 18:51 /usr/local/bin/inotifywatch
inotifywait用于等待文件或文件集上的一个特定事件，它可以监控任何文件和目录设置，并且可以递归地监控整个目录树
inotifywatch用于收集被监控的文件系统统计数据，包括每个inotify事件发生多少次等信息

  
  




三、	企业案例WEB内容版本发布管理
3.1、环境描述
随着企业的业务增多，为了维持所有WEB层的WEB程序保持一致。发版本的通过一台内容服务器向外进行分布和辐射所有的更新的WEB程序，模拟环境如下：
WEB1 节点 IP:10.0.0.202
WEB2节点内容发布Server IP:10.0.0.201

3.2、安装WEB1节点
# yum –y install rsync
# vim /etc/web1.pass
gongda:123
# chmod 600 /etc/web1.pass
# mkdir /web1/wwwroot –p
# vim /etc/rsyncd.conf   #此配置文件没有。需要重新编辑一个
uid = nobody
gid = nobody
use chroot = no
max connections = 10
strict modes = yes
pid file = /var/run/rsyncd.pid
lock file = /var/run/rsync.lock
log file = /var/log/rsyncd.log
[web1]
path = /web1/wwwroot/
comment = web1 file
ignore errors
read only = no
write only = no
hosts allow = 10.0.0.201（WEB2发布端）
hosts deny = *
list = false
uid = root
gid = root
auth users = web1user
secrets file = /etc/web1.pass

启动rsync服务
# rsync --daemon




3.2、安装WEB2内容管理节点
# yum –y install rsync

mkdir /web/wwwroot
在WEB内容发布服务器安装inotify.  
（1）、inotify安装
# tar –xvf inotify-tools-3.14.tar.gz
# ./configure
# make && make install

# ll /usr/local/bin/inotifywa*
-rwxr-xr-x 1 root root 44319 4月   6 18:51 /usr/local/bin/inotifywait
-rwxr-xr-x 1 root root 41409 4月   6 18:51 /usr/local/bin/inotifywatch
inotifywait用于等待文件或文件集上的一个特定事件，它可以监控任何文件和目录设置，并且可以递归地监控整个目录树
inotifywatch用于收集被监控的文件系统统计数据，包括每个inotify事件发生多少次等信息


（2）同步的密码，注意此处只需要写密码，和web1.pass里面的密码要以致
# vim /etc/server.pass
123
#chmod 600 /etc/server.pass

（3）编写一个启动脚本
# vim opt/inotify-rsync.sh 
#!/bin/bash
host1=10.0.0.202  （WEB1）
#======================
src=/web/wwwroot/
dst1=web1
user1=gongda
/usr/local/bin/inotifywait -mrq --timefmt '%d/%m/%y %H:%M' --format '%T %w%f%e' -e modify,delete,create,attrib  $src \
| while read files
        do
  /usr/bin/rsync -vzrtopg --delete --progress --password-file=/etc/server.pass $src $user1@$host1::$dst1
                echo "${files} was rsynced" >>/tmp/rsync.log 2>&1
         done

（4）启动脚本
#cd /opt
#chmod +x inotify-rsync.sh
# nohup bash –x inotify-rsync.sh &
查看生成的日志文件文件






3.2、常见错误
问题一：
@ERROR: chroot failed
rsync error: error starting client-server protocol (code 5) at main.c(1522) [receiver=3.0.3]
原因：服务器端的目录不存在或无权限。创建目录并修正权限可解决问题。
 
问题二：
@ERROR: auth failed on module tee
rsync error: error starting client-server protocol (code 5) at main.c(1522) [receiver=3.0.3]
原因：服务器端该模块（tee）需要验证用户名密码，但客户端没有提供正确的用户名密码，认证失败。提供正确的用户名密码解决此问题。
 
问题三：
@ERROR: Unknown module ‘tee_nonexists’
rsync error: error starting client-server protocol (code 5) at main.c(1522) [receiver=3.0.3]
原因：服务器不存在指定模块。提供正确的模块名或在服务器端修改成你要的模块以解决问题。
 
问题四：
password file must not be other-accessible
continuing without password file
Password:
原因：这是因为rsyncd.pwd rsyncd.secrets的权限不对，应该设置为600。如：chmod 600 rsyncd.pwd
 
问题五：
rsync: failed to connect to 218.107.243.2: No route to host (113)
rsync error: error in socket IO (code 10) at clientserver.c(104) [receiver=2.6.9]
原因：对方没开机、防火墙阻挡、通过的网络上有防火墙阻挡，都有可能。关闭防火墙，其实就是把tcp udp的873端口打开。
问题六：
rsync error: error starting client-server protocol (code 5) at main.c(1524) [Receiver=3.0.7]
原因：/etc/rsyncd.conf配置文件内容有错误。请正确核对配置文件。
 
问题七：
rsync: chown "" failed: Invalid argument (22)
原因：权限无法复制。去掉同步权限的参数即可。(这种情况多见于Linux向Windows的时候)
问题八：
@ERROR: daemon security issue -- contact admin
rsync error: error starting client-server protocol (code 5) at main.c(1530) [sender=3.0.6]
原因：同步的目录里面有软连接文件，需要服务器端的/etc/rsyncd.conf打开use chroot = yes。掠过软连接文件。



      


MYSQL备份工具  XTRABACKUP
                                       第10章--->Xtrabackup
                                       
                                       
                 http://blog.itpub.net/26355921/viewspace-1172234/   
                 xtrabackup对比测试                   
一、Xtrabackup概述
1.1、简介
Xtrabackup是一个对InnoDB做数据备份的工具，支持在线热备份（备份时不影响数据读写），是商业备份工具InnoDB Hotbackup的一个很好的替代品。
    Xtrabackup有两个主要的工具：xtrabackup、innobackupex
  （1）xtrabackup只能备份InnoDB和XtraDB两种数据表，而不能备份MyISAM数据表
  （2）innobackupex-1.5.1则封装了xtrabackup，是一个脚本封装，所以能同时备份处理innodb和myisam，但在处理myisam时需要加一个读锁
 
1.2、安装
#wget http://www.percona.com/redir/downloads/XtraBackup/XtraBackup-2.0.0/binary/Linux/x86_64/percona-xtrabackup-2.0.0.tar.gz

# yum -y install perl-*
# tar -xvf percona-xtrabackup-2.0.0.tar.gz
# mv percona-xtrabackup-2.0.0 /usr/local/xtrabackup
# vim /etc/profile
export PATH=$PATH:/usr/local/xtrabackup/bin

#source /etc/profile


1.3、全量备份
#innobackupex --defaults-file=/etc/my.cnf --user=root --password=123456 /opt/backup/ >>/opt/backup/backup.log 2>&1
 /opt/backup备份存放的目录
 
 
 
1.4、全量恢复
# /etc/init.d/mysqld stop
# rm /data/dbdata/* -rf  备份成功后。删除掉这个MYSQL的数据目录试试？



开始恢复步骤一
# innobackupex --apply-log --defaults-file=/etc/my.cnf --user=root --password=123456 /opt/backup/2014-04-06_08-25-19/

开始恢复步骤二
# cd /data/dbdata
#innobackupex --user=root --password=zeng --defaults-file=/etc/my.cnf --copy-back /opt/backup/2014-04-06_08-25-19/

备份之后的新数据 要重新授予权限,mysql才能正常启动. 
不然会报错  一般报错为 can.t connect to       ......mysql.sock 

1.5、增量备份
(1)、先做全量备份
#innobackupex --defaults-file=/etc/my.cnf --user=root --password=123456 /opt/backup/ >>/opt/backup/backup.log 2>&1

(2)、在Mysql里面多创建一个表

(3)、在做增量备份
#--incremental：增量备份的文件夹
#--incremental-dir：针对哪个做增量备份


# innobackupex --user=root --password=123456 --incremental /opt/backup/ --incremental-dir 2014-04-06_10-11-36
#cd /opt/backup
#ls –l
2014-04-06_10-11-36  全量备份包
2014-04-06_12-40-48  增量备份包

1.6、增量恢复
#/etc/init.d/mysqld stop
# innobackupex --copy-back /databackup/2014-04-06_12-40-48 /
# /etc/init.d/mysqld start





1.7、企业真实环境
(1)、
  innobackupex --user=root --password=123456 --defaults-file=/etc/my.cnf --database=zztx --stream=tar /data/back_data/ 2>/data/back_data/zztx.log | gzip     1>/data/back_data/zztx.tar.gz
      
      说明：
      --database=zztx 单独对zztx数据库做备份 ，若是不添加此参数那就那就是对全库做备份
      2>/data/back_data/zztx.log  输出信息写入日志中
      1>/data/back_data/zztx.tar.gz 打包压缩存储到该文件中

(2)、
此处可以写个脚本做备份(backup.sh)
      #!/bin/sh
      echo "开始备份..."`date`
      log=zztx01_`date +%y%m%d%H%M`.log
      str=zztx01_`date +%y%m%d%H%M`.tar.gz
      innobackupex --user=root --password=123456 --defaults-file=/etc/my.cnf --database=zztx --stream=tar /data/back_data/ 2>/data/back_data/$log | gzip 1>/data/back_data/$str
      echo "备份完毕..."`date`



(3)、恢复数据
      1) 先停止数据库：service mysqld stop
      2) 解压 tar -izxvf zztx.tar.gz -C /data/back_data/db/   (没有db ,需要mkdir /data/back_data/db/)  
      3) 恢复 innobackupex --user=root --password --defaults-file=/etc/my.cnf  --apply-log /data/back_data/db/  (--apply-log选项的命令是准备在一个备份上启动mysql服务)
              innobackupex --user=root --password --defaults-file=/etc/my.cnf  --copy-back /data/back_data/db/  (--copy-back 选项的命令从备份目录拷贝数据,索引,日志到my.cnf文   件里规定的初始位置。)
      4) 赋权 chown -R mysql.mysql /var/lib/mysql/*
      5) 重启数据库 service mysqld restart
      6) 删除垃圾 cd /var/lib/mysql/  && rm xtrabackup*
      进入数据库查看，一切OK~



XTRABACKUP与MYSQLDUMP备份测试









http://blog.itpub.net/26355921/viewspace-1172234/






结论：xtrabackup占用的CPU与内存较少，消耗的IO相对较大，备份后的文件较大。


 
生产环境究竟是使用mysqldump还是xtrabackup来备份与恢复数据库 一个合格的运维工程师或者dba工程师，如果有从事数据库方面的话，首先需要做的就是备份，如果没有备份，出现问题的话，你的业务就会出问题，你的工作甚至会。。。 所以备份是重要的，但光有备份还不行，备份后如果出现问题，你还得使用备份数据来恢复，但恢复数据的时间一般都是很长的，不符合业务需求，所以一个快速备份与恢复的软件就很有必要。 
之前我在维护mysql数据库的时候，使用mysqldump来进行备份与恢复，在备份的时候锁住表，然后全部备份，在数据少的时候没问题，但如果数据很多，不允许锁表，同时需要恢复数据块的情况，mysqldump就不适合了，我在恢复一个4G数据文件的数据库的时候，恢复的数据是使用mysqldump的数据，恢复了3个小时还没有反应，造成的影响很严重，所以我开始寻找其他的别发软件来满足以上的需求，幸好找到了，就是使用xtrabackup来进行备份与恢复，恢复4G数据文件的数据库，仅需要14秒，同时在备份的时候不会锁表，而且支持增量备份，所以把我的比较分享给大家，希望对大家有益！ Xtrabackup 是percona公司的开源项目，用以实现类似innodb官方的热备份工具InnoDB Hot Backup的功能，能够非常快速地备份与恢复mysql数据库。 Xtrabackup中包含两个工具： xtrabackup是用于热备份innodb, xtradb表中数据的工具，不能备份其他类型的表，也不能备份数据表结构； 
innobackupex是将xtrabackup进行封装的perl脚本，提供了备份myisam表的能力





IP网络存储ISCSI
                                     IP网络存储ISCSI
IP网络存储ISCSI
一、	ISCSI概述
1.1、	介绍
本章主要介绍了基于IP SAN 的网络存储ISCSI ，iscsl技术以其低廉的构成和优秀的存储性能，博得了很多CIO和存储管理的喜爱，目前陆续进入企业应用领域，推动了企业的存储环境向集中式转变，虽然， 目前对于ISCSI因该在什么样的环境中使用还存在诸多争议，ISCSI的前途是光明的，在未来的存储世界中，将会占据重要位置。


1.2、	SCSI介绍
SCSI是小型计算机系统接口(Samll Computer System Inerface) 的简称，SCSI作用输入/输出接口，主要用于硬盘、光盘、磁带机、扫描仪、打印机等设备.
 
 
1.3、	FC介绍
FC是光纤通道(Fibre Channel)的简称，是一种适合于前兆数据传输的、成熟而安全的解决方案。与传统的SCSI技术相比，FC提供更高的数据传输速率，更远的传输距离，更多的设备连接支持、更稳定的性能，更简易的安装。


1.4、	DAS介绍
DAS是直接式存储(Direct-Attached Stroage)的简称，是指将通过scsi接口或者光纤通道直接连接到一台计算机上面，当服务器在地理上比较分散，很难通过远程进行互连时，DAS是比较好的解决方案。但是这种方式存储之能通过与连接的主机进行访问，不能实现数据与其它主机的共享。同时DAS会占用服务器的操作资源。如：CPU资源 I/O资源，数据量越大，占用的资源就越多。


1.5、	NAS介绍
网络接入存储 (Network-Attached Stroge)简称NAS，它通过网络交换机连接存储系统和服务器，建立专门用于数据存储的私有网络，用户通过TCP/IP协议访问数据，采用标准的文件协议如：NFS、HTTP、CIFS来实现基于文件级的数据共享，NAS存储是文件共享访问变得更加方便快捷，并且能很容易的增加存储容量，通过专业化与存储技术相结合，NAS为那些需要共享大量文件数据的企业提供一个高效的，高可靠、高性价比的决绝方案。但是NAS也有一定的局限性，它会受到网络带宽和网络拥堵的影响，在一定程序上限制了NAS的网络传输能力.


1.6、	SAN介绍
存储区域网络(Storage Area Network)简称SAN，它是通过光纤交换机，光纤路由器，光纤集线器等设备将磁盘阵列、磁带等存储设备与相关服务器连接起来的告诉专用子网。
SAN主要由3个部分组成：
连接设备(如、路由器、光纤交换机)
通信接口(如、SICI、FC)
通信协议(如、IP和SCSI) 这3个部分再加上存储设备和服务器构成了一个SAN系统。


1.7、	iSCSI概念
iscsi，即internet SCSI，是IETF制定的一项标准，用于将SCSI数据块映射为以太网数据包，它一种基于IP Storage的理论的新型存储技术，该技术将存储行业广泛应用SCSI接口技术与IP网络技术相结合，可以在IP网络上构建SAN，简单的说iscsi就是在IP网络上运行SCSI协议的一种网络存储技术，





二、	iSCSI工作原理
2.1、iSCSI的组成
一个简单的iSCSI系统大概是由以下部分组成：
	iSCSI Initiator 或者iSCSI HBA
	iSCSI Target
	以太网交换机
	一台或者多台服务器
 

2.2、iSCSI Initiator

	iSCSI Initiator是一个安装在计算上的软件或者硬件设备，它负责与iSCSI存储设备进行通信iSCSI 服务器与iSCSI存储设备之间的连接方式有两种:
第一种基于软件的方式：是iSCSI Initiator（免费）, 在iSCSI服务器上安装Initiator 后，Initiator软件可以将以太网卡虚拟为iSCSI卡，进而接受报和发送iSCSI数据报文，从而实现主机和iSCSI存储设备之间的iSCSI协议和TCP/IP协议传输功能。
第二种方式: 是硬件iSCSI HBA(Host Bus Adapter) HBA硬件卡，即iSCSI Initiator硬件。这种方式需要先购买iSCSI HBA卡，然后将其安装在iSCSI服务器上，从而实现iSCSI服务器与交换机之间、iSCSI服务器与存储设备之间的高效数据传输.
iSCSI适配卡大致分成两类，一为TOE HBA卡，一为iSCSI HBA卡，前者价格较便宜，后者效能极佳，但价格非常昂贵。代表性的厂商有Adaptec、Alacritech、Intel、LSI、Qlogic等，其中Intel专注于TOE HBA卡的开发

2.3、iSCSI Target 
iSCSI Target是一个可以用于存储数据的iSCSI磁盘阵列或者具有iSCSI功能的设备都可以被称为”iSCSI Target”，以为大多数操作系统都可以利用一些软件将系统转变为一个”iSCSI Target”。
 利用iSCSI target软件，可以将服务器的存储空间分配给客户机使用,客户机可以像使用本地硬盘一样使用iSCSI磁盘，包括对其进行分区、格式化及读写等。而且每个客户端可以向iSCSI磁盘写数据，户不干扰，而且不会破坏存储到服务器中的数据。同时,iSCSI对可以通过配置文件对权限进行限制。非常的灵活。
    我们知道，iSCSI使用了TCIP/IP协议进行通信的，因此，将iSCSI两端连接起来，仅仅需要一个以太网络就可以了，由此可知，iSCSI的存储性能和这个以太网有直接的关系，所以最好在iSCSI网络中使用千兆以太网交换机，劣质的网络设备会严重影响存储系统的性能，也就说，要为每个服务器配置高质量的千M以太网和千M交换机，并且提供两个链接，对于 ISCSI Target，应该为每个独立阵列中的两个独立端口配置一个设备交换机，最后将交换机连接起来，采用这种配置防止。其中一个交换机出现问题。另外一个任然可以保证数据的正常运行。
IP网络存储ISCSI

一、	ISCSI概述
1.1、	介绍

本章主要介绍了基于IP SAN 的网络存储ISCSI ，iscsl技术以其低廉的构成和优秀的存储性能，博得了很多CIO和存储管理的喜爱，目前陆续进入企业应用领域，推动了企业的存储环境向集中式转变，虽然， 目前对于ISCSI因该在什么样的环境中使用还存在诸多争议，ISCSI的前途是光明的，在未来的存储世界中，将会占据重要位置。
1.2、	SCSI介绍
SCSI是小型计算机系统接口(Samll Computer System Inerface) 的简称，SCSI作用输入/输出接口，主要用于硬盘、光盘、磁带机、扫描仪、打印机等设备.
 
1.3、	FC介绍
FC是光纤通道(Fibre Channel)的简称，是一种适合于前兆数据传输的、成熟而安全的解决方案。与传统的SCSI技术相比，FC提供更高的数据传输速率，更远的传输距离，更多的设备连接支持、更稳定的性能，更简易的安装。

1.4、	DAS介绍
DAS是直接式存储(Direct-Attached Stroage)的简称，是指将通过scsi接口或者光纤通道直接连接到一台计算机上面，当服务器在地理上比较分散，很难通过远程进行互连时，DAS是比较好的解决方案。但是这种方式存储之能通过与连接的主机进行访问，不能实现数据与其它主机的共享。同时DAS会占用服务器的操作资源。如：CPU资源 I/O资源，数据量越大，占用的资源就越多。


1.5、	NAS介绍
网络接入存储 (Network-Attached Stroge)简称NAS，它通过网络交换机连接存储系统和服务器，建立专门用于数据存储的私有网络，用户通过TCP/IP协议访问数据，采用标准的文件协议如：NFS、HTTP、CIFS来实现基于文件级的数据共享，NAS存储是文件共享访问变得更加方便快捷，并且能很容易的增加存储容量，通过专业化与存储技术相结合，NAS为那些需要共享大量文件数据的企业提供一个高效的，高可靠、高性价比的决绝方案。但是NAS也有一定的局限性，它会受到网络带宽和网络拥堵的影响，在一定程序上限制了NAS的网络传输能力.

1.6、	SAN介绍
存储区域网络(Storage Area Network)简称SAN，它是通过光纤交换机，光纤路由器，光纤集线器等设备将磁盘阵列、磁带等存储设备与相关服务器连接起来的告诉专用子网。
SAN主要由3个部分组成：
连接设备(如、路由器、光纤交换机)
通信接口(如、SICI、FC)
通信协议(如、IP和SCSI) 这3个部分再加上存储设备和服务器构成了一个SAN系统。

1.7、	iSCSI概念
iscsi，即internet SCSI，是IETF制定的一项标准，用于将SCSI数据块映射为以太网数据包，它一种基于IP Storage的理论的新型存储技术，该技术将存储行业广泛应用SCSI接口技术与IP网络技术相结合，可以在IP网络上构建SAN，简单的说iscsi就是在IP网络上运行SCSI协议的一种网络存储技术，

二、	iSCSI工作原理
2.1、iSCSI的组成
一个简单的iSCSI系统大概是由以下部分组成：
	iSCSI Initiator 或者iSCSI HBA
	iSCSI Target
	以太网交换机
	一台或者多台服务器
 

2.2、iSCSI Initiator

	iSCSI Initiator是一个安装在计算上的软件或者硬件设备，它负责与iSCSI存储设备进行通信iSCSI 服务器与iSCSI存储设备之间的连接方式有两种:
第一种基于软件的方式：是iSCSI Initiator（免费）, 在iSCSI服务器上安装Initiator 后，Initiator软件可以将以太网卡虚拟为iSCSI卡，进而接受报和发送iSCSI数据报文，从而实现主机和iSCSI存储设备之间的iSCSI协议和TCP/IP协议传输功能。
第二种方式: 是硬件iSCSI HBA(Host Bus Adapter) HBA硬件卡，即iSCSI Initiator硬件。这种方式需要先购买iSCSI HBA卡，然后将其安装在iSCSI服务器上，从而实现iSCSI服务器与交换机之间、iSCSI服务器与存储设备之间的高效数据传输.
iSCSI适配卡大致分成两类，一为TOE HBA卡，一为iSCSI HBA卡，前者价格较便宜，后者效能极佳，但价格非常昂贵。代表性的厂商有Adaptec、Alacritech、Intel、LSI、Qlogic等，其中Intel专注于TOE HBA卡的开发

2.3、iSCSI Target 
iSCSI Target是一个可以用于存储数据的iSCSI磁盘阵列或者具有iSCSI功能的设备都可以被称为”iSCSI Target”，以为大多数操作系统都可以利用一些软件将系统转变为一个”iSCSI Target”。
 利用iSCSI target软件，可以将服务器的存储空间分配给客户机使用,客户机可以像使用本地硬盘一样使用iSCSI磁盘，包括对其进行分区、格式化及读写等。而且每个客户端可以向iSCSI磁盘写数据，户不干扰，而且不会破坏存储到服务器中的数据。同时,iSCSI对可以通过配置文件对权限进行限制。非常的灵活。
    我们知道，iSCSI使用了TCIP/IP协议进行通信的，因此，将iSCSI两端连接起来，仅仅需要一个以太网络就可以了，由此可知，iSCSI的存储性能和这个以太网有直接的关系，所以最好在iSCSI网络中使用千兆以太网交换机，劣质的网络设备会严重影响存储系统的性能，也就说，要为每个服务器配置高质量的千M以太网和千M交换机，并且提供两个链接，对于 ISCSI Target，应该为每个独立阵列中的两个独立端口配置一个设备交换机，最后将交换机连接起来，采用这种配置防止。其中一个交换机出现问题。另外一个任然可以保证数据的正常运行。
    
    
二、基于命令行的操作:

Target 10.0.0.201操作:
对于每个Target来说，主机的ID是唯一，
存储设备的LUN ID 是由ISCSI target来分配的。
ISCSI驱动器为了scsi请求和回应提供了一个通过IP网络传输的驱动.

# yum -y install scsi-target-utils
# /etc/init.d/tgtd start
# chkconfig tgtd on
# chkconfig --list tgtd

 
 
(1)模拟一个控制器 
# tgtadm  --lld iscsi --mode target --op new --targetname iqn.2014-07-03.com.sxkj.mydisk1 --tid 1 

--lld：表示驱动或者接口类型
--mode:target目标
--op：new 新建
--targetname:表示创建targename名称.iqn.xxxxxxx.mydisk1 前和尾部固定，中间自由定义.
--tid：标识号


#查看
# tgtadm --lld iscsi --mode target --op show
 
 
 
(2)在模拟控制器关联一个设备 
# tgtadm --lld iscsi --mode logicalunit --op new --tid 1 --lun 1 -b /dev/sdb

--lld：表示驱动或者接口类型
--mode:target目标
--op：new 新建
--tid：标识号
--lun:lun标识号
-b:指定设备号


 #查看
# tgtadm --lld iscsi --mode target --op show

(3)基于IP的授权
# tgtadm --lld iscsi --mode target --op bind --tid 1 -I 10.0.0.0/16

    取消授权
    #tgtadm --lld iscsi --mode target --op unbind --tid 1 -I 10.0.0.0/16
    
    删除一个逻辑卷
    #tgtadm --lld iscsi --mode target --op delete --tid 1 --lun 1
    
    删除一个target
    #tgtadm --lld iscsi --mode target --op delete --tid 1
    
 Initiator 10.0.0.202操作:    
 
# iscsi-iname
iqn.1994-05.com.redhat:d18ee3c506b 

# iscsi-iname -p iqn.2014-07-03.com.skkjgongda
iqn.2014-07-03.com.skkjgongda:fb66a38ae152

# vim /etc/iscsi/initiatorname.iscsi 
InitiatorName=iqn.2014-07-03.com.skkjgongda:fb66a38ae152 给自己的客户端取个固定的名字。


发现服务端Target
# iscsiadm -m discovery -t sendtargets -p 10.0.0.201


登录服务端:
# iscsiadm -m node -T iqn.2014-07-03.com.sxkj.mydisk1 -p 10.0.0.201 -l
# iscsiadm -m node -o delete -T iqn.2014-07-03.com.sxkj.mydisk1 -p 10.0.0.201

先退出登录。
# iscsiadm -m node -T iqn.2014-07-03.com.sxkj.mydisk1 -p 10.0.0.201 -U all

在删除一个发现:
iscsiadm -m node -o delete -T iqn.2014-07-03.com.sxkj.mydisk1 -p 10.0.0.201
    
    
     
    
五、总结所有的步骤简单化精华


iscsi单机文件共享系统，也就说比如有服务端共享一个/sdb存储出来
每个客户端可以在/sdb里面使用一个分区.
比如客户端1可以使用fdisk /sdb 分一个/sdb1
比如客户端2可以使用fdisk /sdb 分一个/sdb2
比如客户端3可以使用fdisk /sdb 分一个/sdb3
如果客户端1和客户端2同时使用/sdb1就会出现内存奔溃的情况。这个一大BUG，

5.1、环境描述:
服务器端target 10.0.0.203 增加一块30G sisci硬盘
客户端：10.0.0.204
客户端：10.0.0.202


5.2、服务安装
(1)、安装服务
# yum -y install scsi-target-utils
(2)、修改配置文件
#vim /etc/tgt/targets.conf
<target iqn.2014-06-10.com.sxkj.mydisk1>
    backing-store /dev/sdb    #如果多个存储设备。直接加多一个backing-store
    incominguser alvin alvin123 #基于用户认证
    initiator-address 10.0.0.0/16 #基于IP授权访问
</target>



(3)、重启服务
# /etc/init.d/tgtd restart
(4)、查看是否成功
# tgtadm --lld iscsi --mode target --op show





5.3、客户端安装
(1)安装软件
# yum -y install iscsi-initiator-utils

(2)修改Initiator唯一标识号
跟target一样也需要一个唯一标识号。可以使用-p来更改,然后编辑配置文件永久修改
# iscsi-iname
# iscsi-iname -p iqn.2014-06.com.sxkjgongda
# vim /etc/iscsi/initiatorname.iscsi
InitiatorName=iqn.1994-05.com.redhat:1c39abfdfa0  #给自己的客户端Initiator起个名字

(3)、修改配置文件
# vim /etc/iscsi/iscsid.conf
node.session.auth.authmethod = CHAP  #开启chap认证
node.session.auth.username = Alvin    #服务端target创建和绑定的用户
node.session.auth.password = alvin123  #服务端target创建的密码写进来

(4)、发现targe命令
# iscsiadm -m discovery -d 2 -t st -p 10.0.0.203

(5)、重启服务
# /etc/init.d/iscsi restart  是否可以看到共享磁盘？

(6)、可以使用fdisl对共享磁盘进行分区。然后挂在到本地
    
    



CACTI部署
                                  Cacti部署
一、	Cacti概述
1.1、什么是Cacti
Cacti是一套基于PHP,MySQL,SNMP及RRDTool开发的网络流量监测图形分析工具。

1.2、Cacti简介
1. cacti是用php语言实现的一个软件，它的主要功能是用snmp服务获取数据，然后用rrdtool储存和更新数据，当用户需要查看数据的时候用rrdtool生成图表呈现给用户。因此，snmp和rrdtool是cacti的关键。Snmp关系着数据的收集，rrdtool关系着数据存储和图表的生成。
2. Mysql配合PHP程序存储一些变量数据并对变量数据进行调用，如：主机名、主机ip、snmp团体名、端口号、模板信息等变量
3. snmp抓到数据不是存储在mysql中，而是存在rrdtool生成的rrd文件中（在cacti根目录的rra文件夹下）。rrdtool对数据的更新和存储就是对rrd文件的处理，rrd文件是大小固定的档案文件（RoundRobinArchive），它能够存储的数据笔数在创建时就已经定义。

1.3、Cacti组成部分
 
 
2.1    Data Retrieval
Cacti首先要做的工作就是收集数据，cacti使用Poller（轮询器）收集数据。Poller是操作系统scheduler的扩展，如在类Unix系统中的crontab。现在的IT设施中会有许多不同的设备，如服务器、网络设备等，cacti主要使用SNMP协议来从远端的设备上收集数据，所有可以使用SNMP协议的设备都可以被cacti监控。
2.2    Data Storage
存储收集到的数据有许多方法，可以使用数据库、平面文件等，cacti使用的是RDDTool。RRD是Round Robin Database（环形数据库）的缩写，RRD用来存储和显示时间序列数据，如网络带宽、机房温度、服务器负载等，RRD使用非常紧凑的方式存储数据，数据不会随着时间的推移而增大，RRD还可以生成美观的图形。这些特性使得cacti没有存储需求。RRD也做一席位其他的工作，如RRD会将原始数据与已整合的数据进行合并，以使得历史数据的存储节省空间，RRD支持的整合功能包括：AVERAGE, MAXIMUM, MINIMUM和LAST。
2.3    Data Presentation
Cacti最大的一个特点是内置了RRDTool画图功能，将其与通用的web服务器相结合，可以实现在任意平台上使用浏览器就可以查看监控画面。
1.4、Cacti原理图
 
 
 
二、Cacti 服务端安装
2.1、安装关联包
# yum -y install install php php-mysql php-snmp mysql mysql-server net-snmp net-snmp-libs net-snmp-utils php-pdo perl-DBD-MySQL rrdtool



2.2、配置SNMP
#vim /etc/snmp/snmpd.conf
#将下边这行中的default 
com2sec notConfigUser  default       public
#改为：127.0.0.1
com2sec notConfigUser  127.0.0.1       public
com2sec notConfigUser  10.0.0.0/16       public
#将下边这行中的systemview
access  notConfigGroup ""      any       noauth    exact  systemview none none
#改为：all
access  notConfigGroup ""      any       noauth    exact  all none none
#将下边这行的注释“#”去掉
view all    included  .1          80





重启snmpd服务
# /etc/init.d/snmpd  restart
# chkconfig snmpd on
2.3、安装Cacti
# wget http://www.cacti.net/downloads/cacti-0.8.8b.tar.gz   下载cacti主文件
# tar -xvf cacti-0.8.8b.tar.gz
# mv cacti-0.8.8b /var/www/html/cacti
# chown apache:apahce /var/www/html/cacti/ -R 
# chmod 755 /var/www/html/cacti/ -R


2.4、启动Mysql配置数据库
# /etc/init.d/mysqld restart
# mysql –uroot –p
> create database cacti default character set utf8;  注意咯。为utf8为否是乱码
> grant all privileges on cacti.* to cacti@localhost identified by 'cacti' with grant option;
> grant all privileges on cacti.* to cacti@127.0.0.1 identified by 'cacti' with grant option;
>use cacti;
>source /var/www/html/cacti/cacti.sql;
> flush privileges;
>quit
2.5、修改cacti PHP文件，修改数据库地址
#vim /var/www/html/cacti/include/config.php
$database_type = "mysql";
$database_default = "cacti";
$database_hostname = "localhost";
$database_username = "cacti";
$database_password = "cacti";
$database_port = "3306";

# vim /etc/php.ini
;date.timezone =
date.timezone = Asia/Shanghai

# crontab –e
*/5 * * * *  /usr/bin/php /var/www/html/cacti/poller.php >/dev/null 2>&1
# /etc/init.d/crond restart



2.6、验证安装
在浏览器里面打开
http://10.0.0.201/cacti
mysql关闭时候访问报FATAL: Cannot connect to MySQL server on 'localhost'. Please make sure you have specified a valid MySQL database name in 'include/config.php；


修改 config.php 的localhost 为ip地址 127.0.0.1

(1)然后 #点“Next”- #选择“New Install”,点击“Next” 确保所有的路径都是显示“FOUND”,没有“NOT FOUND”的点击Finish 完成安装。

(2)要求输入用户密码登陆，输入默认用户和密码为:admin 密码：admin
第一次登陆要求修改密码：请输入新的密码修改

(3)登陆成功后。到此界面
 

三、Cacti 客户端安装
3.1、安装snmp
# yum -y install net-snmp

3.2、配置snmp
#vim /etc/snmp/snmpd.conf
#将下边这行中的default 
com2sec notConfigUser  default       public
#改为：127.0.0.1
com2sec notConfigUser  10.0.0.201       public  修改成cacti服务器的IP地址
#将下边这行中的systemview
access  notConfigGroup ""      any       noauth    exact  systemview none none
#改为：all
access  notConfigGroup ""      any       noauth    exact  all none none
#将下边这行的注释“#”去掉
view all    included  .1          80

3.3、重启snmp服务
# # /etc/init.d/snmpd  restart
四、Cacti 的使用
4.1、新建一个本地主机
(1)、选择Devices
 

(2)、选择ADD 添加
 












(3)、输入信息然后点击右下角Create
 

 (4)、创建成功后如下图
 

(5)、为监控模板创建图形文件
 







(6)、勾选所有模板，点击Create
 
(7)、选择创建图形的颜色
 


(8)、创建成功
 
(9)、加入默认树图
 

(10)、选择ADD

 

(11)、选择HOST –〉Create创建
 







(12)选择树图查看
 


(13)查看日志轮询情况。就是执行计划任务的情况
 



14、轮询是否报错。这个将决定状态是否UP 
 
 

14、如果没有up。手动执行
/usr/bin/php /var/www/html/cacti/poller.php  执行一边轮询和数据生成.
生成的数据在：/var/www/html/cacti/rra 里面
每次执行轮询的记录在/var/www/html/cacti/log 日志里面





自动化运维
http://os.51cto.com/art/201408/448607.htm



http://mobile.51cto.com/comment-448601.htm

